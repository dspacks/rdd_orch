{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31192,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Development Environment (ADE) for Healthcare Data Documentation\n",
        "\n",
        "## Version 1.0 - 11/15/2025\n",
        "\n",
        "This notebook implements a specialized development environment for building, testing, and managing AI agents using the Google Gemini API and Agent Development Kit (ADK).\n",
        "\n",
        "### System Overview\n",
        "\n",
        "The ADE creates an \"Orchestrator\" and team of sub-agents that:\n",
        "- Ingest complex, technical, and often imperfect data specifications (CSV, XML, JSON)\n",
        "- Produce comprehensive, human-readable documentation\n",
        "- Provide Human-in-the-Loop (HITL) review workflows\n",
        "- Manage context using the \"Toon\" notation system\n",
        "\n",
        "### Key Components\n",
        "\n",
        "1. **SQLite Database** - Project-local persistence\n",
        "2. **Toon System** - Context management for large files\n",
        "3. **Core Agents** - Specialized AI agents for data processing\n",
        "4. **ReviewQueue** - Human-in-the-loop workflow\n",
        "5. **Orchestrator** - Agent chaining and workflow management"
      ],
      "metadata": {
        "id": "qADNu24I85Ob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Dependencies"
      ],
      "metadata": {
        "id": "ypS-NnqG85Oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Install required packages\n",
        "# !pip install -q google-generativeai sqlite3 pandas numpy"
      ],
      "metadata": {
        "id": "ab7-N3Vz85Oi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import sqlite3\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "from enum import Enum\n",
        "import google.generativeai as genai\n",
        "from dataclasses import dataclass, asdict\n",
        "import hashlib\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:41:05.250401Z",
          "iopub.execute_input": "2025-11-15T23:41:05.250621Z",
          "iopub.status.idle": "2025-11-15T23:41:14.025427Z",
          "shell.execute_reply.started": "2025-11-15T23:41:05.250599Z",
          "shell.execute_reply": "2025-11-15T23:41:14.02431Z"
        },
        "id": "kv9RMZla85Ok"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Configure Google Gemini API\n",
        "#from kaggle_secrets import UserSecretsClient\n",
        "from google.colab import userdata\n",
        "# Get API key from Kaggle secrets\n",
        "#user_secrets = UserSecretsClient()\n",
        "#api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "# Configure the Gemini API\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "print(\"âœ“ Gemini API configured successfully\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:47:36.828027Z",
          "iopub.execute_input": "2025-11-15T23:47:36.828382Z",
          "iopub.status.idle": "2025-11-15T23:47:36.920797Z",
          "shell.execute_reply.started": "2025-11-15T23:47:36.828354Z",
          "shell.execute_reply": "2025-11-15T23:47:36.919774Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOVGveoe85Ok",
        "outputId": "8c8bc037-1543-4879-d9f8-19e4ef48e672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Gemini API configured successfully\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âš ï¸ Important: API Rate Limits & Configuration\n",
        "\n",
        "The system includes flexible rate limiting based on your Gemini API tier. You can configure this in the **API Configuration** cell above.\n",
        "\n",
        "**Available Tier Configurations:**\n",
        "\n",
        "| Tier | Requests/Min | Processing Time (7 vars) | Usage |\n",
        "|------|-------------|-------------------------|--------|\n",
        "| **FREE** | 10 | ~2-3 minutes | Default, free tier |\n",
        "| **PAYG** | 360 | ~10 seconds | Pay-as-you-go |\n",
        "| **ENTERPRISE** | 1000 | ~5 seconds | Enterprise customers |\n",
        "| **CONSERVATIVE** | 8 | ~3-4 minutes | Extra safe, fewer retries |\n",
        "\n",
        "**How to Change Your Configuration:**\n",
        "\n",
        "1. **Use a preset tier:**\n",
        "   ```python\n",
        "   # In the API Configuration cell, change this line:\n",
        "   API_CONFIG = APITier.PAYG  # Instead of APITier.FREE\n",
        "   ```\n",
        "\n",
        "2. **Create a custom configuration:**\n",
        "   ```python\n",
        "   API_CONFIG = APITier.custom(\n",
        "       requests_per_minute=50,\n",
        "       max_retries=3,\n",
        "       base_retry_delay=2.0\n",
        "   )\n",
        "   ```\n",
        "\n",
        "3. **Override for a specific job:**\n",
        "   ```python\n",
        "   # Create custom config\n",
        "   fast_config = APITier.PAYG\n",
        "   \n",
        "   # Pass to orchestrator\n",
        "   orchestrator = Orchestrator(db, api_config=fast_config)\n",
        "   ```\n",
        "\n",
        "**What Happens Automatically:**\n",
        "\n",
        "âœ… **Rate limiting** - Waits between requests to stay within limits  \n",
        "âœ… **Retry logic** - Auto-retries with exponential backoff if rate limit hit  \n",
        "âœ… **Clear messages** - Shows `â±ï¸ Rate limiting: waiting X.Xs...`  \n",
        "\n",
        "**Tips for Best Performance:**\n",
        "\n",
        "1. **Free tier users:** Use `auto_approve=True` for testing small datasets first\n",
        "2. **Paid tier users:** Change to `APITier.PAYG` for much faster processing  \n",
        "3. **Having quota issues?** Try `APITier.CONSERVATIVE` for extra safety\n",
        "4. **Need specific limits?** Use `APITier.custom(your_limit)`\n",
        "\n",
        "**Example: Upgrading from Free to Paid Tier**\n",
        "\n",
        "```python\n",
        "# After upgrading your Gemini API plan:\n",
        "# 1. Change configuration (in API Configuration cell)\n",
        "API_CONFIG = APITier.PAYG\n",
        "\n",
        "# 2. Re-initialize orchestrator\n",
        "orchestrator = Orchestrator(db)  # Uses new API_CONFIG\n",
        "\n",
        "# 3. Process normally - now 36x faster!\n",
        "job_id = orchestrator.process_data_dictionary(\n",
        "    source_data=sample_data_dictionary,\n",
        "    source_file=\"study.csv\",\n",
        "    auto_approve=True\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "I2kIwAHj85Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "@dataclass\n",
        "class APIConfig:\n",
        "    \"\"\"Configuration for API rate limits and retry behavior.\"\"\"\n",
        "    requests_per_minute: int = 10\n",
        "    max_retries: int = 3\n",
        "    base_retry_delay: float = 6.0\n",
        "    model_name: str = \"gemini-2.0-flash-exp\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.min_delay = 60.0 / self.requests_per_minute\n",
        "\n",
        "\n",
        "# Predefined configurations for different API tiers\n",
        "class APITier:\n",
        "    \"\"\"Predefined API configurations for different Gemini tiers.\"\"\"\n",
        "\n",
        "    # Free tier: 10 requests/minute\n",
        "    FREE = APIConfig(\n",
        "        requests_per_minute=10,\n",
        "        max_retries=3,\n",
        "        base_retry_delay=6.0,\n",
        "        model_name=\"gemini-2.0-flash-exp\"\n",
        "    )\n",
        "\n",
        "    # Pay-as-you-go tier: 360 requests/minute\n",
        "    PAYG = APIConfig(\n",
        "        requests_per_minute=360,\n",
        "        max_retries=3,\n",
        "        base_retry_delay=2.0,\n",
        "        model_name=\"gemini-2.0-flash-exp\"\n",
        "    )\n",
        "\n",
        "    # Enterprise tier: 1000+ requests/minute\n",
        "    ENTERPRISE = APIConfig(\n",
        "        requests_per_minute=1000,\n",
        "        max_retries=2,\n",
        "        base_retry_delay=1.0,\n",
        "        model_name=\"gemini-2.0-flash-exp\"\n",
        "    )\n",
        "\n",
        "    # Conservative mode: Extra safe with delays\n",
        "    CONSERVATIVE = APIConfig(\n",
        "        requests_per_minute=8,\n",
        "        max_retries=5,\n",
        "        base_retry_delay=8.0,\n",
        "        model_name=\"gemini-2.0-flash-exp\"\n",
        "    )\n",
        "\n",
        "    @staticmethod\n",
        "    def custom(requests_per_minute: int, max_retries: int = 3,\n",
        "               base_retry_delay: float = 6.0, model_name: str = \"gemini-2.0-flash-exp\") -> APIConfig:\n",
        "        \"\"\"Create a custom API configuration.\"\"\"\n",
        "        return APIConfig(\n",
        "            requests_per_minute=requests_per_minute,\n",
        "            max_retries=max_retries,\n",
        "            base_retry_delay=base_retry_delay,\n",
        "            model_name=model_name\n",
        "        )\n",
        "\n",
        "\n",
        "# Set your tier here - CHANGE THIS BASED ON YOUR API TIER\n",
        "API_CONFIG = APITier.FREE  # Options: FREE, PAYG, ENTERPRISE, CONSERVATIVE, or APITier.custom(...)\n",
        "\n",
        "print(f\"ðŸ“Š API Configuration:\")\n",
        "print(f\"   Tier: {'FREE' if API_CONFIG == APITier.FREE else 'CUSTOM'}\")\n",
        "print(f\"   Requests/minute: {API_CONFIG.requests_per_minute}\")\n",
        "print(f\"   Min delay between requests: {API_CONFIG.min_delay:.1f}s\")\n",
        "print(f\"   Max retries: {API_CONFIG.max_retries}\")\n",
        "print(f\"   Model: {API_CONFIG.model_name}\")\n",
        "print(f\"\\nðŸ’¡ Tip: Change API_CONFIG to match your tier:\")\n",
        "print(f\"   - API_CONFIG = APITier.FREE (10 req/min)\")\n",
        "print(f\"   - API_CONFIG = APITier.PAYG (360 req/min)\")\n",
        "print(f\"   - API_CONFIG = APITier.ENTERPRISE (1000 req/min)\")\n",
        "print(f\"   - API_CONFIG = APITier.custom(50) (50 req/min)\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:41:18.967524Z",
          "iopub.execute_input": "2025-11-15T23:41:18.968488Z",
          "iopub.status.idle": "2025-11-15T23:41:18.979898Z",
          "shell.execute_reply.started": "2025-11-15T23:41:18.968453Z",
          "shell.execute_reply": "2025-11-15T23:41:18.978716Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkZuH4x385On",
        "outputId": "1621dcde-c07a-436e-bb56-20298caaf3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š API Configuration:\n",
            "   Tier: FREE\n",
            "   Requests/minute: 10\n",
            "   Min delay between requests: 6.0s\n",
            "   Max retries: 3\n",
            "   Model: gemini-2.0-flash-exp\n",
            "\n",
            "ðŸ’¡ Tip: Change API_CONFIG to match your tier:\n",
            "   - API_CONFIG = APITier.FREE (10 req/min)\n",
            "   - API_CONFIG = APITier.PAYG (360 req/min)\n",
            "   - API_CONFIG = APITier.ENTERPRISE (1000 req/min)\n",
            "   - API_CONFIG = APITier.custom(50) (50 req/min)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Configuration and Rate Limits\n",
        "\n",
        "Configure API rate limits based on your Gemini API tier."
      ],
      "metadata": {
        "id": "lTttbz7l85Op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âš ï¸ Important: API Rate Limits\n",
        "\n",
        "**Gemini API Free Tier Limits:**\n",
        "- **10 requests per minute** per model\n",
        "- The system automatically handles rate limiting with delays between requests\n",
        "- Each API call will wait ~6 seconds to stay within limits\n",
        "- Processing 7 variables takes approximately **2-3 minutes** due to rate limiting\n",
        "\n",
        "**Tips for Faster Processing:**\n",
        "1. Use `auto_approve=True` for testing (skips manual review)\n",
        "2. Start with a small dataset (3-5 variables) to test\n",
        "3. For production with paid tier, limits are much higher\n",
        "4. The system automatically retries with exponential backoff if limits are hit\n",
        "\n",
        "**If you see quota errors:**\n",
        "- The system will automatically retry (up to 3 times)\n",
        "- Wait times increase with each retry (6s, 12s, 24s)\n",
        "- Consider upgrading to paid tier for higher quotas"
      ],
      "metadata": {
        "id": "qXfg5ajE85Oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Database Schema and Setup\n",
        "\n",
        "The SQLite database is the backbone of the HITL workflow and provides persistent storage for all project data."
      ],
      "metadata": {
        "id": "YCo4mofs85Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class DatabaseManager:\n",
        "    \"\"\"Manages SQLite database operations for the ADE project.\"\"\"\n",
        "\n",
        "    def __init__(self, db_path: str = \"project.db\"):\n",
        "        self.db_path = db_path\n",
        "        self.conn = None\n",
        "        self.cursor = None\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Establish database connection.\"\"\"\n",
        "        self.conn = sqlite3.connect(self.db_path)\n",
        "        self.conn.row_factory = sqlite3.Row\n",
        "        self.cursor = self.conn.cursor()\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Close database connection.\"\"\"\n",
        "        if self.conn:\n",
        "            self.conn.close()\n",
        "\n",
        "    def initialize_schema(self):\n",
        "        \"\"\"Create all required tables for the ADE system.\"\"\"\n",
        "\n",
        "        # Agents table\n",
        "        self.cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS Agents (\n",
        "            agent_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            name TEXT NOT NULL UNIQUE,\n",
        "            system_prompt TEXT NOT NULL,\n",
        "            agent_type TEXT NOT NULL,\n",
        "            config JSON,\n",
        "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        # Toons table - Context snippets\n",
        "        self.cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS Toons (\n",
        "            toon_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            name TEXT NOT NULL UNIQUE,\n",
        "            toon_type TEXT NOT NULL CHECK(toon_type IN (\n",
        "                'Toon_Summary', 'Toon_Chunk', 'Toon_Instruction',\n",
        "                'Toon_Version', 'Toon_Design', 'Toon_Mapping'\n",
        "            )),\n",
        "            content TEXT NOT NULL,\n",
        "            metadata JSON,\n",
        "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        # Jobs table\n",
        "        self.cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS Jobs (\n",
        "            job_id TEXT PRIMARY KEY,\n",
        "            source_file TEXT NOT NULL,\n",
        "            status TEXT NOT NULL DEFAULT 'Running' CHECK(status IN (\n",
        "                'Running', 'Completed', 'Failed', 'Paused'\n",
        "            )),\n",
        "            metadata JSON,\n",
        "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        # ReviewQueue table - HITL workflow\n",
        "        self.cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS ReviewQueue (\n",
        "            item_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            job_id TEXT NOT NULL,\n",
        "            status TEXT NOT NULL DEFAULT 'Pending' CHECK(status IN (\n",
        "                'Pending', 'Approved', 'Rejected', 'Needs_Clarification'\n",
        "            )),\n",
        "            source_agent TEXT NOT NULL,\n",
        "            target_agent TEXT,\n",
        "            source_data TEXT NOT NULL,\n",
        "            generated_content TEXT NOT NULL,\n",
        "            approved_content TEXT,\n",
        "            rejection_feedback TEXT,\n",
        "            clarification_response TEXT,\n",
        "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "            FOREIGN KEY (job_id) REFERENCES Jobs(job_id)\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        # SystemState table - Application state\n",
        "        self.cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS SystemState (\n",
        "            state_key TEXT PRIMARY KEY,\n",
        "            state_value TEXT NOT NULL,\n",
        "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        # SessionHistory table - Chat logs\n",
        "        self.cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS SessionHistory (\n",
        "            history_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            job_id TEXT,\n",
        "            role TEXT NOT NULL CHECK(role IN ('user', 'assistant', 'system')),\n",
        "            content TEXT NOT NULL,\n",
        "            metadata JSON,\n",
        "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "            FOREIGN KEY (job_id) REFERENCES Jobs(job_id)\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        self.conn.commit()\n",
        "        print(\"Database schema initialized successfully.\")\n",
        "\n",
        "    def execute_query(self, query: str, params: tuple = ()):\n",
        "        \"\"\"Execute a query and return results.\"\"\"\n",
        "        self.cursor.execute(query, params)\n",
        "        return self.cursor.fetchall()\n",
        "\n",
        "    def execute_update(self, query: str, params: tuple = ()):\n",
        "        \"\"\"Execute an update/insert query.\"\"\"\n",
        "        self.cursor.execute(query, params)\n",
        "        self.conn.commit()\n",
        "        return self.cursor.lastrowid"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:41:28.947822Z",
          "iopub.execute_input": "2025-11-15T23:41:28.948105Z",
          "iopub.status.idle": "2025-11-15T23:41:28.958551Z",
          "shell.execute_reply.started": "2025-11-15T23:41:28.948085Z",
          "shell.execute_reply": "2025-11-15T23:41:28.957415Z"
        },
        "id": "VeXx68Ln85Or"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Toon Notation in Practice\n",
        "\n",
        "**When to use Toon notation:**\n",
        "1. **Large data arrays** - Use tabular format for rows of similar objects\n",
        "2. **Context injection** - Encode data before passing to agents\n",
        "3. **Toon library storage** - Store data compactly in Toon snippets\n",
        "4. **Prompt optimization** - Reduce token usage by 40-70%\n",
        "\n",
        "**Integration with agents:**\n",
        "```python\n",
        "# Instead of JSON\n",
        "data_json = json.dumps(parsed_data)\n",
        "\n",
        "# Use Toon notation\n",
        "data_toon = ToonNotation.encode(parsed_data)\n",
        "\n",
        "# Pass to agent (uses fewer tokens!)\n",
        "result = agent.process(data_toon)\n",
        "```"
      ],
      "metadata": {
        "id": "r5nQ4xCk85Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class ToonNotation:\n",
        "    \"\"\"\n",
        "    Compact notation for encoding data to maximize context efficiency.\n",
        "\n",
        "    Reduces token usage by 40-70% compared to standard JSON while preserving\n",
        "    all information. Inspired by YAML but optimized for LLM context windows.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _needs_quoting(value: str) -> bool:\n",
        "        \"\"\"Check if a string value needs quotes to avoid ambiguity.\"\"\"\n",
        "        if not isinstance(value, str):\n",
        "            return False\n",
        "        # Quote if contains comma, colon, or looks like a number/boolean\n",
        "        if ',' in value or ':' in value:\n",
        "            return True\n",
        "        if value.lower() in ['true', 'false', 'null', 'none']:\n",
        "            return True\n",
        "        try:\n",
        "            float(value)\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_tabular(arr: list) -> bool:\n",
        "        \"\"\"Check if array is uniform objects (tabular format).\"\"\"\n",
        "        if not arr or not isinstance(arr[0], dict):\n",
        "            return False\n",
        "        keys = set(arr[0].keys())\n",
        "        return all(isinstance(item, dict) and set(item.keys()) == keys for item in arr)\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_primitive_array(arr: list) -> bool:\n",
        "        \"\"\"Check if array contains only primitives (not dicts/lists).\"\"\"\n",
        "        return all(not isinstance(item, (dict, list)) for item in arr)\n",
        "\n",
        "    @staticmethod\n",
        "    def encode(data: Any, indent: int = 0) -> str:\n",
        "        \"\"\"\n",
        "        Encode data in Toon notation.\n",
        "\n",
        "        Examples:\n",
        "            {'id': 1, 'name': 'Ada'} â†’\n",
        "                id: 1\n",
        "                name: Ada\n",
        "\n",
        "            {'tags': ['foo', 'bar']} â†’\n",
        "                tags[2]: foo,bar\n",
        "\n",
        "            {'items': [{'id': 1, 'qty': 5}, {'id': 2, 'qty': 3}]} â†’\n",
        "                items[2]{id,qty}:\n",
        "                  1,5\n",
        "                  2,3\n",
        "        \"\"\"\n",
        "        prefix = \"  \" * indent\n",
        "\n",
        "        # Handle None/null\n",
        "        if data is None:\n",
        "            return \"null\"\n",
        "\n",
        "        # Handle primitives\n",
        "        if isinstance(data, bool):\n",
        "            return str(data).lower()\n",
        "        if isinstance(data, (int, float)):\n",
        "            return str(data)\n",
        "        if isinstance(data, str):\n",
        "            if ToonNotation._needs_quoting(data):\n",
        "                return f'\"{data}\"'\n",
        "            return data\n",
        "\n",
        "        # Handle empty containers\n",
        "        if isinstance(data, dict) and not data:\n",
        "            return \"\"  # Empty dict produces no output\n",
        "        if isinstance(data, list) and not data:\n",
        "            return \"[0]:\"\n",
        "\n",
        "        # Handle root array\n",
        "        if isinstance(data, list):\n",
        "            # Primitive array (inline)\n",
        "            if ToonNotation._is_primitive_array(data):\n",
        "                values = [\n",
        "                    f'\"{v}\"' if ToonNotation._needs_quoting(v) else str(v)\n",
        "                    for v in data\n",
        "                ]\n",
        "                return f\"[{len(data)}]: {','.join(values)}\"\n",
        "\n",
        "            # Tabular array (uniform objects)\n",
        "            elif ToonNotation._is_tabular(data):\n",
        "                keys = list(data[0].keys())\n",
        "                result = f\"[{len(data)}]{{{','.join(keys)}}}:\\n\"\n",
        "                for item in data:\n",
        "                    values = [\n",
        "                        f'\"{item[k]}\"' if ToonNotation._needs_quoting(item[k]) else str(item[k])\n",
        "                        for k in keys\n",
        "                    ]\n",
        "                    result += f\"{prefix}  {','.join(values)}\\n\"\n",
        "                return result.rstrip()\n",
        "\n",
        "            # Mixed/nested array (list format)\n",
        "            else:\n",
        "                result = f\"[{len(data)}]:\\n\"\n",
        "                for item in data:\n",
        "                    if isinstance(item, (dict, list)):\n",
        "                        item_str = ToonNotation.encode(item, indent + 1)\n",
        "                        result += f\"{prefix}  - {item_str}\\n\"\n",
        "                    else:\n",
        "                        val = f'\"{item}\"' if ToonNotation._needs_quoting(item) else str(item)\n",
        "                        result += f\"{prefix}  - {val}\\n\"\n",
        "                return result.rstrip()\n",
        "\n",
        "        # Handle object\n",
        "        if isinstance(data, dict):\n",
        "            result = []\n",
        "            for key, value in data.items():\n",
        "                # Empty arrays\n",
        "                if isinstance(value, list) and not value:\n",
        "                    result.append(f\"{prefix}{key}[0]:\")\n",
        "                # Primitive array (inline)\n",
        "                elif isinstance(value, list) and ToonNotation._is_primitive_array(value):\n",
        "                    values = [\n",
        "                        f'\"{v}\"' if ToonNotation._needs_quoting(v) else str(v)\n",
        "                        for v in value\n",
        "                    ]\n",
        "                    result.append(f\"{prefix}{key}[{len(value)}]: {','.join(values)}\")\n",
        "                # Tabular array\n",
        "                elif isinstance(value, list) and ToonNotation._is_tabular(value):\n",
        "                    keys = list(value[0].keys())\n",
        "                    result.append(f\"{prefix}{key}[{len(value)}]{{{','.join(keys)}}}:\")\n",
        "                    for item in value:\n",
        "                        values = [\n",
        "                            f'\"{item[k]}\"' if ToonNotation._needs_quoting(item[k]) else str(item[k])\n",
        "                            for k in keys\n",
        "                        ]\n",
        "                        result.append(f\"{prefix}  {','.join(values)}\")\n",
        "                # Mixed array\n",
        "                elif isinstance(value, list):\n",
        "                    result.append(f\"{prefix}{key}[{len(value)}]:\")\n",
        "                    for item in value:\n",
        "                        if isinstance(item, (dict, list)):\n",
        "                            item_str = ToonNotation.encode(item, indent + 1)\n",
        "                            # Handle array of arrays\n",
        "                            if isinstance(item, list):\n",
        "                                result.append(f\"{prefix}  - {item_str}\")\n",
        "                            else:\n",
        "                                result.append(f\"{prefix}  - {item_str}\")\n",
        "                        else:\n",
        "                            val = f'\"{item}\"' if ToonNotation._needs_quoting(item) else str(item)\n",
        "                            result.append(f\"{prefix}  - {val}\")\n",
        "                # Nested object\n",
        "                elif isinstance(value, dict):\n",
        "                    result.append(f\"{prefix}{key}:\")\n",
        "                    nested = ToonNotation.encode(value, indent + 1)\n",
        "                    result.append(nested)\n",
        "                # Primitive value\n",
        "                else:\n",
        "                    val = value\n",
        "                    if isinstance(val, bool):\n",
        "                        val = str(val).lower()\n",
        "                    elif isinstance(val, str) and ToonNotation._needs_quoting(val):\n",
        "                        val = f'\"{val}\"'\n",
        "                    result.append(f\"{prefix}{key}: {val}\")\n",
        "\n",
        "            return \"\\n\".join(result)\n",
        "\n",
        "        return str(data)\n",
        "\n",
        "    @staticmethod\n",
        "    def compare_sizes(data: dict) -> dict:\n",
        "        \"\"\"Compare token usage between JSON and Toon notation.\"\"\"\n",
        "        json_str = json.dumps(data, indent=2)\n",
        "        toon_str = ToonNotation.encode(data)\n",
        "\n",
        "        # Rough token estimation (1 token â‰ˆ 4 chars)\n",
        "        json_tokens = len(json_str) // 4\n",
        "        toon_tokens = len(toon_str) // 4\n",
        "        savings = 100 * (1 - toon_tokens / json_tokens)\n",
        "\n",
        "        return {\n",
        "            'json_chars': len(json_str),\n",
        "            'toon_chars': len(toon_str),\n",
        "            'json_tokens': json_tokens,\n",
        "            'toon_tokens': toon_tokens,\n",
        "            'savings_percent': round(savings, 1),\n",
        "            'json': json_str,\n",
        "            'toon': toon_str\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"âœ“ Toon Notation system loaded\")\n",
        "print(\"  Compact data encoding for efficient context usage\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:43:21.298354Z",
          "iopub.execute_input": "2025-11-15T23:43:21.299087Z",
          "iopub.status.idle": "2025-11-15T23:43:21.322401Z",
          "shell.execute_reply.started": "2025-11-15T23:43:21.299054Z",
          "shell.execute_reply": "2025-11-15T23:43:21.321374Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYTzLTy785Os",
        "outputId": "7098fe2b-4a16-4aaa-a917-46884a042eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Toon Notation system loaded\n",
            "  Compact data encoding for efficient context usage\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "class DataParserAgent(BaseAgent):\n",
        "    \"\"\"Agent for parsing raw data into standardized JSON format.\"\"\"\n",
        "    \n",
        "    def __init__(self, config: APIConfig = None):\n",
        "        system_prompt = \"\"\"\n",
        "You are a DataParserAgent specialized in converting raw data specifications\n",
        "(CSV, JSON, XML) into a standardized format using Toon notation.\n",
        "\n",
        "Toon notation is a compact format that reduces token usage:\n",
        "- Objects: key: value (one per line)\n",
        "- Primitive arrays: key[count]: val1,val2,val3\n",
        "- Tabular arrays: key[count]{col1,col2}: then data rows\n",
        "- Example: items[2]{id,name}:\n",
        "            1,foo\n",
        "            2,bar\n",
        "\n",
        "Your task:\n",
        "1. Parse the input data (CSV, JSON, or XML)\n",
        "2. Preserve all original field names and values\n",
        "3. Output in Toon notation format\n",
        "4. Each variable should include: original_name, original_type (if available),\n",
        "   original_description (if available), and any other metadata\n",
        "\n",
        "Output format (Toon notation):\n",
        "variables[N]{original_name,original_type,original_description,notes}:\n",
        "  field_name,type,description,notes\n",
        "  field_name2,type2,description2,notes2\n",
        "\n",
        "Only output valid Toon notation. No additional commentary.\n",
        "\"\"\"\n",
        "        super().__init__(\"DataParserAgent\", system_prompt, config)\n",
        "    \n",
        "    def parse_csv(self, csv_data: str) -> List[Dict]:\n",
        "        \"\"\"Parse CSV data dictionary.\"\"\"\n",
        "        result = self.process(csv_data)\n",
        "        \n",
        "        # Try to parse as Toon notation first\n",
        "        # For now, fall back to JSON parsing since LLM might output JSON\n",
        "        if \"```json\" in result or \"{\" in result:\n",
        "            # Extract JSON from markdown code block if present\n",
        "            if \"```json\" in result:\n",
        "                result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in result:\n",
        "                result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "            return json.loads(result)\n",
        "        else:\n",
        "            # Agent used Toon notation - for now convert back\n",
        "            # In future, we'd parse Toon notation directly\n",
        "            # For MVP, request JSON output\n",
        "            return json.loads(result)"
      ],
      "metadata": {
        "id": "nLcVptLR85Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Initialize database\n",
        "db = DatabaseManager(\"project.db\")\n",
        "db.connect()\n",
        "db.initialize_schema()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:43:55.331716Z",
          "iopub.execute_input": "2025-11-15T23:43:55.33202Z",
          "iopub.status.idle": "2025-11-15T23:43:55.413532Z",
          "shell.execute_reply.started": "2025-11-15T23:43:55.331996Z",
          "shell.execute_reply": "2025-11-15T23:43:55.412676Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxTL4JpR85Ou",
        "outputId": "4a63634d-3317-4143-88ae-8db482d90293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database schema initialized successfully.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Toon System - Context Management\n",
        "\n",
        "The \"Toon\" system is a critical component for managing large files and providing granular control over agent context. A Toon is a discrete, named snippet of context stored in the database."
      ],
      "metadata": {
        "id": "VfVFn7Z485Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class ToonType(Enum):\n",
        "    \"\"\"Enumeration of Toon types.\"\"\"\n",
        "    SUMMARY = \"Toon_Summary\"\n",
        "    CHUNK = \"Toon_Chunk\"\n",
        "    INSTRUCTION = \"Toon_Instruction\"\n",
        "    VERSION = \"Toon_Version\"\n",
        "    DESIGN = \"Toon_Design\"\n",
        "    MAPPING = \"Toon_Mapping\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Toon:\n",
        "    \"\"\"Represents a context snippet (Toon).\"\"\"\n",
        "    name: str\n",
        "    toon_type: ToonType\n",
        "    content: str\n",
        "    metadata: Optional[Dict[str, Any]] = None\n",
        "    toon_id: Optional[int] = None\n",
        "\n",
        "\n",
        "class ToonManager:\n",
        "    \"\"\"Manages the Toon Library for context management.\"\"\"\n",
        "\n",
        "    def __init__(self, db_manager: DatabaseManager):\n",
        "        self.db = db_manager\n",
        "\n",
        "    def create_toon(self, name: str, toon_type: ToonType, content: str,\n",
        "                    metadata: Optional[Dict] = None) -> int:\n",
        "        \"\"\"Create a new Toon in the library.\"\"\"\n",
        "        query = \"\"\"\n",
        "        INSERT INTO Toons (name, toon_type, content, metadata)\n",
        "        VALUES (?, ?, ?, ?)\n",
        "        \"\"\"\n",
        "        metadata_json = json.dumps(metadata) if metadata else None\n",
        "        toon_id = self.db.execute_update(\n",
        "            query,\n",
        "            (name, toon_type.value, content, metadata_json)\n",
        "        )\n",
        "        print(f\"Created Toon '{name}' (ID: {toon_id}, Type: {toon_type.value})\")\n",
        "        return toon_id\n",
        "\n",
        "    def get_toon(self, toon_id: int) -> Optional[Toon]:\n",
        "        \"\"\"Retrieve a Toon by ID.\"\"\"\n",
        "        query = \"SELECT * FROM Toons WHERE toon_id = ?\"\n",
        "        result = self.db.execute_query(query, (toon_id,))\n",
        "        if result:\n",
        "            row = result[0]\n",
        "            return Toon(\n",
        "                toon_id=row['toon_id'],\n",
        "                name=row['name'],\n",
        "                toon_type=ToonType(row['toon_type']),\n",
        "                content=row['content'],\n",
        "                metadata=json.loads(row['metadata']) if row['metadata'] else None\n",
        "            )\n",
        "        return None\n",
        "\n",
        "    def get_toon_by_name(self, name: str) -> Optional[Toon]:\n",
        "        \"\"\"Retrieve a Toon by name.\"\"\"\n",
        "        query = \"SELECT * FROM Toons WHERE name = ?\"\n",
        "        result = self.db.execute_query(query, (name,))\n",
        "        if result:\n",
        "            row = result[0]\n",
        "            return Toon(\n",
        "                toon_id=row['toon_id'],\n",
        "                name=row['name'],\n",
        "                toon_type=ToonType(row['toon_type']),\n",
        "                content=row['content'],\n",
        "                metadata=json.loads(row['metadata']) if row['metadata'] else None\n",
        "            )\n",
        "        return None\n",
        "\n",
        "    def list_toons(self, toon_type: Optional[ToonType] = None) -> List[Toon]:\n",
        "        \"\"\"List all Toons, optionally filtered by type.\"\"\"\n",
        "        if toon_type:\n",
        "            query = \"SELECT * FROM Toons WHERE toon_type = ? ORDER BY created_at DESC\"\n",
        "            results = self.db.execute_query(query, (toon_type.value,))\n",
        "        else:\n",
        "            query = \"SELECT * FROM Toons ORDER BY created_at DESC\"\n",
        "            results = self.db.execute_query(query)\n",
        "\n",
        "        toons = []\n",
        "        for row in results:\n",
        "            toons.append(Toon(\n",
        "                toon_id=row['toon_id'],\n",
        "                name=row['name'],\n",
        "                toon_type=ToonType(row['toon_type']),\n",
        "                content=row['content'],\n",
        "                metadata=json.loads(row['metadata']) if row['metadata'] else None\n",
        "            ))\n",
        "        return toons\n",
        "\n",
        "    def update_toon(self, toon_id: int, content: Optional[str] = None,\n",
        "                    metadata: Optional[Dict] = None):\n",
        "        \"\"\"Update a Toon's content or metadata.\"\"\"\n",
        "        updates = []\n",
        "        params = []\n",
        "\n",
        "        if content is not None:\n",
        "            updates.append(\"content = ?\")\n",
        "            params.append(content)\n",
        "\n",
        "        if metadata is not None:\n",
        "            updates.append(\"metadata = ?\")\n",
        "            params.append(json.dumps(metadata))\n",
        "\n",
        "        if updates:\n",
        "            updates.append(\"updated_at = CURRENT_TIMESTAMP\")\n",
        "            query = f\"UPDATE Toons SET {', '.join(updates)} WHERE toon_id = ?\"\n",
        "            params.append(toon_id)\n",
        "            self.db.execute_update(query, tuple(params))\n",
        "            print(f\"Updated Toon ID {toon_id}\")\n",
        "\n",
        "    def delete_toon(self, toon_id: int):\n",
        "        \"\"\"Delete a Toon from the library.\"\"\"\n",
        "        query = \"DELETE FROM Toons WHERE toon_id = ?\"\n",
        "        self.db.execute_update(query, (toon_id,))\n",
        "        print(f\"Deleted Toon ID {toon_id}\")\n",
        "\n",
        "\n",
        "# Review Queue Data Structures\n",
        "class ReviewStatus(Enum):\n",
        "    \"\"\"Status of items in the review queue.\"\"\"\n",
        "    PENDING = \"Pending\"\n",
        "    APPROVED = \"Approved\"\n",
        "    REJECTED = \"Rejected\"\n",
        "    NEEDS_CLARIFICATION = \"Needs_Clarification\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ReviewItem:\n",
        "    \"\"\"Represents an item in the review queue.\"\"\"\n",
        "    job_id: str\n",
        "    source_agent: str\n",
        "    source_data: str\n",
        "    generated_content: str\n",
        "    status: ReviewStatus\n",
        "    item_id: Optional[int] = None\n",
        "    approved_content: Optional[str] = None\n",
        "    feedback: Optional[str] = None\n",
        "    created_at: Optional[str] = None\n",
        "\n",
        "\n",
        "class ReviewQueueManager:\n",
        "    \"\"\"Manages the review queue for Human-in-the-Loop workflow.\"\"\"\n",
        "\n",
        "    def __init__(self, db_manager: DatabaseManager):\n",
        "        self.db = db_manager\n",
        "\n",
        "    def add_item(self, item: ReviewItem) -> int:\n",
        "        \"\"\"Add an item to the review queue.\"\"\"\n",
        "        query = \"\"\"\n",
        "        INSERT INTO ReviewQueue (job_id, source_agent, source_data, generated_content, status)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "        \"\"\"\n",
        "        cursor = self.db.conn.execute(\n",
        "            query,\n",
        "            (item.job_id, item.source_agent, item.source_data,\n",
        "             item.generated_content, item.status.value)\n",
        "        )\n",
        "        self.db.conn.commit()\n",
        "        return cursor.lastrowid\n",
        "\n",
        "    def get_pending_items(self, job_id: Optional[str] = None) -> List[ReviewItem]:\n",
        "        \"\"\"Get all pending review items, optionally filtered by job_id.\"\"\"\n",
        "        if job_id:\n",
        "            query = \"\"\"\n",
        "            SELECT * FROM ReviewQueue\n",
        "            WHERE status = 'Pending' AND job_id = ?\n",
        "            ORDER BY created_at\n",
        "            \"\"\"\n",
        "            rows = self.db.execute_query(query, (job_id,))\n",
        "        else:\n",
        "            query = \"\"\"\n",
        "            SELECT * FROM ReviewQueue\n",
        "            WHERE status = 'Pending'\n",
        "            ORDER BY created_at\n",
        "            \"\"\"\n",
        "            rows = self.db.execute_query(query)\n",
        "\n",
        "        return [self._row_to_item(row) for row in rows]\n",
        "\n",
        "    def get_clarification_items(self, job_id: Optional[str] = None) -> List[ReviewItem]:\n",
        "        \"\"\"Get items that need clarification.\"\"\"\n",
        "        if job_id:\n",
        "            query = \"\"\"\n",
        "            SELECT * FROM ReviewQueue\n",
        "            WHERE status = 'Needs_Clarification' AND job_id = ?\n",
        "            ORDER BY created_at\n",
        "            \"\"\"\n",
        "            rows = self.db.execute_query(query, (job_id,))\n",
        "        else:\n",
        "            query = \"\"\"\n",
        "            SELECT * FROM ReviewQueue\n",
        "            WHERE status = 'Needs_Clarification'\n",
        "            ORDER BY created_at\n",
        "            \"\"\"\n",
        "            rows = self.db.execute_query(query)\n",
        "\n",
        "        return [self._row_to_item(row) for row in rows]\n",
        "\n",
        "    def get_approved_items(self, job_id: str) -> List[ReviewItem]:\n",
        "        \"\"\"Get all approved items for a job.\"\"\"\n",
        "        query = \"\"\"\n",
        "        SELECT * FROM ReviewQueue\n",
        "        WHERE status = 'Approved' AND job_id = ?\n",
        "        ORDER BY created_at\n",
        "        \"\"\"\n",
        "        rows = self.db.execute_query(query, (job_id,))\n",
        "        return [self._row_to_item(row) for row in rows]\n",
        "\n",
        "    def approve_item(self, item_id: int, approved_content: Optional[str] = None):\n",
        "        \"\"\"Approve a review item.\"\"\"\n",
        "        if approved_content:\n",
        "            query = \"\"\"\n",
        "            UPDATE ReviewQueue\n",
        "            SET status = 'Approved', approved_content = ?\n",
        "            WHERE item_id = ?\n",
        "            \"\"\"\n",
        "            self.db.execute_update(query, (approved_content, item_id))\n",
        "        else:\n",
        "            # Use generated_content as approved_content\n",
        "            query = \"\"\"\n",
        "            UPDATE ReviewQueue\n",
        "            SET status = 'Approved', approved_content = generated_content\n",
        "            WHERE item_id = ?\n",
        "            \"\"\"\n",
        "            self.db.execute_update(query, (item_id,))\n",
        "\n",
        "        print(f\"âœ“ Approved item {item_id}\")\n",
        "\n",
        "    def reject_item(self, item_id: int, feedback: str):\n",
        "        \"\"\"Reject a review item with feedback.\"\"\"\n",
        "        query = \"\"\"\n",
        "        UPDATE ReviewQueue\n",
        "        SET status = 'Rejected', feedback = ?\n",
        "        WHERE item_id = ?\n",
        "        \"\"\"\n",
        "        self.db.execute_update(query, (feedback, item_id))\n",
        "        print(f\"âœ“ Rejected item {item_id}\")\n",
        "\n",
        "    def submit_clarification(self, item_id: int, clarification_response: str):\n",
        "        \"\"\"Submit a clarification response and mark as pending review.\"\"\"\n",
        "        query = \"\"\"\n",
        "        UPDATE ReviewQueue\n",
        "        SET status = 'Pending', feedback = ?\n",
        "        WHERE item_id = ?\n",
        "        \"\"\"\n",
        "        self.db.execute_update(query, (clarification_response, item_id))\n",
        "        print(f\"âœ“ Submitted clarification for item {item_id}\")\n",
        "\n",
        "    def _row_to_item(self, row: Dict) -> ReviewItem:\n",
        "        \"\"\"Convert database row to ReviewItem.\"\"\"\n",
        "        return ReviewItem(\n",
        "            item_id=row['item_id'],\n",
        "            job_id=row['job_id'],\n",
        "            source_agent=row['source_agent'],\n",
        "            source_data=row['source_data'],\n",
        "            generated_content=row['generated_content'],\n",
        "            status=ReviewStatus(row['status']),\n",
        "            approved_content=row['approved_content'],\n",
        "            feedback=row['rejection_feedback'], # Corrected column name\n",
        "            created_at=row['created_at']\n",
        "        )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:00.482363Z",
          "iopub.execute_input": "2025-11-15T23:44:00.482648Z",
          "iopub.status.idle": "2025-11-15T23:44:00.512638Z",
          "shell.execute_reply.started": "2025-11-15T23:44:00.482629Z",
          "shell.execute_reply": "2025-11-15T23:44:00.51159Z"
        },
        "id": "Pm46bKCm85Ov"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class BaseAgent:\n",
        "    \"\"\"Base class for all agents with configurable rate limiting and retry logic.\"\"\"\n",
        "\n",
        "    def __init__(self, name: str, system_prompt: str, config: APIConfig = None):\n",
        "        self.name = name\n",
        "        self.system_prompt = system_prompt\n",
        "        self.config = config or API_CONFIG  # Use global config if not specified\n",
        "        self.model = genai.GenerativeModel(self.config.model_name)\n",
        "        self.active_toons: List[Toon] = []\n",
        "        self.last_request_time = 0\n",
        "\n",
        "    def inject_toons(self, toons: List[Toon]):\n",
        "        \"\"\"Inject Toons into agent context.\"\"\"\n",
        "        self.active_toons = toons\n",
        "\n",
        "    def build_prompt(self, user_input: str, additional_context: str = \"\") -> str:\n",
        "        \"\"\"Build the full prompt with system prompt, Toons, and user input.\"\"\"\n",
        "        prompt_parts = [self.system_prompt]\n",
        "\n",
        "        # Add active Toons as context\n",
        "        if self.active_toons:\n",
        "            prompt_parts.append(\"\\n=== CONTEXT (Toons) ===\")\n",
        "            for toon in self.active_toons:\n",
        "                prompt_parts.append(f\"\\n[{toon.toon_type.value}: {toon.name}]\")\n",
        "                prompt_parts.append(toon.content)\n",
        "\n",
        "        # Add additional context\n",
        "        if additional_context:\n",
        "            prompt_parts.append(\"\\n=== ADDITIONAL CONTEXT ===\")\n",
        "            prompt_parts.append(additional_context)\n",
        "\n",
        "        # Add user input\n",
        "        prompt_parts.append(\"\\n=== INPUT ===\")\n",
        "        prompt_parts.append(user_input)\n",
        "\n",
        "        return \"\\n\".join(prompt_parts)\n",
        "\n",
        "    def _wait_for_rate_limit(self):\n",
        "        \"\"\"Implement rate limiting by waiting if necessary.\"\"\"\n",
        "        if self.last_request_time > 0:\n",
        "            elapsed = time.time() - self.last_request_time\n",
        "            if elapsed < self.config.min_delay:\n",
        "                wait_time = self.config.min_delay - elapsed\n",
        "                print(f\"â±ï¸  Rate limiting: waiting {wait_time:.1f}s...\")\n",
        "                time.sleep(wait_time)\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        \"\"\"Generate response using Gemini API with retry logic and rate limiting.\"\"\"\n",
        "        for attempt in range(self.config.max_retries):\n",
        "            try:\n",
        "                # Wait for rate limit before making request\n",
        "                self._wait_for_rate_limit()\n",
        "\n",
        "                # Make API call\n",
        "                self.last_request_time = time.time()\n",
        "                response = self.model.generate_content(prompt)\n",
        "                return response.text\n",
        "\n",
        "            except Exception as e:\n",
        "                error_str = str(e)\n",
        "\n",
        "                # Check if it's a rate limit error\n",
        "                if \"ResourceExhausted\" in error_str or \"429\" in error_str:\n",
        "                    # Extract retry delay from error if available\n",
        "                    retry_delay = self.config.base_retry_delay\n",
        "\n",
        "                    # Try to extract the suggested retry delay\n",
        "                    if \"retry_delay\" in error_str:\n",
        "                        try:\n",
        "                            import re\n",
        "                            match = re.search(r'seconds: (\\d+)', error_str)\n",
        "                            if match:\n",
        "                                retry_delay = float(match.group(1))\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                    # Add exponential backoff\n",
        "                    wait_time = retry_delay * (2 ** attempt)\n",
        "\n",
        "                    if attempt < self.config.max_retries - 1:\n",
        "                        print(f\"âš ï¸  Rate limit hit. Waiting {wait_time:.1f}s before retry {attempt + 1}/{self.config.max_retries}...\")\n",
        "                        time.sleep(wait_time)\n",
        "                    else:\n",
        "                        print(f\"âŒ Max retries ({self.config.max_retries}) reached.\")\n",
        "                        print(f\"ðŸ’¡ Tip: Try increasing API_CONFIG.max_retries or wait and re-run the cell.\")\n",
        "                        raise\n",
        "                else:\n",
        "                    # For non-rate-limit errors, raise immediately\n",
        "                    print(f\"âŒ API Error: {error_str}\")\n",
        "                    raise\n",
        "\n",
        "        raise Exception(f\"Failed after {self.config.max_retries} retries\")\n",
        "\n",
        "\n",
        "\n",
        "    def process_with_toon(self, data: Any, additional_context: str = \"\") -> str:\n",
        "        \"\"\"\n",
        "        Process data using Toon notation for efficiency.\n",
        "\n",
        "        This method encodes the input data using ToonNotation to reduce token usage\n",
        "        by 40-70% compared to JSON.\n",
        "\n",
        "        Args:\n",
        "            data: Any serializable data structure\n",
        "            additional_context: Additional context to include\n",
        "\n",
        "        Returns:\n",
        "            Generated response from the agent\n",
        "        \"\"\"\n",
        "        # Encode data in Toon notation\n",
        "        toon_encoded = ToonNotation.encode(data)\n",
        "\n",
        "        # Add context explaining the format\n",
        "        toon_context = \"\"\"\n",
        "The input data below is in Toon notation format, a compact encoding that reduces token usage:\n",
        "- Simple values: key: value\n",
        "- Arrays: key[count]: val1,val2,val3\n",
        "- Tabular data: key[count]{col1,col2}: followed by rows\n",
        "\"\"\"\n",
        "        full_context = toon_context\n",
        "        if additional_context:\n",
        "            full_context += \"\\n\" + additional_context\n",
        "\n",
        "        # Process with Toon-encoded data\n",
        "        return self.process(toon_encoded, full_context)\n",
        "\n",
        "    def process(self, input_data: str, additional_context: str = \"\") -> str:\n",
        "        \"\"\"Process input and return output.\"\"\"\n",
        "        full_prompt = self.build_prompt(input_data, additional_context)\n",
        "        return self.generate(full_prompt)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:10.857395Z",
          "iopub.execute_input": "2025-11-15T23:44:10.857843Z",
          "iopub.status.idle": "2025-11-15T23:44:10.873507Z",
          "shell.execute_reply.started": "2025-11-15T23:44:10.857811Z",
          "shell.execute_reply": "2025-11-15T23:44:10.872344Z"
        },
        "id": "HOsvh9u-85Ov"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class DataParserAgent(BaseAgent):\n",
        "    \"\"\"Agent for parsing raw data into standardized JSON format.\"\"\"\n",
        "\n",
        "    def __init__(self, config: APIConfig = None):\n",
        "        system_prompt = \"\"\"\n",
        "You are a DataParserAgent specialized in converting raw data specifications\n",
        "(CSV, JSON, XML) into a standardized JSON format.\n",
        "\n",
        "Your task:\n",
        "1. Parse the input data\n",
        "2. Preserve all original field names and values\n",
        "3. Output a JSON array where each element represents one variable/field\n",
        "4. Each element should include: original_name, original_type (if available),\n",
        "   original_description (if available), and any other metadata\n",
        "\n",
        "Output format:\n",
        "```json\n",
        "[\n",
        "  {\n",
        "    \"original_name\": \"field_name\",\n",
        "    \"original_type\": \"type\",\n",
        "    \"original_description\": \"description\",\n",
        "    \"metadata\": {}\n",
        "  }\n",
        "]\n",
        "```\n",
        "\n",
        "Only output valid JSON. No additional commentary.\n",
        "\"\"\"\n",
        "        super().__init__(\"DataParserAgent\", system_prompt, config)\n",
        "\n",
        "    def parse_csv(self, csv_data: str) -> List[Dict]:\n",
        "        \"\"\"Parse CSV data dictionary.\"\"\"\n",
        "        result = self.process(csv_data)\n",
        "        # Extract JSON from markdown code block if present\n",
        "        if \"```json\" in result:\n",
        "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in result:\n",
        "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "        return json.loads(result)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:17.323324Z",
          "iopub.execute_input": "2025-11-15T23:44:17.323674Z",
          "iopub.status.idle": "2025-11-15T23:44:17.330986Z",
          "shell.execute_reply.started": "2025-11-15T23:44:17.323648Z",
          "shell.execute_reply": "2025-11-15T23:44:17.329676Z"
        },
        "id": "4gCee09G85Ow"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class TechnicalAnalyzerAgent(BaseAgent):\n",
        "    \"\"\"Agent for analyzing technical properties and mapping to internal standards.\"\"\"\n",
        "\n",
        "    def __init__(self, config: APIConfig = None):\n",
        "        system_prompt = \"\"\"\n",
        "You are a TechnicalAnalyzerAgent specialized in analyzing data fields and\n",
        "mapping them to internal standards.\n",
        "\n",
        "Your task:\n",
        "\n",
        "\n",
        "**Input Format: Toon Notation**\n",
        "The input data will be provided in Toon notation, a compact format that reduces token usage:\n",
        "- Simple values: `key: value`\n",
        "- Arrays: `key[count]: val1,val2,val3`\n",
        "- Tabular data: `key[count]{col1,col2}:` followed by data rows\n",
        "\n",
        "Example:\n",
        "```\n",
        "variables[2]{original_name,original_type}:\n",
        "  patient_id,text\n",
        "  age,integer\n",
        "```\n",
        "\n",
        "Parse this format and extract the field information.\n",
        "\n",
        "1. Analyze each field from the parsed data\n",
        "2. Infer technical properties (data_type, constraints, cardinality)\n",
        "3. Map to standardized field names following healthcare data conventions\n",
        "4. If mapping is unclear or confidence is low, flag for clarification\n",
        "\n",
        "Standard field mappings:\n",
        "- variable_name: standardized variable name\n",
        "- data_type: categorical, continuous, date, text, boolean\n",
        "- description: human-readable description\n",
        "- constraints: any validation rules\n",
        "- cardinality: required, optional, repeated\n",
        "- confidence: high, medium, low (for mapping quality)\n",
        "\n",
        "Output format:\n",
        "```json\n",
        "[\n",
        "  {\n",
        "    \"original_name\": \"field_name\",\n",
        "    \"variable_name\": \"standardized_name\",\n",
        "    \"data_type\": \"categorical\",\n",
        "    \"description\": \"description\",\n",
        "    \"constraints\": {},\n",
        "    \"cardinality\": \"required\",\n",
        "    \"confidence\": \"high\",\n",
        "    \"needs_clarification\": false,\n",
        "    \"clarification_question\": \"\"\n",
        "  }\n",
        "]\n",
        "```\n",
        "\n",
        "Only output valid JSON. No additional commentary.\n",
        "\"\"\"\n",
        "        super().__init__(\"TechnicalAnalyzerAgent\", system_prompt, config)\n",
        "\n",
        "    def analyze(self, parsed_data: List[Dict],\n",
        "                clarifications: Optional[Dict[str, str]] = None) -> List[Dict]:\n",
        "        \"\"\"Analyze parsed data and map to internal standards.\"\"\"\n",
        "        additional_context = \"\"\n",
        "        if clarifications:\n",
        "            additional_context = \"\\n=== USER CLARIFICATIONS ===\\n\"\n",
        "            for field, clarification in clarifications.items():\n",
        "                additional_context += f\"{field}: {clarification}\\n\"\n",
        "\n",
        "        # Use Toon notation for efficient token usage (40-70% reduction)\n",
        "        toon_encoded = ToonNotation.encode({\"variables\": parsed_data})\n",
        "\n",
        "        # Add format explanation\n",
        "        format_context = \"\\nData is in Toon notation format for efficiency. Output JSON as specified.\\n\"\n",
        "        full_context = format_context + (additional_context if additional_context else \"\")\n",
        "\n",
        "        result = self.process(toon_encoded, full_context)\n",
        "\n",
        "        # Extract JSON from markdown code block if present\n",
        "        if \"```json\" in result:\n",
        "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in result:\n",
        "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        return json.loads(result)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:21.283671Z",
          "iopub.execute_input": "2025-11-15T23:44:21.283954Z",
          "iopub.status.idle": "2025-11-15T23:44:21.292866Z",
          "shell.execute_reply.started": "2025-11-15T23:44:21.283934Z",
          "shell.execute_reply": "2025-11-15T23:44:21.291753Z"
        },
        "id": "OH96K1Dl85Ow"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class DomainOntologyAgent(BaseAgent):\n",
        "    \"\"\"Agent for mapping to standard healthcare ontologies (OMOP, LOINC, etc.).\"\"\"\n",
        "\n",
        "    def __init__(self, config: APIConfig = None):\n",
        "        system_prompt = \"\"\"\n",
        "You are a DomainOntologyAgent specialized in mapping healthcare data fields\n",
        "to standard ontologies and terminologies.\n",
        "\n",
        "Your task:\n",
        "\n",
        "**Input Format: Toon Notation**\n",
        "Input data is provided in Toon notation (compact format):\n",
        "- `key: value` for simple fields\n",
        "- `key[n]: v1,v2,...` for arrays\n",
        "- Nested objects use indentation\n",
        "\n",
        "Example:\n",
        "```\n",
        "variable_name: blood_pressure_systolic\n",
        "data_type: continuous\n",
        "description: Systolic blood pressure in mmHg\n",
        "```\n",
        "\n",
        "\n",
        "1. For each variable, identify appropriate standard ontology codes\n",
        "2. Primary ontologies to consider:\n",
        "   - OMOP CDM concepts\n",
        "   - LOINC codes (for lab/clinical observations)\n",
        "   - SNOMED CT (for clinical terms)\n",
        "   - RxNorm (for medications)\n",
        "3. Provide both the code and the standard term\n",
        "4. Include a confidence score for each mapping\n",
        "\n",
        "Output format:\n",
        "```json\n",
        "{\n",
        "  \"variable_name\": \"standardized_name\",\n",
        "  \"ontology_mappings\": [\n",
        "    {\n",
        "      \"system\": \"OMOP\",\n",
        "      \"code\": \"123456\",\n",
        "      \"display\": \"Standard Concept Name\",\n",
        "      \"confidence\": \"high\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "Only output valid JSON. No additional commentary.\n",
        "\"\"\"\n",
        "        super().__init__(\"DomainOntologyAgent\", system_prompt, config)\n",
        "\n",
        "    def map_ontologies(self, variable_data: Dict) -> Dict:\n",
        "        \"\"\"Map a variable to standard ontologies.\"\"\"\n",
        "        # Use Toon notation for efficient token usage\n",
        "        toon_encoded = ToonNotation.encode(variable_data)\n",
        "        format_context = \"\\nInput is in Toon notation format. Output JSON as specified.\\n\"\n",
        "        result = self.process(toon_encoded, format_context)\n",
        "\n",
        "        # Extract JSON from markdown code block if present\n",
        "        if \"```json\" in result:\n",
        "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in result:\n",
        "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        return json.loads(result)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:26.398882Z",
          "iopub.execute_input": "2025-11-15T23:44:26.399241Z",
          "iopub.status.idle": "2025-11-15T23:44:26.406733Z",
          "shell.execute_reply.started": "2025-11-15T23:44:26.399198Z",
          "shell.execute_reply": "2025-11-15T23:44:26.405576Z"
        },
        "id": "TrWONP_a85Ow"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class PlainLanguageAgent(BaseAgent):\n",
        "    \"\"\"Agent for generating human-readable documentation.\"\"\"\n",
        "\n",
        "    def __init__(self, config: APIConfig = None):\n",
        "        system_prompt = \"\"\"\n",
        "You are a PlainLanguageAgent specialized in creating clear, comprehensive,\n",
        "human-readable documentation for healthcare data variables.\n",
        "\n",
        "Your task:\n",
        "\n",
        "**Input Format: Toon Notation**\n",
        "The enriched variable data is provided in Toon notation (compact format that saves 40-70% tokens):\n",
        "- Simple fields: `key: value`\n",
        "- Arrays: `key[n]: val1,val2,val3`\n",
        "- Objects: nested with indentation\n",
        "\n",
        "Parse the Toon format and generate clear markdown documentation.\n",
        "\n",
        "\n",
        "1. Convert technical variable specifications into plain language\n",
        "2. Explain what the variable represents in clinical/research context\n",
        "3. Describe data type, constraints, and valid values\n",
        "4. Include ontology mappings and their significance\n",
        "5. Write for an interdisciplinary audience (clinicians, researchers, data scientists)\n",
        "\n",
        "Output format (Markdown):\n",
        "```markdown\n",
        "## Variable: [Variable Name]\n",
        "\n",
        "**Description:** [Clear, concise description]\n",
        "\n",
        "**Technical Details:**\n",
        "- Data Type: [type]\n",
        "- Cardinality: [required/optional]\n",
        "- Valid Values: [constraints or ranges]\n",
        "\n",
        "**Standard Ontology Mappings:**\n",
        "- OMOP: [code] - [term]\n",
        "- LOINC: [code] - [term]\n",
        "\n",
        "**Clinical Context:** [Explanation of why this variable matters]\n",
        "```\n",
        "\n",
        "Only output Markdown documentation. No additional commentary.\n",
        "\"\"\"\n",
        "        super().__init__(\"PlainLanguageAgent\", system_prompt, config)\n",
        "\n",
        "    def document_variable(self, enriched_data: Dict) -> str:\n",
        "        \"\"\"Generate plain language documentation for a variable.\"\"\"\n",
        "        # Use Toon notation for efficient token usage (40-70% reduction)\n",
        "        toon_encoded = ToonNotation.encode(enriched_data)\n",
        "        format_context = \"\\nInput is in Toon notation format. Generate markdown documentation.\\n\"\n",
        "        result = self.process(toon_encoded, format_context)\n",
        "\n",
        "        # Remove markdown code block markers if present\n",
        "        if \"```markdown\" in result:\n",
        "            result = result.split(\"```markdown\")[1].split(\"```\")[0].strip()\n",
        "        elif result.startswith(\"```\") and result.endswith(\"```\"):\n",
        "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:30.787247Z",
          "iopub.execute_input": "2025-11-15T23:44:30.787646Z",
          "iopub.status.idle": "2025-11-15T23:44:30.795372Z",
          "shell.execute_reply.started": "2025-11-15T23:44:30.78762Z",
          "shell.execute_reply": "2025-11-15T23:44:30.794128Z"
        },
        "id": "w4PiwzI685Ox"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class DocumentationAssemblerAgent(BaseAgent):\n",
        "    \"\"\"Agent for assembling final documentation from approved items.\"\"\"\n",
        "\n",
        "    def __init__(self, review_queue: ReviewQueueManager, config: APIConfig = None):\n",
        "        system_prompt = \"\"\"\n",
        "You are a DocumentationAssemblerAgent specialized in creating comprehensive,\n",
        "well-structured data documentation.\n",
        "\n",
        "Your task:\n",
        "1. Compile all approved variable documentation into a cohesive document\n",
        "2. Add a table of contents\n",
        "3. Include metadata (generation date, source file, etc.)\n",
        "4. Organize by logical groupings if applicable\n",
        "5. Ensure consistent formatting throughout\n",
        "\n",
        "Output: A complete Markdown document ready for publication.\n",
        "\"\"\"\n",
        "        super().__init__(\"DocumentationAssemblerAgent\", system_prompt, config)\n",
        "        self.review_queue = review_queue\n",
        "\n",
        "    def assemble(self, job_id: str) -> str:\n",
        "        \"\"\"Assemble final documentation from approved review items.\"\"\"\n",
        "        approved_items = self.review_queue.get_approved_items(job_id)\n",
        "\n",
        "        if not approved_items:\n",
        "            return \"# No approved documentation found for this job.\"\n",
        "\n",
        "        # Build document\n",
        "        doc_parts = [\n",
        "            \"# Healthcare Data Documentation\",\n",
        "            f\"\\n**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "            f\"**Job ID:** {job_id}\",\n",
        "            \"\\n---\\n\"\n",
        "        ]\n",
        "\n",
        "        # Add table of contents\n",
        "        doc_parts.append(\"## Table of Contents\\n\")\n",
        "        for i, item in enumerate(approved_items, 1):\n",
        "            # Extract variable name from content if possible\n",
        "            content = item.approved_content\n",
        "            if \"## Variable:\" in content:\n",
        "                var_name = content.split(\"## Variable:\")[1].split(\"\\n\")[0].strip()\n",
        "                doc_parts.append(f\"{i}. [{var_name}](#{var_name.lower().replace(' ', '-')})\")\n",
        "\n",
        "        doc_parts.append(\"\\n---\\n\")\n",
        "\n",
        "        # Add all approved content\n",
        "        for item in approved_items:\n",
        "            doc_parts.append(item.approved_content)\n",
        "            doc_parts.append(\"\\n---\\n\")\n",
        "\n",
        "        return \"\\n\".join(doc_parts)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:36.204276Z",
          "iopub.execute_input": "2025-11-15T23:44:36.204664Z",
          "iopub.status.idle": "2025-11-15T23:44:36.213091Z",
          "shell.execute_reply.started": "2025-11-15T23:44:36.204636Z",
          "shell.execute_reply": "2025-11-15T23:44:36.212091Z"
        },
        "id": "TzUCpUIl85Ox"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class DomainOntologyAgent(BaseAgent):\n",
        "    \"\"\"Agent for mapping to standard healthcare ontologies (OMOP, LOINC, etc.).\"\"\"\n",
        "\n",
        "    def __init__(self, config: APIConfig = None):\n",
        "        system_prompt = \"\"\"\n",
        "You are a DomainOntologyAgent specialized in mapping healthcare data fields\n",
        "to standard ontologies and terminologies.\n",
        "\n",
        "Your task:\n",
        "1. For each variable, identify appropriate standard ontology codes\n",
        "2. Primary ontologies to consider:\n",
        "   - OMOP CDM concepts\n",
        "   - LOINC codes (for lab/clinical observations)\n",
        "   - SNOMED CT (for clinical terms)\n",
        "   - RxNorm (for medications)\n",
        "3. Provide both the code and the standard term\n",
        "4. Include a confidence score for each mapping\n",
        "\n",
        "Output format:\n",
        "```json\n",
        "{\n",
        "  \"variable_name\": \"standardized_name\",\n",
        "  \"ontology_mappings\": [\n",
        "    {\n",
        "      \"system\": \"OMOP\",\n",
        "      \"code\": \"123456\",\n",
        "      \"display\": \"Standard Concept Name\",\n",
        "      \"confidence\": \"high\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "Only output valid JSON. No additional commentary.\n",
        "\"\"\"\n",
        "        super().__init__(\"DomainOntologyAgent\", system_prompt, config)\n",
        "\n",
        "    def map_ontologies(self, variable_data: Dict) -> Dict:\n",
        "        \"\"\"Map a variable to standard ontologies.\"\"\"\n",
        "        result = self.process(json.dumps(variable_data, indent=2))\n",
        "\n",
        "        # Extract JSON from markdown code block if present\n",
        "        if \"```json\" in result:\n",
        "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in result:\n",
        "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        return json.loads(result)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:40.599972Z",
          "iopub.execute_input": "2025-11-15T23:44:40.600353Z",
          "iopub.status.idle": "2025-11-15T23:44:40.6075Z",
          "shell.execute_reply.started": "2025-11-15T23:44:40.600327Z",
          "shell.execute_reply": "2025-11-15T23:44:40.606364Z"
        },
        "id": "LGjD7aSk85Ox"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class Orchestrator:\n",
        "    \"\"\"Manages the workflow of agents and coordinates the documentation pipeline.\"\"\"\n",
        "\n",
        "    def __init__(self, db_manager: DatabaseManager, api_config: APIConfig = None):\n",
        "        self.db = db_manager\n",
        "        self.config = api_config or API_CONFIG\n",
        "        self.toon_manager = ToonManager(db_manager)\n",
        "        self.review_queue = ReviewQueueManager(db_manager)\n",
        "\n",
        "        # Initialize agents with configuration\n",
        "        self.data_parser = DataParserAgent(config=self.config)\n",
        "        self.technical_analyzer = TechnicalAnalyzerAgent(config=self.config)\n",
        "        self.domain_ontology = DomainOntologyAgent(config=self.config)\n",
        "        self.plain_language = PlainLanguageAgent(config=self.config)\n",
        "        self.assembler = DocumentationAssemblerAgent(self.review_queue, config=self.config)\n",
        "\n",
        "        print(f\"âœ“ Orchestrator initialized with {self.config.requests_per_minute} req/min limit\")\n",
        "\n",
        "    def create_job(self, source_file: str) -> str:\n",
        "        \"\"\"Create a new documentation job.\"\"\"\n",
        "        # Generate unique job ID\n",
        "        job_id = hashlib.md5(\n",
        "            f\"{source_file}_{datetime.now().isoformat()}\".encode()\n",
        "        ).hexdigest()[:12]\n",
        "\n",
        "        query = \"\"\"\n",
        "        INSERT INTO Jobs (job_id, source_file, status)\n",
        "        VALUES (?, ?, 'Running')\n",
        "        \"\"\"\n",
        "        self.db.execute_update(query, (job_id, source_file))\n",
        "        print(f\"Created job {job_id} for source file: {source_file}\")\n",
        "        return job_id\n",
        "\n",
        "    def process_data_dictionary(self, source_data: str, source_file: str = \"input.csv\",\n",
        "                                auto_approve: bool = False) -> str:\n",
        "        \"\"\"\n",
        "        Main workflow: Process a data dictionary through the agent pipeline.\n",
        "\n",
        "        Args:\n",
        "            source_data: The raw data dictionary content\n",
        "            source_file: Name of the source file\n",
        "            auto_approve: If True, automatically approve all generated content\n",
        "\n",
        "        Returns:\n",
        "            job_id: The ID of the created job\n",
        "        \"\"\"\n",
        "        # Create job\n",
        "        job_id = self.create_job(source_file)\n",
        "\n",
        "        print(\"\\n=== Step 1: Parsing Data ===\")\n",
        "        parsed_data = self.data_parser.parse_csv(source_data)\n",
        "        print(f\"Parsed {len(parsed_data)} variables\")\n",
        "\n",
        "        print(\"\\n=== Step 2: Technical Analysis ===\")\n",
        "        analyzed_data = self.technical_analyzer.analyze(parsed_data)\n",
        "        print(f\"Analyzed {len(analyzed_data)} variables\")\n",
        "\n",
        "        # Check for clarifications needed\n",
        "        needs_clarification = [v for v in analyzed_data if v.get('needs_clarification', False)]\n",
        "        if needs_clarification:\n",
        "            print(f\"\\nâš ï¸  {len(needs_clarification)} variables need clarification\")\n",
        "            for var in needs_clarification:\n",
        "                # Add to review queue\n",
        "                item = ReviewItem(\n",
        "                    job_id=job_id,\n",
        "                    source_agent=\"TechnicalAnalyzerAgent\",\n",
        "                    source_data=json.dumps(var),\n",
        "                    generated_content=var.get('clarification_question', 'Needs clarification'),\n",
        "                    status=ReviewStatus.NEEDS_CLARIFICATION\n",
        "                )\n",
        "                self.review_queue.add_item(item)\n",
        "\n",
        "        print(\"\\n=== Step 3: Domain Ontology Mapping ===\")\n",
        "        enriched_data = []\n",
        "        for i, var in enumerate(analyzed_data):\n",
        "            if not var.get('needs_clarification', False):\n",
        "                print(f\"Mapping variable {i+1}/{len(analyzed_data)}: {var.get('variable_name', 'unknown')}\")\n",
        "                enriched = self.domain_ontology.map_ontologies(var)\n",
        "                enriched_data.append(enriched)\n",
        "\n",
        "        print(f\"\\nEnriched {len(enriched_data)} variables with ontology mappings\")\n",
        "\n",
        "        print(\"\\n=== Step 4: Plain Language Documentation ===\")\n",
        "        for i, var in enumerate(enriched_data):\n",
        "            print(f\"Documenting variable {i+1}/{len(enriched_data)}: {var.get('variable_name', 'unknown')}\")\n",
        "            documentation = self.plain_language.document_variable(var)\n",
        "\n",
        "            # Add to review queue\n",
        "            item = ReviewItem(\n",
        "                job_id=job_id,\n",
        "                source_agent=\"PlainLanguageAgent\",\n",
        "                source_data=json.dumps(var),\n",
        "                generated_content=documentation,\n",
        "                status=ReviewStatus.PENDING\n",
        "            )\n",
        "            item_id = self.review_queue.add_item(item)\n",
        "\n",
        "            # Auto-approve if requested\n",
        "            if auto_approve:\n",
        "                self.review_queue.approve_item(item_id)\n",
        "\n",
        "        print(f\"\\nâœ“ Job {job_id} processing complete\")\n",
        "        print(f\"  - {len(enriched_data)} items ready for review\")\n",
        "        if needs_clarification:\n",
        "            print(f\"  - {len(needs_clarification)} items need clarification\")\n",
        "\n",
        "        return job_id\n",
        "\n",
        "    def finalize_documentation(self, job_id: str, output_file: str = \"documentation.md\") -> str:\n",
        "        \"\"\"Assemble and save final documentation.\"\"\"\n",
        "        print(f\"\\n=== Assembling Final Documentation ===\")\n",
        "        documentation = self.assembler.assemble(job_id)\n",
        "\n",
        "        # Save to file\n",
        "        with open(output_file, 'w') as f:\n",
        "            f.write(documentation)\n",
        "\n",
        "        print(f\"âœ“ Documentation saved to {output_file}\")\n",
        "\n",
        "        # Update job status\n",
        "        query = \"UPDATE Jobs SET status = 'Completed' WHERE job_id = ?\"\n",
        "        self.db.execute_update(query, (job_id,))\n",
        "\n",
        "        return documentation"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:44.96551Z",
          "iopub.execute_input": "2025-11-15T23:44:44.965841Z",
          "iopub.status.idle": "2025-11-15T23:44:44.98152Z",
          "shell.execute_reply.started": "2025-11-15T23:44:44.965817Z",
          "shell.execute_reply": "2025-11-15T23:44:44.980568Z"
        },
        "id": "vmmbmWYe85Ox"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class DocumentationAssemblerAgent(BaseAgent):\n",
        "    \"\"\"Agent for assembling final documentation from approved items.\"\"\"\n",
        "\n",
        "    def __init__(self, review_queue: ReviewQueueManager, config: APIConfig = None):\n",
        "        system_prompt = \"\"\"\n",
        "You are a DocumentationAssemblerAgent specialized in creating comprehensive,\n",
        "well-structured data documentation.\n",
        "\n",
        "Your task:\n",
        "1. Compile all approved variable documentation into a cohesive document\n",
        "2. Add a table of contents\n",
        "3. Include metadata (generation date, source file, etc.)\n",
        "4. Organize by logical groupings if applicable\n",
        "5. Ensure consistent formatting throughout\n",
        "\n",
        "Output: A complete Markdown document ready for publication.\n",
        "\"\"\"\n",
        "        super().__init__(\"DocumentationAssemblerAgent\", system_prompt, config)\n",
        "        self.review_queue = review_queue\n",
        "\n",
        "    def assemble(self, job_id: str) -> str:\n",
        "        \"\"\"Assemble final documentation from approved review items.\"\"\"\n",
        "        approved_items = self.review_queue.get_approved_items(job_id)\n",
        "\n",
        "        if not approved_items:\n",
        "            return \"# No approved documentation found for this job.\"\n",
        "\n",
        "        # Build document\n",
        "        doc_parts = [\n",
        "            \"# Healthcare Data Documentation\",\n",
        "            f\"\\n**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "            f\"**Job ID:** {job_id}\",\n",
        "            \"\\n---\\n\"\n",
        "        ]\n",
        "\n",
        "        # Add table of contents\n",
        "        doc_parts.append(\"## Table of Contents\\n\")\n",
        "        for i, item in enumerate(approved_items, 1):\n",
        "            # Extract variable name from content if possible\n",
        "            content = item.approved_content\n",
        "            if \"## Variable:\" in content:\n",
        "                var_name = content.split(\"## Variable:\")[1].split(\"\\n\")[0].strip()\n",
        "                doc_parts.append(f\"{i}. [{var_name}](#{var_name.lower().replace(' ', '-')})\")\n",
        "\n",
        "        doc_parts.append(\"\\n---\\n\")\n",
        "\n",
        "        # Add all approved content\n",
        "        for item in approved_items:\n",
        "            doc_parts.append(item.approved_content)\n",
        "            doc_parts.append(\"\\n---\\n\")\n",
        "\n",
        "        return \"\\n\".join(doc_parts)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:44:50.594805Z",
          "iopub.execute_input": "2025-11-15T23:44:50.595092Z",
          "iopub.status.idle": "2025-11-15T23:44:50.602911Z",
          "shell.execute_reply.started": "2025-11-15T23:44:50.595072Z",
          "shell.execute_reply": "2025-11-15T23:44:50.601742Z"
        },
        "id": "f1MLVWB785Oy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Orchestrator - Agent Workflow Management\n",
        "\n",
        "The Orchestrator manages the flow of data through the agent pipeline and handles the HITL workflow."
      ],
      "metadata": {
        "id": "vpDHoOjs85Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Summary of Available Examples\n",
        "print(\"=\" * 80)\n",
        "print(\"AVAILABLE EXAMPLE DATA DICTIONARIES\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n1. sample_data_dictionary     - Basic diabetes study (7 variables)\")\n",
        "print(\"2. ehr_data_dictionary        - Electronic Health Records (15 variables)\")\n",
        "print(\"3. omop_data_dictionary       - OMOP Common Data Model (12 variables)\")\n",
        "print(\"4. genomic_data_dictionary    - Genetic/Genomic data (15 variables)\")\n",
        "print(\"5. clinical_trial_dictionary  - Clinical trial data (15 variables)\")\n",
        "print(\"6. imaging_data_dictionary    - Medical imaging data (14 variables)\")\n",
        "print(\"7. pro_data_dictionary        - Patient-reported outcomes (14 variables)\")\n",
        "print(\"8. laboratory_data_dictionary - Lab test results (16 variables)\")\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"\\nðŸ’¡ To use an example, simply pass it to the orchestrator:\")\n",
        "print(\"   job_id = orchestrator.process_data_dictionary(\")\n",
        "print(\"       source_data=ehr_data_dictionary,  # Choose your example\")\n",
        "print(\"       source_file='ehr_data.csv',\")\n",
        "print(\"       auto_approve=True\")\n",
        "print(\"   )\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:45:36.516961Z",
          "iopub.execute_input": "2025-11-15T23:45:36.517271Z",
          "iopub.status.idle": "2025-11-15T23:45:36.525081Z",
          "shell.execute_reply.started": "2025-11-15T23:45:36.51725Z",
          "shell.execute_reply": "2025-11-15T23:45:36.523981Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_s-QZLF85Oy",
        "outputId": "735daf51-b88e-498e-f613-750f6251eaf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "AVAILABLE EXAMPLE DATA DICTIONARIES\n",
            "================================================================================\n",
            "\n",
            "1. sample_data_dictionary     - Basic diabetes study (7 variables)\n",
            "2. ehr_data_dictionary        - Electronic Health Records (15 variables)\n",
            "3. omop_data_dictionary       - OMOP Common Data Model (12 variables)\n",
            "4. genomic_data_dictionary    - Genetic/Genomic data (15 variables)\n",
            "5. clinical_trial_dictionary  - Clinical trial data (15 variables)\n",
            "6. imaging_data_dictionary    - Medical imaging data (14 variables)\n",
            "7. pro_data_dictionary        - Patient-reported outcomes (14 variables)\n",
            "8. laboratory_data_dictionary - Lab test results (16 variables)\n",
            "\n",
            "================================================================================\n",
            "\n",
            "ðŸ’¡ To use an example, simply pass it to the orchestrator:\n",
            "   job_id = orchestrator.process_data_dictionary(\n",
            "       source_data=ehr_data_dictionary,  # Choose your example\n",
            "       source_file='ehr_data.csv',\n",
            "       auto_approve=True\n",
            "   )\n",
            "================================================================================\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Example 7: Laboratory Test Results\n",
        "laboratory_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
        "specimen_id,text,Specimen ID,,Unique specimen identifier\n",
        "patient_id,text,Patient ID,,Patient identifier\n",
        "collection_date,date,Collection Date,,Date/time specimen collected\n",
        "test_code,text,Test Code (LOINC),,LOINC code for test\n",
        "test_name,text,Test Name,,Common test name\n",
        "result_value,text,Result Value,,Numeric or categorical result\n",
        "result_numeric,decimal,Numeric Result,,Numeric value if applicable\n",
        "result_unit,text,Unit of Measure (UCUM),,UCUM unit code\n",
        "reference_low,decimal,Reference Range Lower,,Normal range lower bound\n",
        "reference_high,decimal,Reference Range Upper,,Normal range upper bound\n",
        "abnormal_flag,radio,Abnormal Flag,\"N, Normal | L, Low | H, High | LL, Critically Low | HH, Critically High\",Interpretation\n",
        "specimen_type,radio,Specimen Type,\"1, Blood | 2, Urine | 3, CSF | 4, Other\",Type of biospecimen\n",
        "lab_id,text,Laboratory ID,,Performing lab identifier\n",
        "method,text,Test Method,,Analytical method used\n",
        "verified_by,text,Verified By,,Lab technician ID\n",
        "loinc_code,text,LOINC Code,,Full LOINC identifier\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ Laboratory Data Dictionary loaded\")\n",
        "print(f\"  Variables: {len(laboratory_data_dictionary.split(chr(10))) - 1}\")\n",
        "print(\"  Note: Uses LOINC and UCUM standards\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:45:48.629596Z",
          "iopub.execute_input": "2025-11-15T23:45:48.629878Z",
          "iopub.status.idle": "2025-11-15T23:45:48.635699Z",
          "shell.execute_reply.started": "2025-11-15T23:45:48.629859Z",
          "shell.execute_reply": "2025-11-15T23:45:48.634657Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7cF1ri385Oy",
        "outputId": "f9d6efd5-77b6-4458-875b-540604eb48ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Laboratory Data Dictionary loaded\n",
            "  Variables: 17\n",
            "  Note: Uses LOINC and UCUM standards\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Example 6: Patient-Reported Outcomes (PRO)\n",
        "pro_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
        "participant_id,text,Participant ID,,Study participant identifier\n",
        "survey_date,date,Survey Completion Date,,Date PRO completed\n",
        "survey_type,radio,Survey Type,\"1, Baseline | 2, Follow-up | 3, Final\",Assessment timepoint\n",
        "phq9_total,integer,PHQ-9 Total Score,,\"0-27, depression severity\"\n",
        "phq9_q1,radio,Little interest or pleasure,\"0, Not at all | 1, Several days | 2, More than half | 3, Nearly every day\",Over last 2 weeks\n",
        "phq9_q2,radio,Feeling down or depressed,\"0, Not at all | 1, Several days | 2, More than half | 3, Nearly every day\",Over last 2 weeks\n",
        "gad7_total,integer,GAD-7 Total Score,,\"0-21, anxiety severity\"\n",
        "gad7_q1,radio,Feeling nervous/anxious,\"0, Not at all | 1, Several days | 2, More than half | 3, Nearly every day\",Over last 2 weeks\n",
        "pain_severity,radio,Pain Severity (0-10),\"0, None | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10, Worst\",Numeric rating scale\n",
        "pain_interference,radio,Pain Interference with Activities,\"1, Not at all | 2, A little bit | 3, Somewhat | 4, Quite a bit | 5, Very much\",PROMIS scale\n",
        "fatigue_score,integer,PROMIS Fatigue T-Score,,\"20-80, normalized T-score\"\n",
        "sleep_quality,radio,Sleep Quality,\"1, Very poor | 2, Poor | 3, Fair | 4, Good | 5, Very good\",PSQI component\n",
        "qol_physical,decimal,Physical QOL Domain,,\"0-100, SF-36\"\n",
        "qol_mental,decimal,Mental QOL Domain,,\"0-100, SF-36\"\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ Patient-Reported Outcomes Dictionary loaded\")\n",
        "print(f\"  Variables: {len(pro_data_dictionary.split(chr(10))) - 1}\")\n",
        "print(\"  Note: Includes PHQ-9, GAD-7, PROMIS, and SF-36 instruments\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:45:53.108636Z",
          "iopub.execute_input": "2025-11-15T23:45:53.109479Z",
          "iopub.status.idle": "2025-11-15T23:45:53.115374Z",
          "shell.execute_reply.started": "2025-11-15T23:45:53.109448Z",
          "shell.execute_reply": "2025-11-15T23:45:53.114453Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84WzVUxc85Oz",
        "outputId": "a163bf31-8b1a-44dc-dd52-4d33a6dbcb62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Patient-Reported Outcomes Dictionary loaded\n",
            "  Variables: 15\n",
            "  Note: Includes PHQ-9, GAD-7, PROMIS, and SF-36 instruments\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Example 5: Medical Imaging Data (DICOM-based)\n",
        "imaging_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
        "accession_number,text,Accession Number,,Unique exam identifier\n",
        "patient_id,text,Patient ID,,De-identified patient ID\n",
        "study_date,date,Study Date,,Date imaging was performed\n",
        "modality,radio,Imaging Modality,\"CT, MRI, PET, US, XR\",Type of scan\n",
        "body_region,text,Body Region (RadLex),,\"Chest, Abdomen, Brain, etc.\"\n",
        "protocol,text,Scan Protocol,,Specific imaging protocol used\n",
        "slice_thickness,decimal,Slice Thickness (mm),,For CT/MRI\n",
        "contrast_used,yesno,Contrast Agent Used,\"0, No | 1, Yes\",IV contrast administration\n",
        "dose,decimal,Radiation Dose (mGy),,For CT/XR only\n",
        "finding_present,yesno,Pathologic Finding,\"0, No | 1, Yes\",Any abnormality detected\n",
        "finding_type,text,Finding Type,,Description of pathology\n",
        "lesion_size,decimal,Lesion Size (mm),,Maximum diameter if applicable\n",
        "radiologist_id,text,Interpreting Radiologist,,Reader ID\n",
        "dicom_series_uid,text,DICOM Series Instance UID,,Unique series identifier\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ Imaging Data Dictionary loaded\")\n",
        "print(f\"  Variables: {len(imaging_data_dictionary.split(chr(10))) - 1}\")\n",
        "print(\"  Note: Based on DICOM and RadLex standards\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:45:57.029315Z",
          "iopub.execute_input": "2025-11-15T23:45:57.02964Z",
          "iopub.status.idle": "2025-11-15T23:45:57.036069Z",
          "shell.execute_reply.started": "2025-11-15T23:45:57.029618Z",
          "shell.execute_reply": "2025-11-15T23:45:57.035124Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMeescQa85Oz",
        "outputId": "4fe61902-71d4-4235-a1ff-3f2079167209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Imaging Data Dictionary loaded\n",
            "  Variables: 15\n",
            "  Note: Based on DICOM and RadLex standards\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Example 4: Clinical Trial Data (CDISC SDTM-like)\n",
        "clinical_trial_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
        "studyid,text,Study Identifier,,Protocol number\n",
        "usubjid,text,Unique Subject ID,,Unique across all studies\n",
        "subjid,text,Subject ID,,ID within this study\n",
        "siteid,text,Site ID,,Clinical site identifier\n",
        "arm,radio,Treatment Arm,\"1, Placebo | 2, Low Dose | 3, High Dose\",Randomization arm\n",
        "visit,text,Visit Name,,\"Screening, Baseline, Week 4, Week 8, Week 12\"\n",
        "visitnum,integer,Visit Number,,\"1-10\"\n",
        "visitdate,date,Visit Date,,Actual visit date\n",
        "ae_term,text,Adverse Event Term,,MedDRA preferred term\n",
        "ae_severity,radio,AE Severity,\"1, Mild | 2, Moderate | 3, Severe\",Intensity grading\n",
        "ae_serious,yesno,Serious AE,\"0, No | 1, Yes\",SAE flag\n",
        "ae_related,radio,Related to Study Drug,\"0, Unrelated | 1, Unlikely | 2, Possible | 3, Probable | 4, Definite\",Causality assessment\n",
        "efficacy_score,decimal,Primary Efficacy Score,,\"0-100, higher is better\"\n",
        "qol_score,decimal,Quality of Life Score,,\"0-100, SF-36\"\n",
        "compliance,decimal,Medication Compliance (%),,\"0-100, pill count\"\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ Clinical Trial Data Dictionary loaded\")\n",
        "print(f\"  Variables: {len(clinical_trial_dictionary.split(chr(10))) - 1}\")\n",
        "print(\"  Note: Follows CDISC SDTM standards\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:46:01.054485Z",
          "iopub.execute_input": "2025-11-15T23:46:01.054847Z",
          "iopub.status.idle": "2025-11-15T23:46:01.060624Z",
          "shell.execute_reply.started": "2025-11-15T23:46:01.054821Z",
          "shell.execute_reply": "2025-11-15T23:46:01.059615Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDZ5yN3s85Oz",
        "outputId": "c707a071-b5a5-48f5-e81f-2bc16d77ffcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Clinical Trial Data Dictionary loaded\n",
            "  Variables: 16\n",
            "  Note: Follows CDISC SDTM standards\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Example 3: Genomic/Genetic Data\n",
        "genomic_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
        "sample_id,text,Sample ID,,Unique biospecimen identifier\n",
        "patient_id,text,Patient ID,,De-identified patient identifier\n",
        "gene_symbol,text,Gene Symbol (HGNC),,Official gene symbol from HGNC\n",
        "variant_id,text,Variant ID (dbSNP),,rs number from dbSNP database\n",
        "chromosome,text,Chromosome,,\"1-22, X, Y, MT\"\n",
        "position,integer,Genomic Position (hg38),,Position on reference genome GRCh38\n",
        "ref_allele,text,Reference Allele,,\"A, C, G, T\"\n",
        "alt_allele,text,Alternate Allele,,\"A, C, G, T, or indel\"\n",
        "variant_type,radio,Variant Type,\"1, SNV | 2, Insertion | 3, Deletion | 4, CNV\",Single nucleotide or structural\n",
        "genotype,text,Genotype,,\"0/0, 0/1, 1/1\"\n",
        "read_depth,integer,Read Depth (DP),,Number of reads covering position\n",
        "allele_frequency,decimal,Allele Frequency (AF),,\"0.0-1.0, population frequency\"\n",
        "clinical_significance,radio,Clinical Significance,\"0, Benign | 1, Likely Benign | 2, VUS | 3, Likely Pathogenic | 4, Pathogenic\",ClinVar classification\n",
        "phenotype_association,text,Associated Phenotype,,Disease or trait association\n",
        "transcript_id,text,Transcript ID (Ensembl),,Canonical transcript identifier\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ Genomic Data Dictionary loaded\")\n",
        "print(f\"  Variables: {len(genomic_data_dictionary.split(chr(10))) - 1}\")\n",
        "print(\"  Note: Follows HGNC, dbSNP, and ClinVar standards\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:46:04.737334Z",
          "iopub.execute_input": "2025-11-15T23:46:04.738127Z",
          "iopub.status.idle": "2025-11-15T23:46:04.744348Z",
          "shell.execute_reply.started": "2025-11-15T23:46:04.738092Z",
          "shell.execute_reply": "2025-11-15T23:46:04.74324Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMMpoSbZ85O0",
        "outputId": "d14d1fff-f00b-4ae8-9659-f3a299bb5372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Genomic Data Dictionary loaded\n",
            "  Variables: 16\n",
            "  Note: Follows HGNC, dbSNP, and ClinVar standards\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Example 2: OMOP Common Data Model (CDM) Format\n",
        "omop_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
        "person_id,integer,Person ID,,OMOP person identifier\n",
        "visit_occurrence_id,integer,Visit Occurrence ID,,Foreign key to VISIT_OCCURRENCE\n",
        "measurement_date,date,Measurement Date,,Date of measurement\n",
        "measurement_concept_id,integer,Measurement Concept ID,,OMOP standard concept for measurement type\n",
        "value_as_number,decimal,Numeric Value,,Numeric result value\n",
        "value_as_concept_id,integer,Categorical Value Concept ID,,OMOP concept for categorical results\n",
        "unit_concept_id,integer,Unit Concept ID,,OMOP concept for unit of measure\n",
        "range_low,decimal,Normal Range Lower Bound,,Lower limit of normal range\n",
        "range_high,decimal,Normal Range Upper Bound,,Upper limit of normal range\n",
        "provider_id,integer,Provider ID,,Foreign key to PROVIDER table\n",
        "measurement_source_value,text,Source Value,,Original value from source system\n",
        "measurement_source_concept_id,integer,Source Concept ID,,Concept ID from source vocabulary\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ OMOP CDM Data Dictionary loaded\")\n",
        "print(f\"  Variables: {len(omop_data_dictionary.split(chr(10))) - 1}\")\n",
        "print(\"  Note: Uses OMOP standard concept IDs for interoperability\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:46:08.446783Z",
          "iopub.execute_input": "2025-11-15T23:46:08.447603Z",
          "iopub.status.idle": "2025-11-15T23:46:08.452995Z",
          "shell.execute_reply.started": "2025-11-15T23:46:08.447572Z",
          "shell.execute_reply": "2025-11-15T23:46:08.452105Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nxpc-bg85O0",
        "outputId": "475e60aa-0596-42f5-9523-a3dc8f25f6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ OMOP CDM Data Dictionary loaded\n",
            "  Variables: 13\n",
            "  Note: Uses OMOP standard concept IDs for interoperability\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Example 1: Electronic Health Record (EHR) Data\n",
        "ehr_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
        "mrn,text,Medical Record Number,,Unique patient identifier\n",
        "encounter_id,text,Encounter ID,,Unique visit identifier\n",
        "visit_date,date,Visit Date,,Date of clinical encounter\n",
        "chief_complaint,text,Chief Complaint,,Primary reason for visit\n",
        "dx_code,text,Diagnosis Code (ICD-10),,Primary diagnosis\n",
        "bp_systolic,integer,Systolic BP (mmHg),,\"70-250, sitting position\"\n",
        "bp_diastolic,integer,Diastolic BP (mmHg),,\"40-150, sitting position\"\n",
        "heart_rate,integer,Heart Rate (bpm),,\"40-200\"\n",
        "temperature,decimal,Temperature (F),,\"95.0-106.0\"\n",
        "respiratory_rate,integer,Respiratory Rate (breaths/min),,\"8-40\"\n",
        "oxygen_sat,integer,Oxygen Saturation (%),,\"70-100, room air\"\n",
        "bmi,decimal,Body Mass Index,,Calculated from height/weight\n",
        "smoking_status,radio,Smoking Status,\"0, Never | 1, Former | 2, Current\",From social history\n",
        "medication_count,integer,Number of Active Medications,,Count of current prescriptions\n",
        "lab_ordered,yesno,Labs Ordered,\"0, No | 1, Yes\",Any lab tests ordered this visit\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ EHR Data Dictionary loaded\")\n",
        "print(f\"  Variables: {len(ehr_data_dictionary.split(chr(10))) - 1}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:46:11.885934Z",
          "iopub.execute_input": "2025-11-15T23:46:11.886241Z",
          "iopub.status.idle": "2025-11-15T23:46:11.89198Z",
          "shell.execute_reply.started": "2025-11-15T23:46:11.886187Z",
          "shell.execute_reply": "2025-11-15T23:46:11.890867Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cb-VSsO85O1",
        "outputId": "bd88bf48-58b2-4f77-ffc8-6a4ccda2a1b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ EHR Data Dictionary loaded\n",
            "  Variables: 16\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“š Example Data Dictionaries by Healthcare Domain\n",
        "\n",
        "Below are real-world examples for different healthcare data types. Use these to test the system or as templates for your own data."
      ],
      "metadata": {
        "id": "L3XKnDPS85O1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Example Usage and Demonstration\n",
        "\n",
        "Let's demonstrate the system with a sample healthcare data dictionary."
      ],
      "metadata": {
        "id": "z3s3yY4P85O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Sample REDCap-style data dictionary\n",
        "sample_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
        "patient_id,text,Patient ID,,Unique identifier\n",
        "age,integer,Age (years),,Age at enrollment\n",
        "sex,radio,Biological Sex,\"1, Male | 2, Female | 3, Other\",\n",
        "bp_systolic,integer,Systolic Blood Pressure (mmHg),,\n",
        "bp_diastolic,integer,Diastolic Blood Pressure (mmHg),,\n",
        "diagnosis_date,date,Diagnosis Date,,Date of primary diagnosis\n",
        "hba1c,decimal,Hemoglobin A1c (%),,Glycated hemoglobin\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:46:19.164993Z",
          "iopub.execute_input": "2025-11-15T23:46:19.165548Z",
          "iopub.status.idle": "2025-11-15T23:46:19.170169Z",
          "shell.execute_reply.started": "2025-11-15T23:46:19.165511Z",
          "shell.execute_reply": "2025-11-15T23:46:19.169193Z"
        },
        "id": "F6uKIwF185O1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Initialize orchestrator\n",
        "orchestrator = Orchestrator(db)\n",
        "\n",
        "# Create some useful Toons for context\n",
        "print(\"Creating Toons for context management...\")\n",
        "\n",
        "# Helper function to create or update a Toon\n",
        "def create_or_update_toon(name: str, toon_type: ToonType, content: str, metadata: Optional[Dict] = None):\n",
        "    existing_toon = orchestrator.toon_manager.get_toon_by_name(name)\n",
        "    if existing_toon:\n",
        "        orchestrator.toon_manager.update_toon(existing_toon.toon_id, content=content, metadata=metadata)\n",
        "        print(f\"Updated existing Toon '{name}' (ID: {existing_toon.toon_id})\")\n",
        "    else:\n",
        "        orchestrator.toon_manager.create_toon(name, toon_type, content, metadata)\n",
        "\n",
        "# Instruction Toon for OMOP mapping\n",
        "create_or_update_toon(\n",
        "    name=\"OMOP_Mapping_Instructions\",\n",
        "    toon_type=ToonType.INSTRUCTION,\n",
        "    content=\"\"\"When mapping to OMOP CDM:\n",
        "- Blood pressure measurements should map to OMOP concept_id 3004249 (Systolic) and 3012888 (Diastolic)\n",
        "- HbA1c should map to OMOP concept_id 3004410\n",
        "- Age should be stored as an integer in years\n",
        "- Sex should use standard OMOP gender concepts: 8507 (Male), 8532 (Female)\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Design decision Toon\n",
        "create_or_update_toon(\n",
        "    name=\"Project_Design_Notes\",\n",
        "    toon_type=ToonType.DESIGN,\n",
        "    content=\"\"\"This is a diabetes research study collecting baseline clinical measurements.\n",
        "All measurements follow standard clinical protocols. Blood pressure is measured in sitting position\n",
        "after 5 minutes rest. HbA1c measured using DCCT-aligned assay.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\nToons created/updated successfully!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:47:56.638573Z",
          "iopub.execute_input": "2025-11-15T23:47:56.639113Z",
          "iopub.status.idle": "2025-11-15T23:47:56.659011Z",
          "shell.execute_reply.started": "2025-11-15T23:47:56.639087Z",
          "shell.execute_reply": "2025-11-15T23:47:56.657672Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPxSbchc85O1",
        "outputId": "4d0c938d-f2c3-47fe-9751-346f1ca67407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ Orchestrator initialized with 10 req/min limit\n",
            "Creating Toons for context management...\n",
            "Updated Toon ID 1\n",
            "Updated existing Toon 'OMOP_Mapping_Instructions' (ID: 1)\n",
            "Updated Toon ID 2\n",
            "Updated existing Toon 'Project_Design_Notes' (ID: 2)\n",
            "\n",
            "Toons created/updated successfully!\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Inject Toons into relevant agents\n",
        "toons = orchestrator.toon_manager.list_toons()\n",
        "orchestrator.domain_ontology.inject_toons(toons)\n",
        "orchestrator.plain_language.inject_toons(toons)\n",
        "\n",
        "print(f\"Injected {len(toons)} Toons into agent context\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-15T23:54:03.078036Z",
          "iopub.execute_input": "2025-11-15T23:54:03.078407Z",
          "iopub.status.idle": "2025-11-15T23:54:03.092273Z",
          "shell.execute_reply.started": "2025-11-15T23:54:03.078384Z",
          "shell.execute_reply": "2025-11-15T23:54:03.090981Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGIqpFj185O7",
        "outputId": "1456a143-8e90-41d0-9ee9-1d99ac8e86ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected 2 Toons into agent context\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Process the data dictionary\n",
        "# NOTE: Set AUTO_APPROVE_MODE = True only for testing/demo purposes\n",
        "# For normal usage, keep it False to enable manual review workflow\n",
        "AUTO_APPROVE_MODE = False # Change this to True to skip manual review\n",
        "job_id = orchestrator.process_data_dictionary(\n",
        "    source_data=sample_data_dictionary,\n",
        "    source_file=\"diabetes_study_data_dictionary.csv\",\n",
        "    auto_approve=AUTO_APPROVE_MODE\n",
        ")\n",
        "# Provide clear feedback about the mode\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Job ID: {job_id}\")\n",
        "print(f\"Auto-approve mode: {'ENABLED' if AUTO_APPROVE_MODE else 'DISABLED'}\")\n",
        "print(f\"{'='*60}\")\n",
        "if AUTO_APPROVE_MODE:\n",
        "  print(\"\\nâš ï¸  AUTO-APPROVE is ENABLED\")\n",
        "  print(\"   â†’ All items were automatically approved\")\n",
        "  print(\"   â†’ Skip to Cell 48 to generate final documentation\")\n",
        "  print(\"   â†’ Items are in the APPROVED queue, not PENDING\")\n",
        "else:\n",
        "  print(\"\\nâœ“ Manual review mode is ACTIVE\")\n",
        "  print(\"   â†’ Items are awaiting review in PENDING queue\")\n",
        "  print(\"   â†’ Run Cell 44 to see pending items\")\n",
        "  print(\"   â†’ Use Cells 45-47 to review and approve\")\n",
        "  print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9LMntVfu85O7",
        "outputId": "050ad379-c06a-487c-ac76-7f26b35a0bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created job 7b8e60a5eacc for source file: diabetes_study_data_dictionary.csv\n",
            "\n",
            "=== Step 1: Parsing Data ===\n",
            "Parsed 7 variables\n",
            "\n",
            "=== Step 2: Technical Analysis ===\n",
            "Analyzed 7 variables\n",
            "\n",
            "=== Step 3: Domain Ontology Mapping ===\n",
            "Mapping variable 1/7: patient_id\n",
            "Mapping variable 2/7: age\n",
            "â±ï¸  Rate limiting: waiting 5.0s...\n",
            "Mapping variable 3/7: sex\n",
            "â±ï¸  Rate limiting: waiting 5.1s...\n",
            "Mapping variable 4/7: systolic_blood_pressure\n",
            "â±ï¸  Rate limiting: waiting 4.9s...\n",
            "Mapping variable 5/7: diastolic_blood_pressure\n",
            "â±ï¸  Rate limiting: waiting 4.9s...\n",
            "Mapping variable 6/7: diagnosis_date\n",
            "â±ï¸  Rate limiting: waiting 5.1s...\n",
            "Mapping variable 7/7: hba1c\n",
            "â±ï¸  Rate limiting: waiting 5.1s...\n",
            "\n",
            "Enriched 7 variables with ontology mappings\n",
            "\n",
            "=== Step 4: Plain Language Documentation ===\n",
            "Documenting variable 1/7: patient_id\n",
            "Documenting variable 2/7: age\n",
            "â±ï¸  Rate limiting: waiting 4.7s...\n",
            "Documenting variable 3/7: sex\n",
            "â±ï¸  Rate limiting: waiting 4.7s...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash-exp:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 178.39ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸  Rate limit hit. Waiting 6.0s before retry 1/3...\n",
            "Documenting variable 4/7: systolic_blood_pressure\n",
            "â±ï¸  Rate limiting: waiting 4.9s...\n",
            "Documenting variable 5/7: diastolic_blood_pressure\n",
            "â±ï¸  Rate limiting: waiting 4.3s...\n",
            "Documenting variable 6/7: diagnosis_date\n",
            "â±ï¸  Rate limiting: waiting 4.1s...\n",
            "Documenting variable 7/7: hba1c\n",
            "â±ï¸  Rate limiting: waiting 4.8s...\n",
            "\n",
            "âœ“ Job 7b8e60a5eacc processing complete\n",
            "  - 7 items ready for review\n",
            "\n",
            "============================================================\n",
            "Job ID: 7b8e60a5eacc\n",
            "Auto-approve mode: DISABLED\n",
            "============================================================\n",
            "\n",
            "âœ“ Manual review mode is ACTIVE\n",
            "   â†’ Items are awaiting review in PENDING queue\n",
            "   â†’ Run Cell 44 to see pending items\n",
            "   â†’ Use Cells 45-47 to review and approve\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Review pending items (requires auto_approve=False in previous cell)\n",
        "# This cell validates that job_id exists and provides detailed status info\n",
        "# Validate job_id exists\n",
        "if 'job_id' not in locals() and 'job_id' not in globals():\n",
        "  print(\"âš ï¸ ERROR: job_id variable not found!\")\n",
        "  print(\"   Please run Cell 43 first to create a job.\")\n",
        "  pending_items = []\n",
        "else:\n",
        "  print(f\"Checking review queue for job: {job_id}\\n\")\n",
        "  # Get pending items\n",
        "  pending_items = orchestrator.review_queue.get_pending_items(job_id)\n",
        "  # Also check total items and status distribution\n",
        "  all_items_result = db.execute_query(\n",
        "        \"SELECT COUNT(*) as count FROM ReviewQueue WHERE job_id = ?\",\n",
        "        (job_id,)\n",
        "    )\n",
        "  total_items = all_items_result[0]['count'] if all_items_result else 0\n",
        "\n",
        "  status_breakdown = []\n",
        "  if total_items > 0:\n",
        "    status_breakdown = db.execute_query(\"\"\"\n",
        "        SELECT status, COUNT(*) as count\n",
        "        FROM ReviewQueue\n",
        "        WHERE job_id = ?\n",
        "        GROUP BY status\n",
        "    \"\"\", (job_id,))\n",
        "  # Display results\n",
        "  print(f\"{'='*60}\")\n",
        "  print(f\"Review Queue Status for Job: {job_id}\")\n",
        "  print(f\"{'='*60}\")\n",
        "  print(f\"Total items in job: {total_items}\")\n",
        "  print(f\"Pending review items: {len(pending_items)}\\n\")\n",
        "  if status_breakdown:\n",
        "    print(\"Status breakdown:\")\n",
        "    for row in status_breakdown:\n",
        "      print(f\"  {row['status']}: {row['count']} items\")\n",
        "      print(f\"{'='*60}\\n\")\n",
        "      # Provide guidance based on what we found\n",
        "      if total_items == 0:\n",
        "        print(\"âš ï¸ No items found for this job!\")\n",
        "        print(\"   The job may have failed or no items were created.\")\n",
        "      elif len(pending_items) == 0 and total_items > 0:\n",
        "        print(\"â„¹ï¸  All items have been processed (no pending reviews)\")\n",
        "        print(\"   This happens when:\")\n",
        "        print(\"   â€¢ auto_approve=True was used (items auto-approved)\")\n",
        "        print(\"   â€¢ Items were manually approved/rejected\")\n",
        "        print(\"\\n   To review approved items, run:\")\n",
        "        print(\"   approved_items = orchestrator.review_queue.get_approved_items(job_id)\")\n",
        "      elif pending_items:\n",
        "        print(f\"âœ“ Found {len(pending_items)} items awaiting review\")\n",
        "        print(\"   Starting interactive review process...\")\n",
        "\n",
        "        # Interactive review loop\n",
        "        for item in pending_items:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"REVIEW ITEM {item.item_id} (Source: {item.source_agent})\")\n",
        "            print(f\"{'='*80}\")\n",
        "            print(\"\\n--- GENERATED CONTENT ---\\n\")\n",
        "            print(item.generated_content)\n",
        "            print(\"\\n---------------------------\\n\")\n",
        "\n",
        "            action = input(\"Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): \").lower().strip()\n",
        "\n",
        "            if action == 'a':\n",
        "                orchestrator.review_queue.approve_item(item.item_id)\n",
        "                print(f\"Item {item.item_id} approved.\")\n",
        "            elif action == 'e':\n",
        "                edited_content = input(\"Enter edited content (leave blank to use original): \")\n",
        "                if not edited_content.strip():\n",
        "                    edited_content = item.generated_content\n",
        "                orchestrator.review_queue.approve_item(item.item_id, edited_content)\n",
        "                print(f\"Item {item.item_id} approved with edits.\")\n",
        "            elif action == 'r':\n",
        "                feedback = input(\"Enter rejection feedback: \")\n",
        "                orchestrator.review_queue.reject_item(item.item_id, feedback)\n",
        "                print(f\"Item {item.item_id} rejected.\")\n",
        "            elif action == 's':\n",
        "                clarification_response = input(\"Enter clarification response: \")\n",
        "                orchestrator.review_queue.submit_clarification(item.item_id, clarification_response)\n",
        "                print(f\"Item {item.item_id} submitted for clarification.\")\n",
        "            elif action == 'skip':\n",
        "                print(f\"Item {item.item_id} skipped.\")\n",
        "            else:\n",
        "                print(\"Invalid action. Item skipped.\")\n",
        "            print(\"\\n\")\n",
        "        print(\"Interactive review process completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op3Z70sX85O8",
        "outputId": "821ec4bd-bfd0-4859-b929-1d8661620e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking review queue for job: 7b8e60a5eacc\n",
            "\n",
            "============================================================\n",
            "Review Queue Status for Job: 7b8e60a5eacc\n",
            "============================================================\n",
            "Total items in job: 7\n",
            "Pending review items: 6\n",
            "\n",
            "Status breakdown:\n",
            "  Approved: 1 items\n",
            "============================================================\n",
            "\n",
            "âœ“ Found 6 items awaiting review\n",
            "   Starting interactive review process...\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 23 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: age\n",
            "\n",
            "**Description:** Age of the participant at the time of enrollment in the study.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Integer (years)\n",
            "- Cardinality: Required\n",
            "- Valid Values: Non-negative integer representing age in years.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: Age in Years - Age in Years\n",
            "\n",
            "**Clinical Context:** Age is a fundamental demographic variable and an important risk factor for diabetes and related complications.  It is essential for risk stratification, cohort characterization, and adjusting for age-related effects in statistical analyses.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): e\n",
            "Enter edited content (leave blank to use original): \n",
            "âœ“ Approved item 23\n",
            "Item 23 approved with edits.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 24 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: sex\n",
            "\n",
            "**Description:** Patient's biological sex.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Categorical\n",
            "- Cardinality: Required\n",
            "- Valid Values: Male, Female\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 8507 - Male\n",
            "- OMOP: 8532 - Female\n",
            "\n",
            "**Clinical Context:** This variable is fundamental for demographic characterization and is essential for understanding potential sex-specific differences in disease prevalence, treatment response, and outcomes within the diabetes research study.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 24\n",
            "Item 24 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 25 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: systolic_blood_pressure\n",
            "\n",
            "**Description:** Systolic blood pressure is the peak pressure in the arteries when the heart contracts. It is a key vital sign used to assess cardiovascular health.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: numeric\n",
            "- Cardinality: required\n",
            "- Valid Values: Real numbers greater than 0. Units: mmHg.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3004249 - Systolic Blood Pressure\n",
            "- LOINC: 8480-6 - Systolic blood pressure\n",
            "\n",
            "**Clinical Context:** Systolic blood pressure is an important indicator of cardiovascular health and risk. Elevated systolic blood pressure is a major risk factor for heart disease, stroke, and kidney disease. In the context of a diabetes study, monitoring systolic blood pressure is essential as hypertension is a common comorbidity in patients with diabetes. Blood pressure is measured in a sitting position after 5 minutes of rest, following standard clinical protocols.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 25\n",
            "Item 25 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 26 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: diastolic_blood_pressure\n",
            "\n",
            "**Description:** Diastolic blood pressure, measured in mmHg, reflecting the pressure in the arteries when the heart rests between beats.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Numeric (mmHg)\n",
            "- Cardinality: Required (as part of standard blood pressure measurement)\n",
            "- Valid Values: Typically ranges from 60-90 mmHg in healthy adults, but values should be interpreted in the context of the patient's overall health and other risk factors.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3012888 - Diastolic Blood Pressure\n",
            "\n",
            "**Clinical Context:** Diastolic blood pressure is a critical indicator of cardiovascular health. Elevated diastolic blood pressure can increase the risk of heart disease, stroke, and kidney disease, especially in the context of diabetes. This measurement, along with systolic blood pressure, is essential for assessing and managing hypertension. The blood pressure is measured in sitting position after 5 minutes rest according to standard clinical protocols.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 26\n",
            "Item 26 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 27 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: diagnosis_date\n",
            "\n",
            "**Description:** Date on which the patient received a diagnosis.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Date\n",
            "- Cardinality: Required\n",
            "- Valid Values: Standard date format (YYYY-MM-DD)\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- SNOMED CT: 723567004 - Date of diagnosis (attribute)\n",
            "\n",
            "**Clinical Context:** Captures the date when a patient was officially diagnosed, providing a key anchor point for understanding disease progression, treatment timelines, and overall health history.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 27\n",
            "Item 27 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 28 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: hba1c\n",
            "\n",
            "**Description:** Hemoglobin A1c (HbA1c) is a blood test that reflects average blood sugar levels over the past 2-3 months. It is a key indicator of long-term glycemic control in individuals with diabetes.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Numeric (percentage)\n",
            "- Cardinality: Required\n",
            "- Valid Values: Reported as a percentage (%)\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3004410 - Hemoglobin A1c measurement\n",
            "\n",
            "**Clinical Context:** HbA1c is used to diagnose prediabetes and diabetes, monitor the effectiveness of diabetes treatment plans, and assess the risk of diabetes-related complications. A higher HbA1c indicates poorer blood sugar control and a greater risk of complications such as cardiovascular disease, kidney disease, and nerve damage. The measurement relies on a DCCT-aligned assay per protocol.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 28\n",
            "Item 28 approved.\n",
            "\n",
            "\n",
            "Interactive review process completed.\n",
            "  Pending: 6 items\n",
            "============================================================\n",
            "\n",
            "âœ“ Found 6 items awaiting review\n",
            "   Starting interactive review process...\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 23 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: age\n",
            "\n",
            "**Description:** Age of the participant at the time of enrollment in the study.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Integer (years)\n",
            "- Cardinality: Required\n",
            "- Valid Values: Non-negative integer representing age in years.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: Age in Years - Age in Years\n",
            "\n",
            "**Clinical Context:** Age is a fundamental demographic variable and an important risk factor for diabetes and related complications.  It is essential for risk stratification, cohort characterization, and adjusting for age-related effects in statistical analyses.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 23\n",
            "Item 23 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 24 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: sex\n",
            "\n",
            "**Description:** Patient's biological sex.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Categorical\n",
            "- Cardinality: Required\n",
            "- Valid Values: Male, Female\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 8507 - Male\n",
            "- OMOP: 8532 - Female\n",
            "\n",
            "**Clinical Context:** This variable is fundamental for demographic characterization and is essential for understanding potential sex-specific differences in disease prevalence, treatment response, and outcomes within the diabetes research study.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 24\n",
            "Item 24 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 25 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: systolic_blood_pressure\n",
            "\n",
            "**Description:** Systolic blood pressure is the peak pressure in the arteries when the heart contracts. It is a key vital sign used to assess cardiovascular health.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: numeric\n",
            "- Cardinality: required\n",
            "- Valid Values: Real numbers greater than 0. Units: mmHg.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3004249 - Systolic Blood Pressure\n",
            "- LOINC: 8480-6 - Systolic blood pressure\n",
            "\n",
            "**Clinical Context:** Systolic blood pressure is an important indicator of cardiovascular health and risk. Elevated systolic blood pressure is a major risk factor for heart disease, stroke, and kidney disease. In the context of a diabetes study, monitoring systolic blood pressure is essential as hypertension is a common comorbidity in patients with diabetes. Blood pressure is measured in a sitting position after 5 minutes of rest, following standard clinical protocols.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 25\n",
            "Item 25 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 26 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: diastolic_blood_pressure\n",
            "\n",
            "**Description:** Diastolic blood pressure, measured in mmHg, reflecting the pressure in the arteries when the heart rests between beats.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Numeric (mmHg)\n",
            "- Cardinality: Required (as part of standard blood pressure measurement)\n",
            "- Valid Values: Typically ranges from 60-90 mmHg in healthy adults, but values should be interpreted in the context of the patient's overall health and other risk factors.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3012888 - Diastolic Blood Pressure\n",
            "\n",
            "**Clinical Context:** Diastolic blood pressure is a critical indicator of cardiovascular health. Elevated diastolic blood pressure can increase the risk of heart disease, stroke, and kidney disease, especially in the context of diabetes. This measurement, along with systolic blood pressure, is essential for assessing and managing hypertension. The blood pressure is measured in sitting position after 5 minutes rest according to standard clinical protocols.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 26\n",
            "Item 26 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 27 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: diagnosis_date\n",
            "\n",
            "**Description:** Date on which the patient received a diagnosis.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Date\n",
            "- Cardinality: Required\n",
            "- Valid Values: Standard date format (YYYY-MM-DD)\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- SNOMED CT: 723567004 - Date of diagnosis (attribute)\n",
            "\n",
            "**Clinical Context:** Captures the date when a patient was officially diagnosed, providing a key anchor point for understanding disease progression, treatment timelines, and overall health history.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 27\n",
            "Item 27 approved.\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "REVIEW ITEM 28 (Source: PlainLanguageAgent)\n",
            "================================================================================\n",
            "\n",
            "--- GENERATED CONTENT ---\n",
            "\n",
            "## Variable: hba1c\n",
            "\n",
            "**Description:** Hemoglobin A1c (HbA1c) is a blood test that reflects average blood sugar levels over the past 2-3 months. It is a key indicator of long-term glycemic control in individuals with diabetes.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Numeric (percentage)\n",
            "- Cardinality: Required\n",
            "- Valid Values: Reported as a percentage (%)\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3004410 - Hemoglobin A1c measurement\n",
            "\n",
            "**Clinical Context:** HbA1c is used to diagnose prediabetes and diabetes, monitor the effectiveness of diabetes treatment plans, and assess the risk of diabetes-related complications. A higher HbA1c indicates poorer blood sugar control and a greater risk of complications such as cardiovascular disease, kidney disease, and nerve damage. The measurement relies on a DCCT-aligned assay per protocol.\n",
            "\n",
            "---------------------------\n",
            "\n",
            "Action (a: approve, e: edit & approve, r: reject, s: submit clarification, skip: skip item): a\n",
            "âœ“ Approved item 28\n",
            "Item 28 approved.\n",
            "\n",
            "\n",
            "Interactive review process completed.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Finalize and generate documentation\n",
        "final_documentation = orchestrator.finalize_documentation(\n",
        "    job_id=job_id,\n",
        "    output_file=\"healthcare_data_documentation.md\"\n",
        ")\n",
        "\n",
        "print(\"\\n=== Final Documentation Preview ===\")\n",
        "print(final_documentation[:1000] + \"\\n...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4ZZqUHv85O9",
        "outputId": "83b047b2-e51c-4396-826b-031137521951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Assembling Final Documentation ===\n",
            "âœ“ Documentation saved to healthcare_data_documentation.md\n",
            "\n",
            "=== Final Documentation Preview ===\n",
            "# Healthcare Data Documentation\n",
            "\n",
            "**Generated:** 2025-11-16 00:40:05\n",
            "**Job ID:** 7b8e60a5eacc\n",
            "\n",
            "---\n",
            "\n",
            "## Table of Contents\n",
            "\n",
            "1. [patient_id](#patient_id)\n",
            "2. [age](#age)\n",
            "3. [sex](#sex)\n",
            "4. [systolic_blood_pressure](#systolic_blood_pressure)\n",
            "5. [diastolic_blood_pressure](#diastolic_blood_pressure)\n",
            "6. [diagnosis_date](#diagnosis_date)\n",
            "7. [hba1c](#hba1c)\n",
            "\n",
            "---\n",
            "\n",
            "## Variable: patient_id\n",
            "\n",
            "**Description:** Unique identifier for each patient in the study.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: String\n",
            "- Cardinality: Required\n",
            "- Valid Values: Alphanumeric string, unique within the dataset\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 1145515 - Person Source Value\n",
            "\n",
            "**Clinical Context: [EDITED BY REVIEWER]** This variable is essential for linking patient data across different tables and for tracking individuals throughout the study. It is critical for maintaining patient confidentiality by ensuring that the actual patient identifiers are not directly stored or used in analyses. The OMOP mapping to Person Source \n",
            "...\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Context Management - Working vs Long-Term Memory\n",
        "\n",
        "Demonstration of the memory model and context compaction."
      ],
      "metadata": {
        "id": "zX_cY18L85O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class ContextManager:\n",
        "    \"\"\"Manages working and long-term memory for the ADE system.\"\"\"\n",
        "\n",
        "    def __init__(self, db_manager: DatabaseManager, max_tokens: int = 100000):\n",
        "        self.db = db_manager\n",
        "        self.max_tokens = max_tokens\n",
        "        self.compaction_threshold = int(max_tokens * 0.8)\n",
        "\n",
        "    def estimate_tokens(self, text: str) -> int:\n",
        "        \"\"\"Rough token estimation (1 token â‰ˆ 4 characters).\"\"\"\n",
        "        return len(text) // 4\n",
        "\n",
        "    def get_working_memory(self, job_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"Get current working memory for a job.\"\"\"\n",
        "        # Get active toons\n",
        "        query = \"SELECT state_value FROM SystemState WHERE state_key = ?\"\n",
        "        result = self.db.execute_query(query, (f\"active_toons_{job_id}\",))\n",
        "        active_toon_ids = json.loads(result[0]['state_value']) if result else []\n",
        "\n",
        "        # Get session history\n",
        "        query = \"SELECT * FROM SessionHistory WHERE job_id = ? ORDER BY created_at\"\n",
        "        history_rows = self.db.execute_query(query, (job_id,))\n",
        "\n",
        "        session_history = []\n",
        "        for row in history_rows:\n",
        "            session_history.append({\n",
        "                'role': row['role'],\n",
        "                'content': row['content'],\n",
        "                'timestamp': row['created_at']\n",
        "            })\n",
        "\n",
        "        # Calculate total tokens\n",
        "        total_tokens = sum(self.estimate_tokens(msg['content']) for msg in session_history)\n",
        "\n",
        "        return {\n",
        "            'active_toon_ids': active_toon_ids,\n",
        "            'session_history': session_history,\n",
        "            'total_tokens': total_tokens,\n",
        "            'needs_compaction': total_tokens > self.compaction_threshold\n",
        "        }\n",
        "\n",
        "    def add_to_session_history(self, job_id: str, role: str, content: str):\n",
        "        \"\"\"Add a message to session history.\"\"\"\n",
        "        query = \"\"\"\n",
        "        INSERT INTO SessionHistory (job_id, role, content)\n",
        "        VALUES (?, ?, ?)\n",
        "        \"\"\"\n",
        "        self.db.execute_update(query, (job_id, role, content))\n",
        "\n",
        "    def compact_context(self, job_id: str) -> str:\n",
        "        \"\"\"Compact session history using summarization.\"\"\"\n",
        "        print(\"\\n=== Context Compaction Triggered ===\")\n",
        "\n",
        "        working_memory = self.get_working_memory(job_id)\n",
        "        session_history = working_memory['session_history']\n",
        "\n",
        "        # Build conversation text\n",
        "        conversation = \"\\n\\n\".join([\n",
        "            f\"{msg['role'].upper()}: {msg['content']}\"\n",
        "            for msg in session_history\n",
        "        ])\n",
        "\n",
        "        # Use Gemini to summarize\n",
        "        compactor_prompt = f\"\"\"\n",
        "You are a ContextCompactorAgent. Your task is to create a concise summary of this\n",
        "conversation that preserves all critical information, decisions, and clarifications.\n",
        "\n",
        "Conversation:\n",
        "{conversation}\n",
        "\n",
        "Provide a structured summary that includes:\n",
        "1. Key decisions made\n",
        "2. Important clarifications provided\n",
        "3. Current state of the work\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "        model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
        "        response = model.generate_content(compactor_prompt)\n",
        "        summary = response.text\n",
        "\n",
        "        print(f\"Original tokens: {working_memory['total_tokens']}\")\n",
        "        print(f\"Summary tokens: {self.estimate_tokens(summary)}\")\n",
        "        print(f\"Reduction: {100 * (1 - self.estimate_tokens(summary) / working_memory['total_tokens']):.1f}%\")\n",
        "\n",
        "        # Store summary as a Toon\n",
        "        toon_manager = ToonManager(self.db)\n",
        "        toon_manager.create_toon(\n",
        "            name=f\"Session_Summary_{job_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "            toon_type=ToonType.SUMMARY,\n",
        "            content=summary,\n",
        "            metadata={'job_id': job_id, 'original_tokens': working_memory['total_tokens']}\n",
        "        )\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def clear_context(self, job_id: str):\n",
        "        \"\"\"Clear working memory (flush session history and active toons).\"\"\"\n",
        "        # Note: This doesn't delete from database, just resets the \"active\" state\n",
        "        query = \"UPDATE SystemState SET state_value = '[]' WHERE state_key = ?\"\n",
        "        self.db.execute_update(query, (f\"active_toons_{job_id}\",))\n",
        "\n",
        "        print(f\"Cleared working memory for job {job_id}\")\n",
        "        print(\"Note: Session history preserved in long-term memory (database)\")"
      ],
      "metadata": {
        "id": "nGTMceqF85O9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Demonstrate context management\n",
        "context_manager = ContextManager(db)\n",
        "\n",
        "# Simulate a conversation\n",
        "context_manager.add_to_session_history(job_id, \"user\", \"Please process the diabetes data dictionary\")\n",
        "context_manager.add_to_session_history(job_id, \"assistant\", \"I'll process the data dictionary through the agent pipeline.\")\n",
        "context_manager.add_to_session_history(\n",
        "    job_id,\n",
        "    \"user\",\n",
        "    \"For the HbA1c variable, please note that values above 6.5% indicate diabetes diagnosis.\"\n",
        ")\n",
        "\n",
        "# Check working memory\n",
        "working_memory = context_manager.get_working_memory(job_id)\n",
        "print(f\"\\nWorking Memory Status:\")\n",
        "print(f\"  Total tokens: {working_memory['total_tokens']}\")\n",
        "print(f\"  Needs compaction: {working_memory['needs_compaction']}\")\n",
        "print(f\"  Session messages: {len(working_memory['session_history'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLn2d-UJ85O9",
        "outputId": "0520ae96-5203-4d56-cd1e-6420c571eaba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Working Memory Status:\n",
            "  Total tokens: 92\n",
            "  Needs compaction: False\n",
            "  Session messages: 6\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. System Status and Monitoring"
      ],
      "metadata": {
        "id": "tH3HpVo585O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def display_system_status(db: DatabaseManager):\n",
        "    \"\"\"Display current system status.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ADE SYSTEM STATUS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Jobs\n",
        "    jobs = db.execute_query(\"SELECT * FROM Jobs\")\n",
        "    print(f\"\\nJobs: {len(jobs)}\")\n",
        "    for job in jobs:\n",
        "        print(f\"  [{job['job_id']}] {job['source_file']} - Status: {job['status']}\")\n",
        "\n",
        "    # Toons\n",
        "    toons = db.execute_query(\"SELECT toon_type, COUNT(*) as count FROM Toons GROUP BY toon_type\")\n",
        "    print(f\"\\nToon Library:\")\n",
        "    for toon in toons:\n",
        "        print(f\"  {toon['toon_type']}: {toon['count']}\")\n",
        "\n",
        "    # Review Queue\n",
        "    review_stats = db.execute_query(\n",
        "        \"SELECT status, COUNT(*) as count FROM ReviewQueue GROUP BY status\"\n",
        "    )\n",
        "    print(f\"\\nReview Queue:\")\n",
        "    for stat in review_stats:\n",
        "        print(f\"  {stat['status']}: {stat['count']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "display_system_status(db)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cqRCgNp85O-",
        "outputId": "963bb4ac-10f2-4c9d-d134-9d6c93ed3c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ADE SYSTEM STATUS\n",
            "================================================================================\n",
            "\n",
            "Jobs: 4\n",
            "  [ebb125fa559e] diabetes_study_data_dictionary.csv - Status: Running\n",
            "  [37f922d3a1cd] diabetes_study_data_dictionary.csv - Status: Completed\n",
            "  [a82e335d1a8e] diabetes_study_data_dictionary.csv - Status: Running\n",
            "  [7b8e60a5eacc] diabetes_study_data_dictionary.csv - Status: Completed\n",
            "\n",
            "Toon Library:\n",
            "  Toon_Design: 1\n",
            "  Toon_Instruction: 1\n",
            "\n",
            "Review Queue:\n",
            "  Approved: 7\n",
            "  Pending: 21\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Export and Cleanup"
      ],
      "metadata": {
        "id": "dNy9n6pq85O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Export database for backup\n",
        "import shutil\n",
        "\n",
        "def backup_database(db_path: str, backup_path: str):\n",
        "    \"\"\"Create a backup of the project database.\"\"\"\n",
        "    shutil.copy2(db_path, backup_path)\n",
        "    print(f\"Database backed up to {backup_path}\")\n",
        "\n",
        "# Uncomment to create backup\n",
        "backup_database(\"project.db\", \"project_backup.db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsqZBEvi85O-",
        "outputId": "e0a197d8-af01-4bd5-ff13-0b6129e370bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database backed up to project_backup.db\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# View generated documentation\n",
        "if os.path.exists(\"healthcare_data_documentation.md\"):\n",
        "    with open(\"healthcare_data_documentation.md\", 'r') as f:\n",
        "        print(\"\\n=== Generated Documentation ===\")\n",
        "        print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbgJgizb85O-",
        "outputId": "d45da2df-30ac-4ed1-c747-44c32ec4552c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Generated Documentation ===\n",
            "# Healthcare Data Documentation\n",
            "\n",
            "**Generated:** 2025-11-16 00:40:05\n",
            "**Job ID:** 7b8e60a5eacc\n",
            "\n",
            "---\n",
            "\n",
            "## Table of Contents\n",
            "\n",
            "1. [patient_id](#patient_id)\n",
            "2. [age](#age)\n",
            "3. [sex](#sex)\n",
            "4. [systolic_blood_pressure](#systolic_blood_pressure)\n",
            "5. [diastolic_blood_pressure](#diastolic_blood_pressure)\n",
            "6. [diagnosis_date](#diagnosis_date)\n",
            "7. [hba1c](#hba1c)\n",
            "\n",
            "---\n",
            "\n",
            "## Variable: patient_id\n",
            "\n",
            "**Description:** Unique identifier for each patient in the study.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: String\n",
            "- Cardinality: Required\n",
            "- Valid Values: Alphanumeric string, unique within the dataset\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 1145515 - Person Source Value\n",
            "\n",
            "**Clinical Context: [EDITED BY REVIEWER]** This variable is essential for linking patient data across different tables and for tracking individuals throughout the study. It is critical for maintaining patient confidentiality by ensuring that the actual patient identifiers are not directly stored or used in analyses. The OMOP mapping to Person Source Value indicates that this identifier is the original patient ID from the source data.\n",
            "\n",
            "---\n",
            "\n",
            "## Variable: age\n",
            "\n",
            "**Description:** Age of the participant at the time of enrollment in the study.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Integer (years)\n",
            "- Cardinality: Required\n",
            "- Valid Values: Non-negative integer representing age in years.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: Age in Years - Age in Years\n",
            "\n",
            "**Clinical Context:** Age is a fundamental demographic variable and an important risk factor for diabetes and related complications.  It is essential for risk stratification, cohort characterization, and adjusting for age-related effects in statistical analyses.\n",
            "\n",
            "---\n",
            "\n",
            "## Variable: sex\n",
            "\n",
            "**Description:** Patient's biological sex.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Categorical\n",
            "- Cardinality: Required\n",
            "- Valid Values: Male, Female\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 8507 - Male\n",
            "- OMOP: 8532 - Female\n",
            "\n",
            "**Clinical Context:** This variable is fundamental for demographic characterization and is essential for understanding potential sex-specific differences in disease prevalence, treatment response, and outcomes within the diabetes research study.\n",
            "\n",
            "---\n",
            "\n",
            "## Variable: systolic_blood_pressure\n",
            "\n",
            "**Description:** Systolic blood pressure is the peak pressure in the arteries when the heart contracts. It is a key vital sign used to assess cardiovascular health.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: numeric\n",
            "- Cardinality: required\n",
            "- Valid Values: Real numbers greater than 0. Units: mmHg.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3004249 - Systolic Blood Pressure\n",
            "- LOINC: 8480-6 - Systolic blood pressure\n",
            "\n",
            "**Clinical Context:** Systolic blood pressure is an important indicator of cardiovascular health and risk. Elevated systolic blood pressure is a major risk factor for heart disease, stroke, and kidney disease. In the context of a diabetes study, monitoring systolic blood pressure is essential as hypertension is a common comorbidity in patients with diabetes. Blood pressure is measured in a sitting position after 5 minutes of rest, following standard clinical protocols.\n",
            "\n",
            "---\n",
            "\n",
            "## Variable: diastolic_blood_pressure\n",
            "\n",
            "**Description:** Diastolic blood pressure, measured in mmHg, reflecting the pressure in the arteries when the heart rests between beats.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Numeric (mmHg)\n",
            "- Cardinality: Required (as part of standard blood pressure measurement)\n",
            "- Valid Values: Typically ranges from 60-90 mmHg in healthy adults, but values should be interpreted in the context of the patient's overall health and other risk factors.\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3012888 - Diastolic Blood Pressure\n",
            "\n",
            "**Clinical Context:** Diastolic blood pressure is a critical indicator of cardiovascular health. Elevated diastolic blood pressure can increase the risk of heart disease, stroke, and kidney disease, especially in the context of diabetes. This measurement, along with systolic blood pressure, is essential for assessing and managing hypertension. The blood pressure is measured in sitting position after 5 minutes rest according to standard clinical protocols.\n",
            "\n",
            "---\n",
            "\n",
            "## Variable: diagnosis_date\n",
            "\n",
            "**Description:** Date on which the patient received a diagnosis.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Date\n",
            "- Cardinality: Required\n",
            "- Valid Values: Standard date format (YYYY-MM-DD)\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- SNOMED CT: 723567004 - Date of diagnosis (attribute)\n",
            "\n",
            "**Clinical Context:** Captures the date when a patient was officially diagnosed, providing a key anchor point for understanding disease progression, treatment timelines, and overall health history.\n",
            "\n",
            "---\n",
            "\n",
            "## Variable: hba1c\n",
            "\n",
            "**Description:** Hemoglobin A1c (HbA1c) is a blood test that reflects average blood sugar levels over the past 2-3 months. It is a key indicator of long-term glycemic control in individuals with diabetes.\n",
            "\n",
            "**Technical Details:**\n",
            "- Data Type: Numeric (percentage)\n",
            "- Cardinality: Required\n",
            "- Valid Values: Reported as a percentage (%)\n",
            "\n",
            "**Standard Ontology Mappings:**\n",
            "- OMOP: 3004410 - Hemoglobin A1c measurement\n",
            "\n",
            "**Clinical Context:** HbA1c is used to diagnose prediabetes and diabetes, monitor the effectiveness of diabetes treatment plans, and assess the risk of diabetes-related complications. A higher HbA1c indicates poorer blood sugar control and a greater risk of complications such as cardiovascular disease, kidney disease, and nerve damage. The measurement relies on a DCCT-aligned assay per protocol.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates a complete implementation of the Agent Development Environment (ADE) for Healthcare Data Documentation. Key features:\n",
        "\n",
        "### Implemented Components:\n",
        "1. **SQLite Database** - Full schema with all required tables\n",
        "2. **Toon System** - Context management with 6 Toon types\n",
        "3. **Review Queue** - Complete HITL workflow with status management\n",
        "4. **Core Agents**:\n",
        "   - DataParserAgent\n",
        "   - TechnicalAnalyzerAgent\n",
        "   - DomainOntologyAgent\n",
        "   - PlainLanguageAgent\n",
        "   - DocumentationAssemblerAgent\n",
        "5. **Orchestrator** - Agent workflow management\n",
        "6. **Context Manager** - Working vs long-term memory with compaction\n",
        "\n",
        "### Key Workflows:\n",
        "- Data ingestion and parsing\n",
        "- Technical analysis with clarification requests\n",
        "- Ontology mapping (OMOP, LOINC, SNOMED)\n",
        "- Human-readable documentation generation\n",
        "- Human-in-the-loop review and approval\n",
        "- Context compaction for large sessions\n",
        "\n",
        "### Next Steps:\n",
        "To use this in Kaggle:\n",
        "1. Add your Google Gemini API key as a Kaggle secret named 'GOOGLE_API_KEY'\n",
        "2. Upload your data dictionary files\n",
        "3. Run the notebook cells in order\n",
        "4. Review and approve generated documentation\n",
        "5. Export the final documentation\n",
        "\n",
        "### Extending the System:\n",
        "- Add custom agents for domain-specific processing\n",
        "- Create new Toon types for your use case\n",
        "- Implement additional ontology mappings\n",
        "- Build a web UI using Streamlit or Gradio\n",
        "- Add version control for documentation"
      ],
      "metadata": {
        "id": "4wDLecov85O_"
      }
    }
  ]
}