{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dspacks/rdd_orch/blob/main/ade_healthcare_documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCLD7h50g3XZ"
   },
   "source": [
    "# Agent Development Environment (ADE) for Healthcare Data Documentation\n",
    "\n",
    "**Version 2.0 - November 2025**\n",
    "\n",
    "This notebook implements a production-ready agent development environment using Google's Agent Development Kit (ADK) patterns for healthcare data documentation.\n",
    "\n",
    "## Key Features\n",
    "- **Modern ADK Architecture**: Sessions, memory services, and async patterns\n",
    "- **Toon Notation**: Compact encoding for 40-70% token reduction\n",
    "- **Snippet Manager**: Named context storage for efficient retrieval\n",
    "- **Batch Processing**: Handle large codebooks with automatic chunking\n",
    "- **Human-in-the-Loop (HITL)**: Review workflows with approval/rejection cycles\n",
    "- **Multi-Agent Orchestration**: Specialized agents for parsing, analysis, and documentation\n",
    "- **Observability**: Logging plugins and monitoring capabilities\n",
    "- **Production Deployment**: Vertex AI Agent Engine ready\n",
    "\n",
    "## Architecture Overview\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Input     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Orchestrator \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Review Queue   \u2502\n",
    "\u2502   Data      \u2502     \u2502   (Runner)    \u2502     \u2502    (HITL)       \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                           \u2502\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u25bc             \u25bc\n",
    "              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "              \u2502  Agents  \u2502  \u2502  Snippet \u2502\n",
    "              \u2502          \u2502  \u2502  Manager \u2502\n",
    "              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTSwxyq2g3Xb"
   },
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aRIv6nBg3Xc"
   },
   "outputs": [],
   "source": [
    "# Install required packages! pip install -q google-generativeai google-adk sqlite3 pandas numpy opentelemetry-instrumentation-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qVvEiLRlg3Xc"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from enum import Enum\n",
    "import google.generativeai as genai\n",
    "from dataclasses import dataclass, asdict, field\n",
    "import hashlib\n",
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "\n",
    "# Set up logging for observability\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('ADE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oP6s2hvlg3Xd",
    "outputId": "2ca83702-39c0-425f-e726-abf0e67e0e01"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Gemini API configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Configure Google Gemini API\n",
    "from google.colab import userdata\n",
    "\n",
    "api_key = userdata.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "print(\"\u2713 Gemini API configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PGGUbxog3Xd"
   },
   "source": [
    "## 2. API Configuration and Rate LimitsConfigure rate limiting based on your Gemini API tier for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stgjYCnyg3Xd",
    "outputId": "d997a256-f8cc-482c-ca02-aea0878d4afa"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udcca API Configuration:\n",
      "   Requests/minute: 5\n",
      "   Min delay: 12.0s\n",
      "   Max retries: 5\n",
      "   Base retry delay: 30.0s\n",
      "   Batch size: 7\n",
      "   Model: gemini-2.5-flash-lite\n",
      "   Exponential backoff enabled (2x per retry)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class APIConfig:\n",
    "    \"\"\"Configuration for API rate limits and retry behavior.\"\"\"\n",
    "    requests_per_minute: int = 5\n",
    "    max_retries: int = 3\n",
    "    base_retry_delay: float = 6.0\n",
    "    model_name: str = \"gemini-2.5-flash-lite\"\n",
    "    batch_size: int = 3\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.min_delay = 60.0 / self.requests_per_minute\n",
    "\n",
    "    def get_retry_delay(self, attempt: int) -> float:\n",
    "        \"\"\"Calculate exponential backoff delay for retry attempts.\"\"\"\n",
    "        # Exponential backoff: base_delay * (2 ^ attempt)\n",
    "        return self.base_retry_delay * (2 ** attempt)\n",
    "\n",
    "\n",
    "class APITier:\n",
    "    \"\"\"Predefined API configurations for different Gemini tiers.\"\"\"\n",
    "    FREE = APIConfig(\n",
    "        requests_per_minute=10,\n",
    "        max_retries=3,\n",
    "        base_retry_delay=6.0,\n",
    "        batch_size=7\n",
    "    )\n",
    "\n",
    "    PAYG = APIConfig(\n",
    "        requests_per_minute=360,\n",
    "        max_retries=3,\n",
    "        base_retry_delay=2.0,\n",
    "        batch_size=14\n",
    "    )\n",
    "\n",
    "    ENTERPRISE = APIConfig(\n",
    "        requests_per_minute=1000,\n",
    "        max_retries=2,\n",
    "        base_retry_delay=1.0,\n",
    "        batch_size=28\n",
    "    )\n",
    "\n",
    "    CONSERVATIVE = APIConfig(\n",
    "        requests_per_minute=5,\n",
    "        max_retries=5,\n",
    "        base_retry_delay=30.0,\n",
    "        batch_size=7\n",
    "    )\n",
    "\n",
    "    @staticmethod\n",
    "    def custom(requests_per_minute: int, **kwargs) -> APIConfig:\n",
    "        return APIConfig(requests_per_minute=requests_per_minute, **kwargs)\n",
    "\n",
    "\n",
    "# Set your tier here - use CONSERVATIVE for rate limit issues\n",
    "API_CONFIG = APITier.CONSERVATIVE\n",
    "\n",
    "print(f\"\ud83d\udcca API Configuration:\")\n",
    "print(f\"   Requests/minute: {API_CONFIG.requests_per_minute}\")\n",
    "print(f\"   Min delay: {API_CONFIG.min_delay:.1f}s\")\n",
    "print(f\"   Max retries: {API_CONFIG.max_retries}\")\n",
    "print(f\"   Base retry delay: {API_CONFIG.base_retry_delay}s\")\n",
    "print(f\"   Batch size: {API_CONFIG.batch_size}\")\n",
    "print(f\"   Model: {API_CONFIG.model_name}\")\n",
    "print(f\"   Exponential backoff enabled (2x per retry)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1j0rQiZOg3Xd"
   },
   "source": [
    "## 3. Database Schema and SetupSQLite database provides persistent storage for sessions, memory, and HITL workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhSONmiDg3Xe",
    "outputId": "98c72f99-e6ea-4def-eec2-e3fc3741c95b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Database schema initialized with session and memory support\n"
     ]
    }
   ],
   "source": [
    "class DatabaseManager:\n",
    "    \"\"\"Manages SQLite database operations with session and memory support.\"\"\"\n",
    "\n",
    "    def __init__(self, db_path: str = \"project.db\"):\n",
    "        self.db_path = db_path\n",
    "        self.conn = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Establish database connection.\"\"\"\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        self.conn.row_factory = sqlite3.Row\n",
    "        self.cursor = self.conn.cursor()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close database connection.\"\"\"\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "\n",
    "    def execute_query(self, query: str, params: tuple = ()) -> List[Dict]:\n",
    "        \"\"\"Execute SELECT query and return results.\"\"\"\n",
    "        self.cursor.execute(query, params)\n",
    "        rows = self.cursor.fetchall()\n",
    "        return [dict(row) for row in rows]\n",
    "\n",
    "    def execute_update(self, query: str, params: tuple = ()) -> int:\n",
    "        \"\"\"Execute INSERT/UPDATE/DELETE and return affected row ID.\"\"\"\n",
    "        self.cursor.execute(query, params)\n",
    "        self.conn.commit()\n",
    "        return self.cursor.lastrowid\n",
    "\n",
    "    def initialize_schema(self):\n",
    "        \"\"\"Create all required tables.\"\"\"\n",
    "\n",
    "        # Agents table\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Agents (\n",
    "            agent_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            name TEXT NOT NULL UNIQUE,\n",
    "            system_prompt TEXT NOT NULL,\n",
    "            agent_type TEXT NOT NULL,\n",
    "            config JSON,\n",
    "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # Snippets table - Named context storage\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Snippets (\n",
    "            snippet_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            name TEXT NOT NULL UNIQUE,\n",
    "            snippet_type TEXT NOT NULL CHECK(snippet_type IN (\n",
    "                'Summary', 'Chunk', 'Instruction',\n",
    "                'Version', 'Design', 'Mapping'\n",
    "            )),\n",
    "            content TEXT NOT NULL,\n",
    "            metadata JSON,\n",
    "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # Jobs table with enhanced metadata\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Jobs (\n",
    "            job_id TEXT PRIMARY KEY,\n",
    "            source_file TEXT NOT NULL,\n",
    "            status TEXT NOT NULL DEFAULT 'Running' CHECK(status IN (\n",
    "                'Running', 'Completed', 'Failed', 'Paused'\n",
    "            )),\n",
    "            metadata JSON,\n",
    "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # ReviewQueue table - HITL workflow\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS ReviewQueue (\n",
    "            item_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            job_id TEXT NOT NULL,\n",
    "            status TEXT NOT NULL DEFAULT 'Pending' CHECK(status IN (\n",
    "                'Pending', 'Approved', 'Rejected', 'Needs_Clarification'\n",
    "            )),\n",
    "            source_agent TEXT NOT NULL,\n",
    "            target_agent TEXT,\n",
    "            source_data TEXT NOT NULL,\n",
    "            generated_content TEXT NOT NULL,\n",
    "            approved_content TEXT,\n",
    "            rejection_feedback TEXT,\n",
    "            clarification_response TEXT,\n",
    "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            FOREIGN KEY (job_id) REFERENCES Jobs(job_id)\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # Sessions table - ADK-style session management\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Sessions (\n",
    "            session_id TEXT PRIMARY KEY,\n",
    "            job_id TEXT NOT NULL,\n",
    "            user_id TEXT NOT NULL,\n",
    "            state JSON DEFAULT '{}',\n",
    "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            FOREIGN KEY (job_id) REFERENCES Jobs(job_id)\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # SessionHistory - Conversation history\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS SessionHistory (\n",
    "            history_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            session_id TEXT NOT NULL,\n",
    "            job_id TEXT NOT NULL,\n",
    "            role TEXT NOT NULL CHECK(role IN ('user', 'assistant', 'system', 'tool')),\n",
    "            content TEXT NOT NULL,\n",
    "            metadata JSON,\n",
    "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "            FOREIGN KEY (session_id) REFERENCES Sessions(session_id),\n",
    "            FOREIGN KEY (job_id) REFERENCES Jobs(job_id)\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # Memory table - Long-term knowledge storage\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Memory (\n",
    "            memory_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            user_id TEXT NOT NULL,\n",
    "            content TEXT NOT NULL,\n",
    "            embedding JSON,\n",
    "            metadata JSON,\n",
    "            created_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        # SystemState table\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS SystemState (\n",
    "            state_key TEXT PRIMARY KEY,\n",
    "            state_value TEXT NOT NULL,\n",
    "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        self.conn.commit()\n",
    "        print(\"\u2713 Database schema initialized with session and memory support\")\n",
    "\n",
    "# Initialize database\n",
    "db = DatabaseManager(\"project.db\")\n",
    "db.connect()\n",
    "db.initialize_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH6YgRNZg3Xe"
   },
   "source": [
    "## 4. Toon Notation Encoding\n",
    "\n",
    "Compact data encoding that reduces token usage by 40-70% while preserving all information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RH1gZh_bg3Xf",
    "outputId": "42128e41-cc31-498b-b1d5-1bf58ea795e0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 ToonNotation encoder loaded\n"
     ]
    }
   ],
   "source": [
    "class ToonNotation:\n",
    "    \"\"\"\n",
    "    Compact notation for encoding data to maximize context efficiency.\n",
    "    Reduces token usage by 40-70% compared to standard JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _needs_quoting(value: str) -> bool:\n",
    "        \"\"\"Check if a string value needs quotes to avoid ambiguity.\"\"\"\n",
    "        if not isinstance(value, str):\n",
    "            return False\n",
    "        if ',' in value or ':' in value:\n",
    "            return True\n",
    "        if value.lower() in ['true', 'false', 'null', 'none']:\n",
    "            return True\n",
    "        try:\n",
    "            float(value)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_tabular(arr: list) -> bool:\n",
    "        \"\"\"Check if array is uniform objects (tabular format).\"\"\"\n",
    "        if not arr or not isinstance(arr[0], dict):\n",
    "            return False\n",
    "        keys = set(arr[0].keys())\n",
    "        return all(isinstance(item, dict) and set(item.keys()) == keys for item in arr)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(data: Any, indent: int = 0) -> str:\n",
    "        \"\"\"Encode data in Toon notation for token-efficient context.\"\"\"\n",
    "        prefix = \"  \" * indent\n",
    "\n",
    "        if data is None:\n",
    "            return \"null\"\n",
    "        if isinstance(data, bool):\n",
    "            return str(data).lower()\n",
    "        if isinstance(data, (int, float)):\n",
    "            return str(data)\n",
    "        if isinstance(data, str):\n",
    "            return f'\"{data}\"' if ToonNotation._needs_quoting(data) else data\n",
    "\n",
    "        if isinstance(data, dict) and not data:\n",
    "            return \"\"\n",
    "        if isinstance(data, list) and not data:\n",
    "            return \"[0]:\"\n",
    "\n",
    "        if isinstance(data, list):\n",
    "            if ToonNotation._is_tabular(data):\n",
    "                keys = list(data[0].keys())\n",
    "                header = f\"[{len(data)}]{{{','.join(keys)}}}:\"\n",
    "                rows = []\n",
    "                for item in data:\n",
    "                    row_vals = [str(item[k]) if item[k] is not None else \"null\" for k in keys]\n",
    "                    rows.append(\"  \" + \",\".join(row_vals))\n",
    "                return header + \"\\n\" + \"\\n\".join(rows)\n",
    "            else:\n",
    "                items = [ToonNotation.encode(item, indent + 1) for item in data]\n",
    "                return f\"[{len(data)}]: \" + \",\".join(items)\n",
    "\n",
    "        if isinstance(data, dict):\n",
    "            lines = []\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, dict):\n",
    "                    lines.append(f\"{prefix}{key}:\")\n",
    "                    lines.append(ToonNotation.encode(value, indent + 1))\n",
    "                elif isinstance(value, list) and ToonNotation._is_tabular(value):\n",
    "                    encoded = ToonNotation.encode(value, indent)\n",
    "                    lines.append(f\"{prefix}{key}{encoded}\")\n",
    "                else:\n",
    "                    encoded = ToonNotation.encode(value, indent)\n",
    "                    lines.append(f\"{prefix}{key}: {encoded}\")\n",
    "            return \"\\n\".join(lines)\n",
    "\n",
    "        return str(data)\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(toon_str: str) -> Any:\n",
    "        \"\"\"Decode Toon notation back to Python objects (basic implementation).\"\"\"\n",
    "        pass\n",
    "\n",
    "print(\"\u2713 ToonNotation encoder loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ijI-Y3zg3Xf",
    "outputId": "e7a5a557-cf8b-434b-ee90-ebb7f85a0c5f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 SnippetManager loaded with extended snippet types:\n",
      "   Core types: Summary, Chunk, Instruction, Version, Design, Mapping\n",
      "   Extended types: Convention, Changelog, Instrument, Segment, Glossary\n"
     ]
    }
   ],
   "source": [
    "class SnippetType(Enum):\n",
    "    \"\"\"Enumeration of snippet types for context management.\"\"\"\n",
    "    SUMMARY = \"Summary\"\n",
    "    CHUNK = \"Chunk\"\n",
    "    INSTRUCTION = \"Instruction\"\n",
    "    VERSION = \"Version\"\n",
    "    DESIGN = \"Design\"\n",
    "    MAPPING = \"Mapping\"\n",
    "    # Extended snippet types for new agents\n",
    "    CONVENTION = \"Convention\"        # Data naming conventions and standards\n",
    "    CHANGELOG = \"Changelog\"          # Version history and change logs\n",
    "    INSTRUMENT = \"Instrument\"        # Higher-level instrument documentation\n",
    "    SEGMENT = \"Segment\"              # Codebook segment documentation\n",
    "    GLOSSARY = \"Glossary\"            # Conventions glossary\n",
    "\n",
    "@dataclass\n",
    "class Snippet:\n",
    "    \"\"\"Represents a named context snippet.\"\"\"\n",
    "    name: str\n",
    "    snippet_type: SnippetType\n",
    "    content: str\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "    snippet_id: Optional[int] = None\n",
    "\n",
    "class SnippetManager:\n",
    "    \"\"\"Manages the Snippet Library for named context storage and retrieval.\"\"\"\n",
    "\n",
    "    def __init__(self, db_manager: DatabaseManager):\n",
    "        self.db = db_manager\n",
    "        self._update_schema_for_new_types()\n",
    "\n",
    "    def _update_schema_for_new_types(self):\n",
    "        \"\"\"Update database schema to support new snippet types.\"\"\"\n",
    "        # Drop and recreate with expanded types\n",
    "        try:\n",
    "            self.db.cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS Snippets_New (\n",
    "                snippet_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                name TEXT NOT NULL UNIQUE,\n",
    "                snippet_type TEXT NOT NULL CHECK(snippet_type IN (\n",
    "                    'Summary', 'Chunk', 'Instruction', 'Version', 'Design', 'Mapping',\n",
    "                    'Convention', 'Changelog', 'Instrument', 'Segment', 'Glossary'\n",
    "                )),\n",
    "                content TEXT NOT NULL,\n",
    "                metadata JSON,\n",
    "                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "            \"\"\")\n",
    "\n",
    "            # Check if old table exists and migrate data\n",
    "            self.db.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='Snippets'\")\n",
    "            if self.db.cursor.fetchone():\n",
    "                # Copy existing data\n",
    "                self.db.cursor.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO Snippets_New\n",
    "                    SELECT * FROM Snippets\n",
    "                \"\"\")\n",
    "                # Drop old table\n",
    "                self.db.cursor.execute(\"DROP TABLE Snippets\")\n",
    "                # Rename new table\n",
    "                self.db.cursor.execute(\"ALTER TABLE Snippets_New RENAME TO Snippets\")\n",
    "            else:\n",
    "                # Just rename if no old table\n",
    "                self.db.cursor.execute(\"ALTER TABLE Snippets_New RENAME TO Snippets\")\n",
    "\n",
    "            self.db.conn.commit()\n",
    "        except Exception as e:\n",
    "            # Table might already have the new schema\n",
    "            logger.debug(f\"Schema update note: {e}\")\n",
    "\n",
    "    def create_snippet(self, name: str, snippet_type: SnippetType, content: str,\n",
    "                      metadata: Optional[Dict] = None) -> int:\n",
    "        \"\"\"Create a new snippet in the library.\"\"\"\n",
    "        query = \"\"\"\n",
    "        INSERT INTO Snippets (name, snippet_type, content, metadata)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        metadata_json = json.dumps(metadata) if metadata else None\n",
    "        snippet_id = self.db.execute_update(query, (name, snippet_type.value, content, metadata_json))\n",
    "        logger.info(f\"Created Snippet '{name}' (ID: {snippet_id})\")\n",
    "        return snippet_id\n",
    "\n",
    "    def get_snippet_by_name(self, name: str) -> Optional[Snippet]:\n",
    "        \"\"\"Retrieve a snippet by name.\"\"\"\n",
    "        query = \"SELECT * FROM Snippets WHERE name = ?\"\n",
    "        result = self.db.execute_query(query, (name,))\n",
    "        if result:\n",
    "            row = result[0]\n",
    "            return Snippet(\n",
    "                snippet_id=row['snippet_id'],\n",
    "                name=row['name'],\n",
    "                snippet_type=SnippetType(row['snippet_type']),\n",
    "                content=row['content'],\n",
    "                metadata=json.loads(row['metadata']) if row['metadata'] else None\n",
    "            )\n",
    "        return None\n",
    "\n",
    "    def update_snippet(self, snippet_id: int, content: str = None, metadata: Dict = None):\n",
    "        \"\"\"Update an existing snippet.\"\"\"\n",
    "        if content:\n",
    "            self.db.execute_update(\n",
    "                \"UPDATE Snippets SET content = ?, updated_at = CURRENT_TIMESTAMP WHERE snippet_id = ?\",\n",
    "                (content, snippet_id)\n",
    "            )\n",
    "        if metadata:\n",
    "            self.db.execute_update(\n",
    "                \"UPDATE Snippets SET metadata = ?, updated_at = CURRENT_TIMESTAMP WHERE snippet_id = ?\",\n",
    "                (json.dumps(metadata), snippet_id)\n",
    "            )\n",
    "\n",
    "    def list_snippets(self, snippet_type: Optional[SnippetType] = None) -> List[Snippet]:\n",
    "        \"\"\"List all snippets, optionally filtered by type.\"\"\"\n",
    "        if snippet_type:\n",
    "            query = \"SELECT * FROM Snippets WHERE snippet_type = ?\"\n",
    "            results = self.db.execute_query(query, (snippet_type.value,))\n",
    "        else:\n",
    "            query = \"SELECT * FROM Snippets\"\n",
    "            results = self.db.execute_query(query)\n",
    "\n",
    "        return [\n",
    "            Snippet(\n",
    "                snippet_id=row['snippet_id'],\n",
    "                name=row['name'],\n",
    "                snippet_type=SnippetType(row['snippet_type']),\n",
    "                content=row['content'],\n",
    "                metadata=json.loads(row['metadata']) if row['metadata'] else None\n",
    "            )\n",
    "            for row in results\n",
    "        ]\n",
    "\n",
    "    def delete_snippet(self, snippet_id: int):\n",
    "        \"\"\"Delete a snippet from the library.\"\"\"\n",
    "        self.db.execute_update(\"DELETE FROM Snippets WHERE snippet_id = ?\", (snippet_id,))\n",
    "        logger.info(f\"Deleted Snippet ID: {snippet_id}\")\n",
    "\n",
    "    def create_convention_snippet(self, name: str, convention_rules: Dict) -> int:\n",
    "        \"\"\"Create a snippet specifically for data conventions.\"\"\"\n",
    "        content = ToonNotation.encode(convention_rules)\n",
    "        return self.create_snippet(\n",
    "            name=name,\n",
    "            snippet_type=SnippetType.CONVENTION,\n",
    "            content=content,\n",
    "            metadata={\"type\": \"naming_conventions\", \"auto_generated\": False}\n",
    "        )\n",
    "\n",
    "    def create_changelog_snippet(self, name: str, changes: List[Dict]) -> int:\n",
    "        \"\"\"Create a snippet for version changelog.\"\"\"\n",
    "        content = ToonNotation.encode({\"changes\": changes})\n",
    "        return self.create_snippet(\n",
    "            name=name,\n",
    "            snippet_type=SnippetType.CHANGELOG,\n",
    "            content=content,\n",
    "            metadata={\"type\": \"version_history\", \"entries\": len(changes)}\n",
    "        )\n",
    "\n",
    "    def create_instrument_snippet(self, name: str, instrument_data: Dict) -> int:\n",
    "        \"\"\"Create a snippet for instrument documentation.\"\"\"\n",
    "        content = ToonNotation.encode(instrument_data)\n",
    "        return self.create_snippet(\n",
    "            name=name,\n",
    "            snippet_type=SnippetType.INSTRUMENT,\n",
    "            content=content,\n",
    "            metadata={\"type\": \"instrument\", \"variable_count\": len(instrument_data.get(\"variables\", []))}\n",
    "        )\n",
    "\n",
    "print(\"\u2713 SnippetManager loaded with extended snippet types:\")\n",
    "print(\"   Core types: Summary, Chunk, Instruction, Version, Design, Mapping\")\n",
    "print(\"   Extended types: Convention, Changelog, Instrument, Segment, Glossary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4PQULOIg3Xg"
   },
   "source": [
    "## 5. Human-in-the-Loop Review QueueThe ReviewQueue manages approval workflows for generated content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "14iKjqjKg3Xg"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReviewItem:\n",
    "    \"\"\"Represents an item in the review queue.\"\"\"\n",
    "    item_id: int\n",
    "    job_id: str\n",
    "    status: str\n",
    "    source_agent: str\n",
    "    target_agent: Optional[str]\n",
    "    source_data: str\n",
    "    generated_content: str\n",
    "    approved_content: Optional[str] = None\n",
    "    rejection_feedback: Optional[str] = None\n",
    "\n",
    "\n",
    "class ReviewQueueManager:\n",
    "    \"\"\"Manages the HITL review workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, db_manager: DatabaseManager):\n",
    "        self.db = db_manager\n",
    "\n",
    "    def add_item(self, job_id: str, source_agent: str, source_data: str,\n",
    "                 generated_content: str, target_agent: Optional[str] = None) -> int:\n",
    "        \"\"\"Add an item to the review queue.\"\"\"\n",
    "        query = \"\"\"\n",
    "        INSERT INTO ReviewQueue (job_id, source_agent, target_agent, source_data, generated_content)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        item_id = self.db.execute_update(\n",
    "            query, (job_id, source_agent, target_agent, source_data, generated_content)\n",
    "        )\n",
    "        logger.info(f\"Added review item {item_id} from {source_agent}\")\n",
    "        return item_id\n",
    "\n",
    "    def get_pending_items(self, job_id: str) -> List[ReviewItem]:\n",
    "        \"\"\"Get all pending review items for a job.\"\"\"\n",
    "        query = \"SELECT * FROM ReviewQueue WHERE job_id = ? AND status = 'Pending'\"\n",
    "        results = self.db.execute_query(query, (job_id,))\n",
    "        return [\n",
    "            ReviewItem(\n",
    "                item_id=row['item_id'],\n",
    "                job_id=row['job_id'],\n",
    "                status=row['status'],\n",
    "                source_agent=row['source_agent'],\n",
    "                target_agent=row['target_agent'],\n",
    "                source_data=row['source_data'],\n",
    "                generated_content=row['generated_content'],\n",
    "                approved_content=row['approved_content'],\n",
    "                rejection_feedback=row['rejection_feedback']\n",
    "            )\n",
    "            for row in results\n",
    "        ]\n",
    "\n",
    "    def approve_item(self, item_id: int, approved_content: Optional[str] = None):\n",
    "        \"\"\"Approve a review item.\"\"\"\n",
    "        if approved_content:\n",
    "            query = \"\"\"\n",
    "            UPDATE ReviewQueue\n",
    "            SET status = 'Approved', approved_content = ?, updated_at = CURRENT_TIMESTAMP\n",
    "            WHERE item_id = ?\n",
    "            \"\"\"\n",
    "            self.db.execute_update(query, (approved_content, item_id))\n",
    "        else:\n",
    "            query = \"\"\"\n",
    "            UPDATE ReviewQueue\n",
    "            SET status = 'Approved', approved_content = generated_content, updated_at = CURRENT_TIMESTAMP\n",
    "            WHERE item_id = ?\n",
    "            \"\"\"\n",
    "            self.db.execute_update(query, (item_id,))\n",
    "        logger.info(f\"Approved review item {item_id}\")\n",
    "\n",
    "    def reject_item(self, item_id: int, feedback: str):\n",
    "        \"\"\"Reject a review item with feedback.\"\"\"\n",
    "        query = \"\"\"\n",
    "        UPDATE ReviewQueue\n",
    "        SET status = 'Rejected', rejection_feedback = ?, updated_at = CURRENT_TIMESTAMP\n",
    "        WHERE item_id = ?\n",
    "        \"\"\"\n",
    "        self.db.execute_update(query, (feedback, item_id))\n",
    "        logger.info(f\"Rejected review item {item_id}\")\n",
    "\n",
    "    def get_approved_items(self, job_id: str) -> List[ReviewItem]:\n",
    "        \"\"\"Get all approved items for a job.\"\"\"\n",
    "        query = \"SELECT * FROM ReviewQueue WHERE job_id = ? AND status = 'Approved'\"\n",
    "        results = self.db.execute_query(query, (job_id,))\n",
    "        return [\n",
    "            ReviewItem(\n",
    "                item_id=row['item_id'],\n",
    "                job_id=row['job_id'],\n",
    "                status=row['status'],\n",
    "                source_agent=row['source_agent'],\n",
    "                target_agent=row['target_agent'],\n",
    "                source_data=row['source_data'],\n",
    "                generated_content=row['generated_content'],\n",
    "                approved_content=row['approved_content'],\n",
    "                rejection_feedback=row['rejection_feedback']\n",
    "            )\n",
    "            for row in results\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 HITL User Interface\n",
    "\n",
    "Interactive widgets for:\n",
    "- **File Upload**: Upload external CSV/JSON data\n",
    "- **Review Dashboard**: Review, approve, reject, or request clarification\n",
    "- **Batch Operations**: Approve/reject multiple items at once\n",
    "- **Clarification Workflow**: Submit and track clarification requests\n",
    "- **Export**: Download Markdown documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "class DataUploader:\n",
    "    \"\"\"Widget for uploading external data files.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.uploaded_data = None\n",
    "        self.upload_output = widgets.Output()\n",
    "        \n",
    "    def create_widget(self):\n",
    "        \"\"\"Create the file upload interface.\"\"\"\n",
    "        upload_button = widgets.Button(\n",
    "            description='Upload CSV/JSON File',\n",
    "            button_style='primary',\n",
    "            tooltip='Upload data dictionary file',\n",
    "            icon='upload'\n",
    "        )\n",
    "        \n",
    "        status_label = widgets.HTML(value='<p>No file uploaded</p>')\n",
    "        \n",
    "        def on_upload_clicked(b):\n",
    "            with self.upload_output:\n",
    "                clear_output()\n",
    "                print('Please select a file to upload...')\n",
    "                \n",
    "                try:\n",
    "                    uploaded = files.upload()\n",
    "                    \n",
    "                    if uploaded:\n",
    "                        filename = list(uploaded.keys())[0]\n",
    "                        content = uploaded[filename]\n",
    "                        \n",
    "                        # Try to parse the file\n",
    "                        if filename.endswith('.csv'):\n",
    "                            self.uploaded_data = pd.read_csv(io.BytesIO(content))\n",
    "                            file_type = 'CSV'\n",
    "                        elif filename.endswith('.json'):\n",
    "                            self.uploaded_data = pd.read_json(io.BytesIO(content))\n",
    "                            file_type = 'JSON'\n",
    "                        else:\n",
    "                            print(f'\u274c Unsupported file type: {filename}')\n",
    "                            return\n",
    "                        \n",
    "                        status_label.value = f'''<p style=\"color: green;\">\u2713 Uploaded: {filename} ({file_type})</p>\n",
    "                        <p>Rows: {len(self.uploaded_data)}, Columns: {len(self.uploaded_data.columns)}</p>'''\n",
    "                        \n",
    "                        print(f'\\n\u2713 Successfully loaded {filename}')\n",
    "                        print(f'\\nPreview:\\n{self.uploaded_data.head()}')\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f'\u274c Error uploading file: {str(e)}')\n",
    "                    status_label.value = f'<p style=\"color: red;\">\u274c Upload failed</p>'\n",
    "        \n",
    "        upload_button.on_click(on_upload_clicked)\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML('<h3>\ud83d\udcc1 Upload External Data</h3>'),\n",
    "            upload_button,\n",
    "            status_label,\n",
    "            self.upload_output\n",
    "        ])\n",
    "\n",
    "# Create the uploader instance\n",
    "data_uploader = DataUploader()\n",
    "print('\u2713 Data uploader initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HITLReviewDashboard:\n",
    "    \"\"\"Interactive dashboard for reviewing queue items.\"\"\"\n",
    "    \n",
    "    def __init__(self, review_queue: ReviewQueueManager):\n",
    "        self.review_queue = review_queue\n",
    "        self.current_job_id = None\n",
    "        self.current_items = []\n",
    "        self.current_index = 0\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "    def create_widget(self, job_id: str):\n",
    "        \"\"\"Create the review dashboard interface.\"\"\"\n",
    "        self.current_job_id = job_id\n",
    "        self.load_pending_items()\n",
    "        \n",
    "        # Job ID input\n",
    "        job_input = widgets.Text(\n",
    "            value=job_id,\n",
    "            description='Job ID:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        refresh_button = widgets.Button(\n",
    "            description='Refresh',\n",
    "            button_style='info',\n",
    "            icon='refresh'\n",
    "        )\n",
    "        \n",
    "        # Status display\n",
    "        status_html = widgets.HTML()\n",
    "        \n",
    "        # Navigation buttons\n",
    "        prev_button = widgets.Button(\n",
    "            description='\u25c0 Previous',\n",
    "            button_style='',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        next_button = widgets.Button(\n",
    "            description='Next \u25b6',\n",
    "            button_style='',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Item display\n",
    "        item_html = widgets.HTML()\n",
    "        \n",
    "        # Edit area for approved content\n",
    "        edit_area = widgets.Textarea(\n",
    "            value='',\n",
    "            description='Edit:',\n",
    "            layout=widgets.Layout(width='100%', height='200px')\n",
    "        )\n",
    "        \n",
    "        # Feedback/clarification area\n",
    "        feedback_area = widgets.Textarea(\n",
    "            value='',\n",
    "            placeholder='Enter feedback or clarification request...',\n",
    "            description='Feedback:',\n",
    "            layout=widgets.Layout(width='100%', height='100px')\n",
    "        )\n",
    "        \n",
    "        # Action buttons\n",
    "        approve_button = widgets.Button(\n",
    "            description='\u2713 Approve',\n",
    "            button_style='success',\n",
    "            icon='check'\n",
    "        )\n",
    "        \n",
    "        reject_button = widgets.Button(\n",
    "            description='\u2717 Reject',\n",
    "            button_style='danger',\n",
    "            icon='times'\n",
    "        )\n",
    "        \n",
    "        clarify_button = widgets.Button(\n",
    "            description='? Request Clarification',\n",
    "            button_style='warning',\n",
    "            icon='question'\n",
    "        )\n",
    "        \n",
    "        def load_pending_items(self):\n",
    "            \"\"\"Load pending items from the review queue.\"\"\"\n",
    "            self.current_items = self.review_queue.get_pending_items(self.current_job_id)\n",
    "            self.current_index = 0\n",
    "            self.update_display()\n",
    "        \n",
    "        def update_display(self):\n",
    "            \"\"\"Update the dashboard display.\"\"\"\n",
    "            if not self.current_items:\n",
    "                status_html.value = '<h3 style=\"color: green;\">\u2713 No pending items</h3>'\n",
    "                item_html.value = '<p>All items have been reviewed!</p>'\n",
    "                edit_area.value = ''\n",
    "                prev_button.disabled = True\n",
    "                next_button.disabled = True\n",
    "                approve_button.disabled = True\n",
    "                reject_button.disabled = True\n",
    "                clarify_button.disabled = True\n",
    "                return\n",
    "            \n",
    "            item = self.current_items[self.current_index]\n",
    "            \n",
    "            # Update status\n",
    "            status_html.value = f'''<h3>Review Item {self.current_index + 1} of {len(self.current_items)}</h3>\n",
    "            <p><strong>Source Agent:</strong> {item.source_agent}</p>\n",
    "            <p><strong>Item ID:</strong> {item.item_id}</p>'''\n",
    "            \n",
    "            # Update item display\n",
    "            source_preview = item.source_data[:200] + '...' if len(item.source_data) > 200 else item.source_data\n",
    "            item_html.value = f'''<div style=\"background: #f5f5f5; padding: 10px; border-radius: 5px;\">\n",
    "            <h4>Source Data:</h4>\n",
    "            <pre>{source_preview}</pre>\n",
    "            <h4>Generated Content:</h4>\n",
    "            <div>{item.generated_content[:1000]}</div>\n",
    "            </div>'''\n",
    "            \n",
    "            # Update edit area with generated content\n",
    "            edit_area.value = item.generated_content\n",
    "            \n",
    "            # Update navigation buttons\n",
    "            prev_button.disabled = self.current_index == 0\n",
    "            next_button.disabled = self.current_index == len(self.current_items) - 1\n",
    "            \n",
    "            # Enable action buttons\n",
    "            approve_button.disabled = False\n",
    "            reject_button.disabled = False\n",
    "            clarify_button.disabled = False\n",
    "        \n",
    "        def on_refresh(b):\n",
    "            self.current_job_id = job_input.value\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                print(f'Refreshing items for job {self.current_job_id}...')\n",
    "            load_pending_items(self)\n",
    "        \n",
    "        def on_prev(b):\n",
    "            if self.current_index > 0:\n",
    "                self.current_index -= 1\n",
    "                update_display()\n",
    "        \n",
    "        def on_next(b):\n",
    "            if self.current_index < len(self.current_items) - 1:\n",
    "                self.current_index += 1\n",
    "                update_display()\n",
    "        \n",
    "        def on_approve(b):\n",
    "            if not self.current_items:\n",
    "                return\n",
    "            \n",
    "            item = self.current_items[self.current_index]\n",
    "            approved_content = edit_area.value\n",
    "            \n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                self.review_queue.approve_item(item.item_id, approved_content)\n",
    "                print(f'\u2713 Approved item {item.item_id}')\n",
    "            \n",
    "            # Remove from current items and update display\n",
    "            self.current_items.pop(self.current_index)\n",
    "            if self.current_index >= len(self.current_items) and self.current_index > 0:\n",
    "                self.current_index -= 1\n",
    "            update_display()\n",
    "        \n",
    "        def on_reject(b):\n",
    "            if not self.current_items:\n",
    "                return\n",
    "            \n",
    "            if not feedback_area.value:\n",
    "                with self.output:\n",
    "                    clear_output()\n",
    "                    print('\u274c Please provide feedback before rejecting')\n",
    "                return\n",
    "            \n",
    "            item = self.current_items[self.current_index]\n",
    "            \n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                self.review_queue.reject_item(item.item_id, feedback_area.value)\n",
    "                print(f'\u2717 Rejected item {item.item_id}')\n",
    "            \n",
    "            # Remove from current items and update display\n",
    "            self.current_items.pop(self.current_index)\n",
    "            if self.current_index >= len(self.current_items) and self.current_index > 0:\n",
    "                self.current_index -= 1\n",
    "            feedback_area.value = ''\n",
    "            update_display()\n",
    "        \n",
    "        def on_clarify(b):\n",
    "            if not self.current_items:\n",
    "                return\n",
    "            \n",
    "            if not feedback_area.value:\n",
    "                with self.output:\n",
    "                    clear_output()\n",
    "                    print('\u274c Please provide clarification request')\n",
    "                return\n",
    "            \n",
    "            item = self.current_items[self.current_index]\n",
    "            \n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                # Update status to Needs_Clarification\n",
    "                query = \"\"\"UPDATE ReviewQueue \n",
    "                          SET status = 'Needs_Clarification', \n",
    "                              rejection_feedback = ?, \n",
    "                              updated_at = CURRENT_TIMESTAMP \n",
    "                          WHERE item_id = ?\"\"\"\n",
    "                self.review_queue.db.execute_update(query, (feedback_area.value, item.item_id))\n",
    "                print(f'? Requested clarification for item {item.item_id}')\n",
    "            \n",
    "            # Remove from current items and update display\n",
    "            self.current_items.pop(self.current_index)\n",
    "            if self.current_index >= len(self.current_items) and self.current_index > 0:\n",
    "                self.current_index -= 1\n",
    "            feedback_area.value = ''\n",
    "            update_display()\n",
    "        \n",
    "        # Wire up event handlers\n",
    "        refresh_button.on_click(on_refresh)\n",
    "        prev_button.on_click(on_prev)\n",
    "        next_button.on_click(on_next)\n",
    "        approve_button.on_click(on_approve)\n",
    "        reject_button.on_click(on_reject)\n",
    "        clarify_button.on_click(on_clarify)\n",
    "        \n",
    "        # Initial display\n",
    "        update_display()\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML('<h2>\ud83d\udccb HITL Review Dashboard</h2>'),\n",
    "            widgets.HBox([job_input, refresh_button]),\n",
    "            status_html,\n",
    "            widgets.HBox([prev_button, next_button]),\n",
    "            item_html,\n",
    "            widgets.HTML('<h4>Edit Generated Content:</h4>'),\n",
    "            edit_area,\n",
    "            widgets.HTML('<h4>Feedback/Clarification:</h4>'),\n",
    "            feedback_area,\n",
    "            widgets.HBox([approve_button, reject_button, clarify_button]),\n",
    "            self.output\n",
    "        ])\n",
    "\n",
    "print('\u2713 HITL Review Dashboard initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchOperationsWidget:\n",
    "    \"\"\"Widget for batch approval/rejection operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, review_queue: ReviewQueueManager):\n",
    "        self.review_queue = review_queue\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "    def create_widget(self, job_id: str):\n",
    "        \"\"\"Create the batch operations interface.\"\"\"\n",
    "        \n",
    "        job_input = widgets.Text(\n",
    "            value=job_id,\n",
    "            description='Job ID:'\n",
    "        )\n",
    "        \n",
    "        agent_filter = widgets.Dropdown(\n",
    "            options=['All', 'PlainLanguageAgent', 'TechnicalAnalyzerAgent', \n",
    "                     'DomainOntologyAgent', 'DataParserAgent'],\n",
    "            value='All',\n",
    "            description='Filter by Agent:'\n",
    "        )\n",
    "        \n",
    "        item_count = widgets.HTML(value='<p>No items loaded</p>')\n",
    "        \n",
    "        load_button = widgets.Button(\n",
    "            description='Load Items',\n",
    "            button_style='info'\n",
    "        )\n",
    "        \n",
    "        approve_all_button = widgets.Button(\n",
    "            description='\u2713 Approve All',\n",
    "            button_style='success',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        reject_all_button = widgets.Button(\n",
    "            description='\u2717 Reject All',\n",
    "            button_style='danger',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        feedback_area = widgets.Textarea(\n",
    "            value='',\n",
    "            placeholder='Enter feedback for batch rejection...',\n",
    "            description='Feedback:',\n",
    "            layout=widgets.Layout(width='100%', height='100px')\n",
    "        )\n",
    "        \n",
    "        def on_load(b):\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                \n",
    "                items = self.review_queue.get_pending_items(job_input.value)\n",
    "                \n",
    "                # Filter by agent if needed\n",
    "                if agent_filter.value != 'All':\n",
    "                    items = [item for item in items if item.source_agent == agent_filter.value]\n",
    "                \n",
    "                if items:\n",
    "                    item_count.value = f'<p><strong>{len(items)} items loaded</strong></p>'\n",
    "                    approve_all_button.disabled = False\n",
    "                    reject_all_button.disabled = False\n",
    "                    \n",
    "                    # Store items for batch operations\n",
    "                    self.current_items = items\n",
    "                    \n",
    "                    # Show preview\n",
    "                    print(f'Loaded {len(items)} items:')\n",
    "                    for i, item in enumerate(items[:5], 1):\n",
    "                        print(f'{i}. Item {item.item_id} from {item.source_agent}')\n",
    "                    if len(items) > 5:\n",
    "                        print(f'... and {len(items) - 5} more')\n",
    "                else:\n",
    "                    item_count.value = '<p>No pending items found</p>'\n",
    "                    approve_all_button.disabled = True\n",
    "                    reject_all_button.disabled = True\n",
    "                    print('No items to process')\n",
    "        \n",
    "        def on_approve_all(b):\n",
    "            if not hasattr(self, 'current_items'):\n",
    "                return\n",
    "            \n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                print(f'Approving {len(self.current_items)} items...')\n",
    "                \n",
    "                for item in self.current_items:\n",
    "                    self.review_queue.approve_item(item.item_id)\n",
    "                \n",
    "                print(f'\u2713 Approved {len(self.current_items)} items')\n",
    "                \n",
    "                # Reset\n",
    "                self.current_items = []\n",
    "                item_count.value = '<p>Batch operation complete</p>'\n",
    "                approve_all_button.disabled = True\n",
    "                reject_all_button.disabled = True\n",
    "        \n",
    "        def on_reject_all(b):\n",
    "            if not hasattr(self, 'current_items'):\n",
    "                return\n",
    "            \n",
    "            if not feedback_area.value:\n",
    "                with self.output:\n",
    "                    clear_output()\n",
    "                    print('\u274c Please provide feedback before batch rejection')\n",
    "                return\n",
    "            \n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                print(f'Rejecting {len(self.current_items)} items...')\n",
    "                \n",
    "                for item in self.current_items:\n",
    "                    self.review_queue.reject_item(item.item_id, feedback_area.value)\n",
    "                \n",
    "                print(f'\u2717 Rejected {len(self.current_items)} items')\n",
    "                \n",
    "                # Reset\n",
    "                self.current_items = []\n",
    "                item_count.value = '<p>Batch operation complete</p>'\n",
    "                approve_all_button.disabled = True\n",
    "                reject_all_button.disabled = True\n",
    "                feedback_area.value = ''\n",
    "        \n",
    "        load_button.on_click(on_load)\n",
    "        approve_all_button.on_click(on_approve_all)\n",
    "        reject_all_button.on_click(on_reject_all)\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML('<h2>\u26a1 Batch Operations</h2>'),\n",
    "            job_input,\n",
    "            agent_filter,\n",
    "            load_button,\n",
    "            item_count,\n",
    "            feedback_area,\n",
    "            widgets.HBox([approve_all_button, reject_all_button]),\n",
    "            self.output\n",
    "        ])\n",
    "\n",
    "print('\u2713 Batch Operations Widget initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClarificationWidget:\n",
    "    \"\"\"Widget for managing clarification requests and responses.\"\"\"\n",
    "    \n",
    "    def __init__(self, review_queue: ReviewQueueManager):\n",
    "        self.review_queue = review_queue\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "    def create_widget(self, job_id: str):\n",
    "        \"\"\"Create the clarification management interface.\"\"\"\n",
    "        \n",
    "        job_input = widgets.Text(\n",
    "            value=job_id,\n",
    "            description='Job ID:'\n",
    "        )\n",
    "        \n",
    "        refresh_button = widgets.Button(\n",
    "            description='Load Clarifications',\n",
    "            button_style='info'\n",
    "        )\n",
    "        \n",
    "        items_html = widgets.HTML(value='<p>Click \"Load Clarifications\" to view items</p>')\n",
    "        \n",
    "        response_area = widgets.Textarea(\n",
    "            value='',\n",
    "            placeholder='Enter your clarification response...',\n",
    "            description='Response:',\n",
    "            layout=widgets.Layout(width='100%', height='150px')\n",
    "        )\n",
    "        \n",
    "        item_selector = widgets.Dropdown(\n",
    "            options=[],\n",
    "            description='Select Item:'\n",
    "        )\n",
    "        \n",
    "        submit_button = widgets.Button(\n",
    "            description='Submit Response',\n",
    "            button_style='primary',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        resolve_button = widgets.Button(\n",
    "            description='Mark as Resolved',\n",
    "            button_style='success',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        def on_refresh(b):\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                \n",
    "                # Query for items needing clarification\n",
    "                query = \"\"\"SELECT * FROM ReviewQueue \n",
    "                          WHERE job_id = ? AND status = 'Needs_Clarification'\"\"\"\n",
    "                results = self.review_queue.db.execute_query(query, (job_input.value,))\n",
    "                \n",
    "                if results:\n",
    "                    items_list = []\n",
    "                    options = []\n",
    "                    \n",
    "                    for row in results:\n",
    "                        items_list.append(row)\n",
    "                        options.append((f\"Item {row['item_id']} - {row['source_agent']}\", row['item_id']))\n",
    "                    \n",
    "                    item_selector.options = options\n",
    "                    \n",
    "                    # Store for later use\n",
    "                    self.clarification_items = {row['item_id']: row for row in results}\n",
    "                    \n",
    "                    items_html.value = f'''<h4>{len(results)} items need clarification</h4>'''\n",
    "                    \n",
    "                    # Show first item details\n",
    "                    if results:\n",
    "                        first_item = results[0]\n",
    "                        items_html.value += f'''<div style=\"background: #fff3cd; padding: 10px; margin: 10px 0; border-radius: 5px;\">\n",
    "                        <strong>Item {first_item['item_id']}</strong><br>\n",
    "                        <strong>Request:</strong> {first_item['rejection_feedback']}<br>\n",
    "                        <strong>Original Content:</strong> {first_item['generated_content'][:200]}...\n",
    "                        </div>'''\n",
    "                    \n",
    "                    submit_button.disabled = False\n",
    "                    resolve_button.disabled = False\n",
    "                    \n",
    "                    print(f'Found {len(results)} items needing clarification')\n",
    "                else:\n",
    "                    items_html.value = '<p style=\"color: green;\">\u2713 No items need clarification</p>'\n",
    "                    item_selector.options = []\n",
    "                    submit_button.disabled = True\n",
    "                    resolve_button.disabled = True\n",
    "                    print('No clarification items found')\n",
    "        \n",
    "        def on_submit_response(b):\n",
    "            if not item_selector.value or not response_area.value:\n",
    "                with self.output:\n",
    "                    clear_output()\n",
    "                    print('\u274c Please select an item and provide a response')\n",
    "                return\n",
    "            \n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                \n",
    "                # Update the clarification_response field\n",
    "                query = \"\"\"UPDATE ReviewQueue \n",
    "                          SET clarification_response = ?, \n",
    "                              updated_at = CURRENT_TIMESTAMP \n",
    "                          WHERE item_id = ?\"\"\"\n",
    "                self.review_queue.db.execute_update(query, (response_area.value, item_selector.value))\n",
    "                \n",
    "                print(f'\u2713 Submitted clarification response for item {item_selector.value}')\n",
    "                response_area.value = ''\n",
    "        \n",
    "        def on_resolve(b):\n",
    "            if not item_selector.value:\n",
    "                with self.output:\n",
    "                    clear_output()\n",
    "                    print('\u274c Please select an item')\n",
    "                return\n",
    "            \n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                \n",
    "                # Move back to Pending status for re-review\n",
    "                query = \"\"\"UPDATE ReviewQueue \n",
    "                          SET status = 'Pending', \n",
    "                              updated_at = CURRENT_TIMESTAMP \n",
    "                          WHERE item_id = ?\"\"\"\n",
    "                self.review_queue.db.execute_update(query, (item_selector.value,))\n",
    "                \n",
    "                print(f'\u2713 Marked item {item_selector.value} as resolved - moved back to Pending')\n",
    "                \n",
    "                # Refresh the list\n",
    "                on_refresh(b)\n",
    "        \n",
    "        refresh_button.on_click(on_refresh)\n",
    "        submit_button.on_click(on_submit_response)\n",
    "        resolve_button.on_click(on_resolve)\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML('<h2>\u2753 Clarification Management</h2>'),\n",
    "            widgets.HBox([job_input, refresh_button]),\n",
    "            items_html,\n",
    "            item_selector,\n",
    "            response_area,\n",
    "            widgets.HBox([submit_button, resolve_button]),\n",
    "            self.output\n",
    "        ])\n",
    "\n",
    "print('\u2713 Clarification Widget initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportWidget:\n",
    "    \"\"\"Widget for exporting documentation to Markdown.\"\"\"\n",
    "    \n",
    "    def __init__(self, assembler_agent, review_queue: ReviewQueueManager):\n",
    "        self.assembler = assembler_agent\n",
    "        self.review_queue = review_queue\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "    def create_widget(self, job_id: str):\n",
    "        \"\"\"Create the export interface.\"\"\"\n",
    "        \n",
    "        job_input = widgets.Text(\n",
    "            value=job_id,\n",
    "            description='Job ID:'\n",
    "        )\n",
    "        \n",
    "        filename_input = widgets.Text(\n",
    "            value='healthcare_data_documentation.md',\n",
    "            description='Filename:'\n",
    "        )\n",
    "        \n",
    "        status_html = widgets.HTML(value='<p>Ready to export</p>')\n",
    "        \n",
    "        preview_button = widgets.Button(\n",
    "            description='\ud83d\udc41 Preview',\n",
    "            button_style='info'\n",
    "        )\n",
    "        \n",
    "        export_button = widgets.Button(\n",
    "            description='\ud83d\udce5 Export to Markdown',\n",
    "            button_style='success'\n",
    "        )\n",
    "        \n",
    "        download_button = widgets.Button(\n",
    "            description='\ud83d\udcbe Download File',\n",
    "            button_style='primary',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        def on_preview(b):\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                \n",
    "                # Get approved items count\n",
    "                approved_items = self.review_queue.get_approved_items(job_input.value)\n",
    "                \n",
    "                if not approved_items:\n",
    "                    print('\u274c No approved items found for this job')\n",
    "                    status_html.value = '<p style=\"color: red;\">No approved items to export</p>'\n",
    "                    return\n",
    "                \n",
    "                print(f'Found {len(approved_items)} approved items')\n",
    "                print('\\nPreview of first item:')\n",
    "                print('=' * 60)\n",
    "                print(approved_items[0].approved_content[:500])\n",
    "                print('\\n... (truncated)')\n",
    "                print('=' * 60)\n",
    "                \n",
    "                status_html.value = f'<p style=\"color: green;\">{len(approved_items)} items ready to export</p>'\n",
    "        \n",
    "        def on_export(b):\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                \n",
    "                print(f'Assembling documentation for job {job_input.value}...')\n",
    "                \n",
    "                try:\n",
    "                    # Use the assembler to create the documentation\n",
    "                    documentation = self.assembler.assemble(job_input.value)\n",
    "                    \n",
    "                    # Write to file\n",
    "                    with open(filename_input.value, 'w') as f:\n",
    "                        f.write(documentation)\n",
    "                    \n",
    "                    print(f'\u2713 Exported {len(documentation)} characters to {filename_input.value}')\n",
    "                    status_html.value = f'<p style=\"color: green;\">\u2713 Exported to {filename_input.value}</p>'\n",
    "                    download_button.disabled = False\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f'\u274c Error during export: {str(e)}')\n",
    "                    status_html.value = '<p style=\"color: red;\">Export failed</p>'\n",
    "        \n",
    "        def on_download(b):\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                \n",
    "                try:\n",
    "                    files.download(filename_input.value)\n",
    "                    print(f'\u2713 Downloaded {filename_input.value}')\n",
    "                except Exception as e:\n",
    "                    print(f'\u274c Error downloading file: {str(e)}')\n",
    "        \n",
    "        preview_button.on_click(on_preview)\n",
    "        export_button.on_click(on_export)\n",
    "        download_button.on_click(on_download)\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML('<h2>\ud83d\udcc4 Markdown Export</h2>'),\n",
    "            job_input,\n",
    "            filename_input,\n",
    "            status_html,\n",
    "            widgets.HBox([preview_button, export_button, download_button]),\n",
    "            self.output\n",
    "        ])\n",
    "\n",
    "print('\u2713 Export Widget initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage Example\n",
    "\n",
    "To use the HITL UI components:\n",
    "\n",
    "```python\n",
    "# 1. Upload external data\n",
    "display(data_uploader.create_widget())\n",
    "\n",
    "# 2. Process the uploaded data (use your orchestrator)\n",
    "# job_id = orchestrator.process_data(data_uploader.uploaded_data, ...)\n",
    "\n",
    "# 3. Review items in the queue\n",
    "review_dashboard = HITLReviewDashboard(review_queue_manager)\n",
    "display(review_dashboard.create_widget('your_job_id'))\n",
    "\n",
    "# 4. OR use batch operations\n",
    "batch_ops = BatchOperationsWidget(review_queue_manager)\n",
    "display(batch_ops.create_widget('your_job_id'))\n",
    "\n",
    "# 5. Manage clarifications\n",
    "clarify_widget = ClarificationWidget(review_queue_manager)\n",
    "display(clarify_widget.create_widget('your_job_id'))\n",
    "\n",
    "# 6. Export documentation\n",
    "export_widget = ExportWidget(assembler_agent, review_queue_manager)\n",
    "display(export_widget.create_widget('your_job_id'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Complete HITL Workflow Demo\n",
    "\n",
    "This section demonstrates the full Human-in-the-Loop workflow from data upload to documentation export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE HITL WORKFLOW DEMO\n",
    "# This cell demonstrates the full workflow with all UI components\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "class HITLWorkflowApp:\n",
    "    \"\"\"Integrated HITL workflow application.\"\"\"\n",
    "    \n",
    "    def __init__(self, db_manager, orchestrator, assembler_agent):\n",
    "        self.db = db_manager\n",
    "        self.orchestrator = orchestrator\n",
    "        self.assembler = assembler_agent\n",
    "        self.review_queue = ReviewQueueManager(db_manager)\n",
    "        \n",
    "        # Initialize UI components\n",
    "        self.uploader = DataUploader()\n",
    "        self.review_dashboard = HITLReviewDashboard(self.review_queue)\n",
    "        self.batch_ops = BatchOperationsWidget(self.review_queue)\n",
    "        self.clarify_widget = ClarificationWidget(self.review_queue)\n",
    "        self.export_widget = ExportWidget(self.assembler, self.review_queue)\n",
    "        \n",
    "        self.current_job_id = None\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "    def create_app(self):\n",
    "        \"\"\"Create the complete HITL application interface.\"\"\"\n",
    "        \n",
    "        # Tab widget for different sections\n",
    "        tabs = widgets.Tab()\n",
    "        \n",
    "        # Tab 1: Upload & Process\n",
    "        upload_tab = self._create_upload_tab()\n",
    "        \n",
    "        # Tab 2: Review Dashboard\n",
    "        review_tab = self._create_review_tab()\n",
    "        \n",
    "        # Tab 3: Batch Operations\n",
    "        batch_tab = self._create_batch_tab()\n",
    "        \n",
    "        # Tab 4: Clarifications\n",
    "        clarify_tab = self._create_clarify_tab()\n",
    "        \n",
    "        # Tab 5: Export\n",
    "        export_tab = self._create_export_tab()\n",
    "        \n",
    "        tabs.children = [upload_tab, review_tab, batch_tab, clarify_tab, export_tab]\n",
    "        tabs.set_title(0, '1\ufe0f\u20e3 Upload & Process')\n",
    "        tabs.set_title(1, '2\ufe0f\u20e3 Review')\n",
    "        tabs.set_title(2, '3\ufe0f\u20e3 Batch Ops')\n",
    "        tabs.set_title(3, '4\ufe0f\u20e3 Clarifications')\n",
    "        tabs.set_title(4, '5\ufe0f\u20e3 Export')\n",
    "        \n",
    "        # Header\n",
    "        header = widgets.HTML(\n",
    "            '''<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                          padding: 20px; border-radius: 10px; color: white; margin-bottom: 20px;\">\n",
    "               <h1 style=\"margin: 0;\">\ud83c\udfe5 Healthcare Documentation ADE - HITL System</h1>\n",
    "               <p style=\"margin: 5px 0 0 0;\">Agent-Driven Evaluation with Human-in-the-Loop Review</p>\n",
    "               </div>'''\n",
    "        )\n",
    "        \n",
    "        # Job ID display\n",
    "        self.job_display = widgets.HTML(value='<p><strong>Current Job:</strong> None</p>')\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            header,\n",
    "            self.job_display,\n",
    "            tabs,\n",
    "            self.output\n",
    "        ])\n",
    "    \n",
    "    def _create_upload_tab(self):\n",
    "        \"\"\"Create upload and process tab.\"\"\"\n",
    "        \n",
    "        upload_widget = self.uploader.create_widget()\n",
    "        \n",
    "        job_name_input = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Enter job name (optional)',\n",
    "            description='Job Name:'\n",
    "        )\n",
    "        \n",
    "        process_button = widgets.Button(\n",
    "            description='\u25b6 Process Data',\n",
    "            button_style='success',\n",
    "            icon='play'\n",
    "        )\n",
    "        \n",
    "        status_html = widgets.HTML()\n",
    "        progress_bar = widgets.IntProgress(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            description='Progress:',\n",
    "            bar_style='info'\n",
    "        )\n",
    "        \n",
    "        process_output = widgets.Output()\n",
    "        \n",
    "        def on_process(b):\n",
    "            if self.uploader.uploaded_data is None:\n",
    "                with process_output:\n",
    "                    clear_output()\n",
    "                    print('\u274c Please upload data first')\n",
    "                return\n",
    "            \n",
    "            with process_output:\n",
    "                clear_output()\n",
    "                \n",
    "                try:\n",
    "                    # Create job\n",
    "                    job_name = job_name_input.value or f'Job_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "                    \n",
    "                    print(f'Creating job: {job_name}')\n",
    "                    progress_bar.value = 10\n",
    "                    \n",
    "                    # Convert DataFrame to CSV string\n",
    "                    csv_data = self.uploader.uploaded_data.to_csv(index=False)\n",
    "                    \n",
    "                    print('Processing with orchestrator...')\n",
    "                    progress_bar.value = 30\n",
    "                    \n",
    "                    # Run orchestrator (simplified - adjust based on your orchestrator API)\n",
    "                    # This assumes your orchestrator has a method to process data\n",
    "                    # You may need to adjust this based on the actual implementation\n",
    "                    result = self.orchestrator.process_pipeline(\n",
    "                        data=csv_data,\n",
    "                        job_name=job_name,\n",
    "                        auto_approve=False  # Require HITL review\n",
    "                    )\n",
    "                    \n",
    "                    progress_bar.value = 80\n",
    "                    \n",
    "                    self.current_job_id = result.get('job_id', job_name)\n",
    "                    \n",
    "                    progress_bar.value = 100\n",
    "                    progress_bar.bar_style = 'success'\n",
    "                    \n",
    "                    status_html.value = f'''<div style=\"background: #d4edda; padding: 15px; \n",
    "                                              border-radius: 5px; border-left: 4px solid #28a745;\">\n",
    "                                            <strong>\u2713 Processing Complete!</strong><br>\n",
    "                                            Job ID: <code>{self.current_job_id}</code><br>\n",
    "                                            Items created: {result.get('items_created', 'N/A')}<br>\n",
    "                                            <br>\n",
    "                                            \ud83d\udc49 Go to the <strong>Review</strong> tab to approve items\n",
    "                                            </div>'''\n",
    "                    \n",
    "                    self.job_display.value = f'<p><strong>Current Job:</strong> <code>{self.current_job_id}</code></p>'\n",
    "                    \n",
    "                    print(f'\\n\u2713 Job created successfully: {self.current_job_id}')\n",
    "                    print(f'Items sent to review queue: {result.get(\"items_created\", \"N/A\")}')\n",
    "                    print('\\n\ud83d\udc49 Switch to the Review tab to approve items')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    progress_bar.bar_style = 'danger'\n",
    "                    status_html.value = f'<p style=\"color: red;\">\u274c Error: {str(e)}</p>'\n",
    "                    print(f'\u274c Error processing data: {str(e)}')\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "        \n",
    "        process_button.on_click(on_process)\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            upload_widget,\n",
    "            widgets.HTML('<hr>'),\n",
    "            widgets.HTML('<h3>Process Uploaded Data</h3>'),\n",
    "            job_name_input,\n",
    "            process_button,\n",
    "            progress_bar,\n",
    "            status_html,\n",
    "            process_output\n",
    "        ])\n",
    "    \n",
    "    def _create_review_tab(self):\n",
    "        \"\"\"Create review dashboard tab.\"\"\"\n",
    "        \n",
    "        # Create a dynamic widget that updates with current job\n",
    "        container = widgets.VBox()\n",
    "        \n",
    "        def refresh_review():\n",
    "            job_id = self.current_job_id or 'no_job'\n",
    "            container.children = [self.review_dashboard.create_widget(job_id)]\n",
    "        \n",
    "        refresh_button = widgets.Button(\n",
    "            description='\ud83d\udd04 Refresh with Current Job',\n",
    "            button_style='info'\n",
    "        )\n",
    "        refresh_button.on_click(lambda b: refresh_review())\n",
    "        \n",
    "        return widgets.VBox([refresh_button, container])\n",
    "    \n",
    "    def _create_batch_tab(self):\n",
    "        \"\"\"Create batch operations tab.\"\"\"\n",
    "        container = widgets.VBox()\n",
    "        \n",
    "        def refresh_batch():\n",
    "            job_id = self.current_job_id or 'no_job'\n",
    "            container.children = [self.batch_ops.create_widget(job_id)]\n",
    "        \n",
    "        refresh_button = widgets.Button(\n",
    "            description='\ud83d\udd04 Refresh with Current Job',\n",
    "            button_style='info'\n",
    "        )\n",
    "        refresh_button.on_click(lambda b: refresh_batch())\n",
    "        \n",
    "        return widgets.VBox([refresh_button, container])\n",
    "    \n",
    "    def _create_clarify_tab(self):\n",
    "        \"\"\"Create clarification management tab.\"\"\"\n",
    "        container = widgets.VBox()\n",
    "        \n",
    "        def refresh_clarify():\n",
    "            job_id = self.current_job_id or 'no_job'\n",
    "            container.children = [self.clarify_widget.create_widget(job_id)]\n",
    "        \n",
    "        refresh_button = widgets.Button(\n",
    "            description='\ud83d\udd04 Refresh with Current Job',\n",
    "            button_style='info'\n",
    "        )\n",
    "        refresh_button.on_click(lambda b: refresh_clarify())\n",
    "        \n",
    "        return widgets.VBox([refresh_button, container])\n",
    "    \n",
    "    def _create_export_tab(self):\n",
    "        \"\"\"Create export tab.\"\"\"\n",
    "        container = widgets.VBox()\n",
    "        \n",
    "        def refresh_export():\n",
    "            job_id = self.current_job_id or 'no_job'\n",
    "            container.children = [self.export_widget.create_widget(job_id)]\n",
    "        \n",
    "        refresh_button = widgets.Button(\n",
    "            description='\ud83d\udd04 Refresh with Current Job',\n",
    "            button_style='info'\n",
    "        )\n",
    "        refresh_button.on_click(lambda b: refresh_export())\n",
    "        \n",
    "        return widgets.VBox([refresh_button, container])\n",
    "\n",
    "print('\u2713 HITL Workflow App initialized')\n",
    "print('Use: app = HITLWorkflowApp(db_manager, orchestrator, assembler)')\n",
    "print('Then: display(app.create_app())')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Start: Launch the HITL UI\n",
    "\n",
    "Run the cell below to launch the complete HITL workflow interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the complete HITL Workflow App\n",
    "# Make sure you've initialized db, orchestrator, and assembler first\n",
    "\n",
    "# Example initialization (adjust based on your setup):\n",
    "# db = DatabaseManager('healthcare_ade.db')\n",
    "# orchestrator = Orchestrator(db, api_config)\n",
    "# assembler = DocumentationAssemblerAgent(review_queue_manager)\n",
    "\n",
    "# Then launch the app:\n",
    "# hitl_app = HITLWorkflowApp(db, orchestrator, assembler)\n",
    "# display(hitl_app.create_app())\n",
    "\n",
    "print('Ready to launch HITL Workflow App')\n",
    "print('Uncomment the lines above and ensure dependencies are initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVrpQLdwg3Xg"
   },
   "source": [
    "## 6. Core Agent ClassesSpecialized agents with retry logic, rate limiting, and Toon context injection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "Gar58tYMg3Xg"
   },
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    \"\"\"Base class for all agents with rate limiting, retry logic, and observability.\"\"\"\n",
    "\n",
    "    def __init__(self, name: str, system_prompt: str, config: APIConfig = None):\n",
    "        self.name = name\n",
    "        self.system_prompt = system_prompt\n",
    "        self.config = config or API_CONFIG\n",
    "        self.model = genai.GenerativeModel(self.config.model_name)\n",
    "        self.active_snippets: List[Snippet] = []\n",
    "        self.last_request_time = 0\n",
    "        self.request_count = 0\n",
    "        self.logger = logging.getLogger(f'ADE.{name}')\n",
    "\n",
    "    def batch_items(self, items: List[Dict], batch_size: int = None) -> List[List[Dict]]:\n",
    "        \"\"\"Split items into batches.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.batch_size\n",
    "        return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]\n",
    "\n",
    "    def format_batch_prompt(self, items: List[Dict], item_type: str = \"variable\") -> str:\n",
    "        \"\"\"Format multiple items into a single prompt.\"\"\"\n",
    "        formatted_items = []\n",
    "        for i, item in enumerate(items, 1):\n",
    "            item_str = json.dumps(item, indent=2)\n",
    "            formatted_items.append(f\"{i}. {item_str}\")\n",
    "\n",
    "        return f\"\\n\\nProcess these {len(items)} {item_type}s:\\n\" + \"\\n\".join(formatted_items)\n",
    "\n",
    "    def inject_snippets(self, snippets: List[Snippet]):\n",
    "        \"\"\"Inject context snippets into agent.\"\"\"\n",
    "        self.active_snippets = snippets\n",
    "        self.logger.info(f\"Injected {len(snippets)} snippets\")\n",
    "\n",
    "    def build_prompt(self, user_input: str, additional_context: str = \"\") -> str:\n",
    "        \"\"\"Build the full prompt with system prompt, snippets, and user input.\"\"\"\n",
    "        prompt_parts = [self.system_prompt]\n",
    "\n",
    "        if self.active_snippets:\n",
    "            prompt_parts.append(\"\\n=== CONTEXT (Snippets) ===\")\n",
    "            for snippet in self.active_snippets:\n",
    "                prompt_parts.append(f\"\\n[{snippet.snippet_type.value}: {snippet.name}]\")\n",
    "                prompt_parts.append(snippet.content)\n",
    "\n",
    "        if additional_context:\n",
    "            prompt_parts.append(\"\\n=== ADDITIONAL CONTEXT ===\")\n",
    "            prompt_parts.append(additional_context)\n",
    "\n",
    "        prompt_parts.append(\"\\n=== INPUT ===\")\n",
    "        prompt_parts.append(user_input)\n",
    "\n",
    "        return \"\\n\".join(prompt_parts)\n",
    "\n",
    "    def _wait_for_rate_limit(self):\n",
    "        \"\"\"Implement rate limiting by waiting if necessary.\"\"\"\n",
    "        if self.last_request_time > 0:\n",
    "            elapsed = time.time() - self.last_request_time\n",
    "            if elapsed < self.config.min_delay:\n",
    "                wait_time = self.config.min_delay - elapsed\n",
    "                print(f\"\u23f1\ufe0f  Rate limiting: waiting {wait_time:.1f}s...\")\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        \"\"\"Generate content with exponential backoff retry logic.\"\"\"\n",
    "        for attempt in range(self.config.max_retries):\n",
    "            try:\n",
    "                self._wait_for_rate_limit()\n",
    "                response = self.model.generate_content(prompt)\n",
    "                self.last_request_time = time.time()\n",
    "                self.request_count += 1\n",
    "                return response.text\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt < self.config.max_retries - 1:\n",
    "                    # Exponential backoff: increases delay with each retry\n",
    "                    delay = self.config.get_retry_delay(attempt)\n",
    "                    self.logger.warning(\n",
    "                        f\"Rate limit hit, retrying in {delay:.1f}s (attempt {attempt + 1}/{self.config.max_retries})\"\n",
    "                    )\n",
    "                    print(f\"\u26a0\ufe0f  Rate limit hit, waiting {delay:.1f}s before retry {attempt + 1}/{self.config.max_retries}\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        raise Exception(f\"Max retries ({self.config.max_retries}) exceeded\")\n",
    "\n",
    "    def process(self, user_input: str, additional_context: str = \"\") -> str:\n",
    "        \"\"\"Process input through the agent.\"\"\"\n",
    "        prompt = self.build_prompt(user_input, additional_context)\n",
    "        return self.generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vauMdsv6g3Xg",
    "outputId": "6e717959-094a-4233-e7a6-6eabe8da6449"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 All agent classes defined with Toon support and observability\n"
     ]
    }
   ],
   "source": [
    "class DataParserAgent(BaseAgent):\n",
    "    \"\"\"Agent for parsing raw data into standardized JSON format.\"\"\"\n",
    "\n",
    "    def __init__(self, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a DataParserAgent specialized in converting raw data specifications into standardized JSON format.\n",
    "\n",
    "Your task:\n",
    "1. Parse the input data (CSV, JSON, or XML)\n",
    "2. Preserve all original field names and values\n",
    "3. Output a JSON array where each element represents one variable/field\n",
    "4. Include: original_name, original_type, original_description, and any metadata\n",
    "\n",
    "Output format:\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"original_name\": \"field_name\",\n",
    "    \"original_type\": \"type\",\n",
    "    \"original_description\": \"description\",\n",
    "    \"metadata\": {}\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "Only output valid JSON. No additional commentary.\"\"\"\n",
    "        super().__init__(\"DataParserAgent\", system_prompt, config)\n",
    "\n",
    "    def parse_csv(self, csv_data: str) -> List[Dict]:\n",
    "        \"\"\"Parse CSV data dictionary.\"\"\"\n",
    "        result = self.process(csv_data)\n",
    "        if \"```json\" in result:\n",
    "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in result:\n",
    "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        return json.loads(result)\n",
    "\n",
    "\n",
    "class TechnicalAnalyzerAgent(BaseAgent):\n",
    "    \"\"\"Agent for analyzing technical properties and mapping to internal standards.\"\"\"\n",
    "\n",
    "    def __init__(self, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a TechnicalAnalyzerAgent specialized in analyzing data fields.\n",
    "\n",
    "Your task:\n",
    "1. Analyze each field from the parsed data\n",
    "2. Infer technical properties (data_type, constraints, cardinality)\n",
    "3. Map to standardized field names following healthcare data conventions\n",
    "4. Flag unclear mappings for clarification\n",
    "\n",
    "Output format (JSON array for ALL variables):\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"original_name\": \"field_name\",\n",
    "    \"variable_name\": \"standardized_name\",\n",
    "    \"data_type\": \"categorical|continuous|date|text|boolean\",\n",
    "    \"description\": \"description\",\n",
    "    \"constraints\": {},\n",
    "    \"cardinality\": \"required|optional|repeated\",\n",
    "    \"confidence\": \"high|medium|low\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "Only output valid JSON.\"\"\"\n",
    "        super().__init__(\"TechnicalAnalyzerAgent\", system_prompt, config)\n",
    "\n",
    "    def analyze_batch(self, parsed_data: List[Dict], clarifications: Optional[Dict[str, str]] = None) -> List[Dict]:\n",
    "        \"\"\"Analyze multiple variables in a single batch request.\"\"\"\n",
    "        additional_context = \"\"\n",
    "        if clarifications:\n",
    "            additional_context = \"\\n=== USER CLARIFICATIONS ===\\n\"\n",
    "            for field, clarification in clarifications.items():\n",
    "                additional_context += f\"{field}: {clarification}\\n\"\n",
    "\n",
    "        # Batch the variables into a single prompt\n",
    "        batch_prompt = self.format_batch_prompt(parsed_data, \"variable\")\n",
    "        toon_encoded = ToonNotation.encode({\"variables\": parsed_data})\n",
    "\n",
    "        format_context = \"\\nAnalyze ALL variables in a single JSON array. Output JSON only.\\n\"\n",
    "        result = self.process(toon_encoded + batch_prompt, format_context + additional_context)\n",
    "\n",
    "        if \"```json\" in result:\n",
    "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in result:\n",
    "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        return json.loads(result)\n",
    "\n",
    "    def analyze(self, parsed_data: List[Dict], clarifications: Optional[Dict[str, str]] = None) -> List[Dict]:\n",
    "        \"\"\"Backward compatible single-call analyze method.\"\"\"\n",
    "        return self.analyze_batch(parsed_data, clarifications)\n",
    "\n",
    "\n",
    "class DomainOntologyAgent(BaseAgent):\n",
    "    \"\"\"Agent for mapping to standard healthcare ontologies.\"\"\"\n",
    "\n",
    "    def __init__(self, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a DomainOntologyAgent specialized in mapping healthcare data fields to standard ontologies.\n",
    "\n",
    "Your task:\n",
    "1. For each variable, identify appropriate standard ontology codes\n",
    "2. Primary ontologies: OMOP CDM, LOINC, SNOMED CT, RxNorm\n",
    "3. Provide code and standard term\n",
    "4. Include confidence score for each mapping\n",
    "\n",
    "Output format:\n",
    "```json\n",
    "{\n",
    "  \"variable_name\": \"standardized_name\",\n",
    "  \"ontology_mappings\": [\n",
    "    {\n",
    "      \"system\": \"OMOP\",\n",
    "      \"code\": \"123456\",\n",
    "      \"display\": \"Standard Concept Name\",\n",
    "      \"confidence\": \"high\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Only output valid JSON. No additional commentary.\"\"\"\n",
    "        super().__init__(\"DomainOntologyAgent\", system_prompt, config)\n",
    "\n",
    "    def map_ontologies(self, variable_data: Dict) -> Dict:\n",
    "        \"\"\"Map a variable to standard ontologies.\"\"\"\n",
    "        toon_encoded = ToonNotation.encode(variable_data)\n",
    "        result = self.process(toon_encoded, \"\\nInput is in Toon notation. Output JSON.\\n\")\n",
    "\n",
    "        if \"```json\" in result:\n",
    "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in result:\n",
    "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        return json.loads(result)\n",
    "\n",
    "\n",
    "class PlainLanguageAgent(BaseAgent):\n",
    "    \"\"\"Agent for generating human-readable documentation.\"\"\"\n",
    "\n",
    "    def __init__(self, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a PlainLanguageAgent specialized in creating clear, comprehensive documentation for healthcare data variables.\n",
    "\n",
    "Your task:\n",
    "1. Convert technical variable specifications into plain language\n",
    "2. Explain clinical/research context\n",
    "3. Describe data type, constraints, and valid values\n",
    "4. Include ontology mappings and significance\n",
    "5. Write for interdisciplinary audience (clinicians, researchers, data scientists)\n",
    "\n",
    "Output format (Markdown for EACH variable):\n",
    "```markdown\n",
    "## Variable: [Variable Name]\n",
    "\n",
    "**Description:** [Clear, concise description]\n",
    "\n",
    "**Technical Details:**\n",
    "- Data Type: [type]\n",
    "- Cardinality: [required/optional]\n",
    "- Valid Values: [constraints or ranges]\n",
    "\n",
    "**Standard Ontology Mappings:**\n",
    "- OMOP: [code] - [term]\n",
    "- LOINC: [code] - [term]\n",
    "\n",
    "**Clinical Context:** [Explanation of why this variable matters]\n",
    "```\n",
    "\n",
    "Process all variables and output markdown for each, separated by ---\"\"\"\n",
    "        super().__init__(\"PlainLanguageAgent\", system_prompt, config)\n",
    "\n",
    "    def document_variables_batched(self, variables: List[Dict]) -> List[str]:\n",
    "        \"\"\"Generate documentation for multiple variables in batches.\"\"\"\n",
    "        batches = self.batch_items(variables)\n",
    "        all_docs = []\n",
    "\n",
    "        for batch_num, batch in enumerate(batches, 1):\n",
    "            print(f\"Documenting batch {batch_num}/{len(batches)} ({len(batch)} variables)\")\n",
    "\n",
    "            # Format batch into single prompt\n",
    "            batch_prompt = self.format_batch_prompt(batch, \"variable\")\n",
    "            toon_encoded = ToonNotation.encode({\"variables\": batch})\n",
    "\n",
    "            # Single API call for entire batch\n",
    "            result = self.process(toon_encoded + batch_prompt)\n",
    "\n",
    "            # Parse results for each variable\n",
    "            docs = self._parse_batch_documentation(result, batch)\n",
    "            all_docs.extend(docs)\n",
    "\n",
    "            if batch_num < len(batches):\n",
    "                wait_time = 15.0\n",
    "                print(f\"\u23f1\ufe0f  Waiting {wait_time}s before next batch...\")\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        return all_docs\n",
    "\n",
    "    def _parse_batch_documentation(self, result: str, batch: List[Dict]) -> List[str]:\n",
    "        \"\"\"Extract individual variable documentation from batch response.\"\"\"\n",
    "        docs = []\n",
    "\n",
    "        # Split by variable headers\n",
    "        parts = result.split(\"## Variable:\")\n",
    "\n",
    "        for i, part in enumerate(parts[1:], 1):  # Skip first empty split\n",
    "            doc = \"## Variable:\" + part\n",
    "            # Clean up extra content\n",
    "            if i < len(parts):\n",
    "                doc = doc.split(\"---\")[0].strip()\n",
    "            docs.append(doc)\n",
    "\n",
    "        return docs[:len(batch)]  # Only return docs for variables in batch\n",
    "\n",
    "    def document_variable(self, enriched_data: Dict) -> str:\n",
    "        \"\"\"Generate plain language documentation for a single variable.\"\"\"\n",
    "        toon_encoded = ToonNotation.encode(enriched_data)\n",
    "        result = self.process(toon_encoded, \"\\nInput is in Toon notation. Generate markdown.\\n\")\n",
    "\n",
    "        if \"```markdown\" in result:\n",
    "            result = result.split(\"```markdown\")[1].split(\"```\")[0].strip()\n",
    "        elif result.startswith(\"```\") and result.endswith(\"```\"):\n",
    "            result = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        return result\n",
    "\n",
    "\n",
    "class DocumentationAssemblerAgent(BaseAgent):\n",
    "    \"\"\"Agent for assembling final documentation from approved items.\"\"\"\n",
    "\n",
    "    def __init__(self, review_queue: ReviewQueueManager, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a DocumentationAssemblerAgent specialized in creating comprehensive, well-structured data documentation.\n",
    "\n",
    "Your task:\n",
    "1. Compile all approved variable documentation into a cohesive document\n",
    "2. Add a table of contents\n",
    "3. Include metadata (generation date, source file, etc.)\n",
    "4. Organize by logical groupings if applicable\n",
    "5. Ensure consistent formatting throughout\n",
    "\n",
    "Output: A complete Markdown document ready for publication.\"\"\"\n",
    "        super().__init__(\"DocumentationAssemblerAgent\", system_prompt, config)\n",
    "        self.review_queue = review_queue\n",
    "\n",
    "    def assemble(self, job_id: str) -> str:\n",
    "        \"\"\"Assemble final documentation from approved review items.\"\"\"\n",
    "        approved_items = self.review_queue.get_approved_items(job_id)\n",
    "\n",
    "        if not approved_items:\n",
    "            return \"# No approved documentation found for this job.\"\n",
    "\n",
    "        doc_parts = [\n",
    "            \"# Healthcare Data Documentation\",\n",
    "            f\"\\n**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "            f\"**Job ID:** {job_id}\",\n",
    "            \"\\n---\\n\"\n",
    "        ]\n",
    "\n",
    "        doc_parts.append(\"## Table of Contents\\n\")\n",
    "        for i, item in enumerate(approved_items, 1):\n",
    "            content = item.approved_content\n",
    "            if \"## Variable:\" in content:\n",
    "                var_name = content.split(\"## Variable:\")[1].split(\"\\n\")[0].strip()\n",
    "                doc_parts.append(f\"{i}. [{var_name}](#{var_name.lower().replace(' ', '-')})\")\n",
    "\n",
    "        doc_parts.append(\"\\n---\\n\")\n",
    "\n",
    "        for item in approved_items:\n",
    "            doc_parts.append(item.approved_content)\n",
    "            doc_parts.append(\"\\n---\\n\")\n",
    "\n",
    "        return \"\\n\".join(doc_parts)\n",
    "\n",
    "\n",
    "print(\"\u2713 All agent classes defined with Toon support and observability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 Extended Agent Classes\n",
    "\n",
    "Additional specialized agents for design improvement, data conventions compliance, version control, and higher-level documentation."
   ],
   "metadata": {
    "id": "Sye6R_gbg3Xh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIC4e3FCg3Xh",
    "outputId": "42a86da2-60a0-49bb-fb8b-30ce71194bb3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Extended Agent classes defined:\n",
      "   - DesignImprovementAgent: Enhances documentation design\n",
      "   - DataConventionsAgent: Enforces naming conventions\n",
      "   - VersionControlAgent: Tracks documentation versions\n",
      "   - HigherLevelDocumentationAgent: Generates instrument/codebook docs\n",
      "   - ValidationAgent: Validates outputs for quality and consistency\n"
     ]
    }
   ],
   "source": [
    "class DesignImprovementAgent(BaseAgent):\n",
    "    \"\"\"Agent for enhancing design documentation and improving clarity.\"\"\"\n",
    "\n",
    "    def __init__(self, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a DesignImprovementAgent specialized in enhancing\n",
    "        documentation design and clarity.\n",
    "\n",
    "        Your task:\n",
    "        1. Review the provided documentation\n",
    "        2. Identify areas for improvement in structure, clarity, and completeness\n",
    "        3. Suggest and apply design enhancements\n",
    "        4. Score the design before and after improvements\n",
    "\n",
    "        Output format:\n",
    "        ```json\n",
    "        {\n",
    "          \"improved_content\": \"enhanced documentation text\",\n",
    "          \"design_score\": {\n",
    "            \"before\": 70,\n",
    "            \"after\": 85\n",
    "          },\n",
    "          \"improvements_made\": [\"list of improvements\"]\n",
    "        }\n",
    "        ```\n",
    "        Only output valid JSON. No additional commentary.\"\"\"\n",
    "\n",
    "        super().__init__(\"DesignImprovementAgent\", system_prompt, config)\n",
    "\n",
    "    def improve_design(self, documentation: str) -> Dict:\n",
    "        \"\"\"Improve the design of documentation.\"\"\"\n",
    "        result = self.process(documentation)\n",
    "        if \"```json\" in result:\n",
    "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        try:\n",
    "            return json.loads(result)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"improved_content\": documentation, \"design_score\": {\"before\": 0, \"after\": 0}}\n",
    "\n",
    "\n",
    "class DataConventionsAgent(BaseAgent):\n",
    "    \"\"\"Agent for analyzing and enforcing data naming conventions.\"\"\"\n",
    "\n",
    "    def __init__(self, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a DataConventionsAgent specialized in analyzing\n",
    "        data naming conventions and standards compliance.\n",
    "\n",
    "        Your task:\n",
    "        1. Analyze variable naming patterns\n",
    "        2. Check compliance with common standards (snake_case, camelCase, etc.)\n",
    "        3. Identify convention violations and warnings\n",
    "        4. Suggest standardized names\n",
    "\n",
    "        Output format:\n",
    "        ```json\n",
    "        {\n",
    "          \"naming_pattern\": \"detected pattern\",\n",
    "          \"convention_compliance\": 85,\n",
    "          \"convention_warnings\": [\"list of warnings\"],\n",
    "          \"suggested_name\": \"standardized_name\"\n",
    "        }\n",
    "        ```\n",
    "        Only output valid JSON. No additional commentary.\"\"\"\n",
    "\n",
    "        super().__init__(\"DataConventionsAgent\", system_prompt, config)\n",
    "\n",
    "    def analyze_conventions(self, var_data: Dict) -> Dict:\n",
    "        \"\"\"Analyze naming conventions for a variable.\"\"\"\n",
    "        result = self.process(json.dumps(var_data))\n",
    "        if \"```json\" in result:\n",
    "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        try:\n",
    "            return json.loads(result)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"naming_pattern\": \"unknown\", \"convention_compliance\": 0, \"convention_warnings\": []}\n",
    "\n",
    "    def generate_conventions_glossary(self, all_vars: List[Dict]) -> Dict:\n",
    "        \"\"\"Generate a glossary of conventions used.\"\"\"\n",
    "        patterns = {}\n",
    "        for var in all_vars:\n",
    "            conv = var.get('conventions', {})\n",
    "            pattern = conv.get('naming_pattern', 'unknown')\n",
    "            patterns[pattern] = patterns.get(pattern, 0) + 1\n",
    "\n",
    "        dominant = max(patterns.keys(), key=lambda k: patterns[k]) if patterns else 'mixed'\n",
    "        return {\n",
    "            \"dominant_pattern\": dominant,\n",
    "            \"pattern_distribution\": patterns,\n",
    "            \"total_variables\": len(all_vars)\n",
    "        }\n",
    "\n",
    "\n",
    "class VersionControlAgent(BaseAgent):\n",
    "    \"\"\"Agent for tracking documentation versions and changes.\"\"\"\n",
    "\n",
    "    def __init__(self, db_manager: DatabaseManager, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a VersionControlAgent specialized in tracking\n",
    "        documentation versions and managing change history.\"\"\"\n",
    "\n",
    "        super().__init__(\"VersionControlAgent\", system_prompt, config)\n",
    "        self.db = db_manager\n",
    "\n",
    "    def create_version(self, element_id: str, element_type: str, content: str, author: str = \"system\") -> Dict:\n",
    "        \"\"\"Create a new version for a documentation element.\"\"\"\n",
    "        # Get current version\n",
    "        query = \"\"\"SELECT version FROM SystemState\n",
    "                   WHERE key = ? ORDER BY updated_at DESC LIMIT 1\"\"\"\n",
    "        current = self.db.execute_query(query, (f\"{element_type}:{element_id}:version\",))\n",
    "\n",
    "        if current:\n",
    "            current_version = current[0]['version']\n",
    "            # Increment version\n",
    "            parts = current_version.split('.')\n",
    "            parts[-1] = str(int(parts[-1]) + 1)\n",
    "            new_version = '.'.join(parts)\n",
    "        else:\n",
    "            new_version = \"1.0.0\"\n",
    "\n",
    "        # Store version\n",
    "        self.db.execute_update(\n",
    "            \"\"\"INSERT OR REPLACE INTO SystemState (key, value, version, updated_at)\n",
    "               VALUES (?, ?, ?, CURRENT_TIMESTAMP)\"\"\",\n",
    "            (f\"{element_type}:{element_id}:version\", content, new_version)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"element_id\": element_id,\n",
    "            \"element_type\": element_type,\n",
    "            \"new_version\": new_version,\n",
    "            \"author\": author\n",
    "        }\n",
    "\n",
    "    def get_version_history(self, element_id: str) -> List[Dict]:\n",
    "        \"\"\"Get version history for an element.\"\"\"\n",
    "        query = \"\"\"SELECT * FROM SystemState\n",
    "                   WHERE key LIKE ? ORDER BY updated_at DESC\"\"\"\n",
    "        return self.db.execute_query(query, (f\"%{element_id}%\",))\n",
    "\n",
    "    def rollback_to_version(self, element_id: str, target_version: str) -> Dict:\n",
    "        \"\"\"Rollback to a specific version.\"\"\"\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"element_id\": element_id,\n",
    "            \"rolled_back_to\": target_version\n",
    "        }\n",
    "\n",
    "\n",
    "class HigherLevelDocumentationAgent(BaseAgent):\n",
    "    \"\"\"Agent for generating higher-level documentation (instruments, segments, codebooks).\"\"\"\n",
    "\n",
    "    def __init__(self, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a HigherLevelDocumentationAgent specialized in\n",
    "        generating higher-level documentation for instruments, segments, and codebooks.\n",
    "\n",
    "        Your task:\n",
    "        1. Group related variables into logical instruments/segments\n",
    "        2. Generate comprehensive documentation for these groupings\n",
    "        3. Create codebook overviews\n",
    "\n",
    "        Output format for instrument documentation:\n",
    "        ```json\n",
    "        {\n",
    "          \"instrument_name\": \"name\",\n",
    "          \"description\": \"description\",\n",
    "          \"variables\": [\"list of variable names\"],\n",
    "          \"documentation_markdown\": \"markdown documentation\"\n",
    "        }\n",
    "        ```\n",
    "        Only output valid JSON. No additional commentary.\"\"\"\n",
    "\n",
    "        super().__init__(\"HigherLevelDocumentationAgent\", system_prompt, config)\n",
    "\n",
    "    def identify_instruments(self, all_vars: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Identify potential instruments/segments from variables.\"\"\"\n",
    "        # Group by common prefixes or patterns\n",
    "        groups = {}\n",
    "        for var in all_vars:\n",
    "            name = var.get('original_name', var.get('variable_name', 'unknown'))\n",
    "            # Simple grouping by prefix\n",
    "            prefix = name.split('_')[0] if '_' in name else name[:3]\n",
    "            if prefix not in groups:\n",
    "                groups[prefix] = []\n",
    "            groups[prefix].append(var)\n",
    "\n",
    "        instruments = []\n",
    "        for prefix, vars in groups.items():\n",
    "            if len(vars) >= 2:  # Only group if 2+ variables\n",
    "                instruments.append({\n",
    "                    \"suggested_name\": f\"{prefix}_instrument\",\n",
    "                    \"variable_count\": len(vars),\n",
    "                    \"variables\": vars\n",
    "                })\n",
    "\n",
    "        return instruments\n",
    "\n",
    "    def document_instrument(self, variables: List[Dict]) -> Dict:\n",
    "        \"\"\"Generate documentation for an instrument.\"\"\"\n",
    "        var_summary = json.dumps(variables[:10])  # Limit for context\n",
    "        result = self.process(f\"Document this instrument with variables: {var_summary}\")\n",
    "        if \"```json\" in result:\n",
    "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        try:\n",
    "            return json.loads(result)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\n",
    "                \"instrument_name\": \"Unknown\",\n",
    "                \"description\": \"Auto-generated instrument\",\n",
    "                \"variables\": [v.get('original_name', 'unknown') for v in variables],\n",
    "                \"documentation_markdown\": \"Documentation pending\"\n",
    "            }\n",
    "\n",
    "    def generate_codebook_overview(self, all_vars: List[Dict], instruments: List[Dict] = None) -> Dict:\n",
    "        \"\"\"Generate an overview for the entire codebook.\"\"\"\n",
    "        return {\n",
    "            \"total_variables\": len(all_vars),\n",
    "            \"instruments\": len(instruments) if instruments else 0,\n",
    "            \"overview\": f\"Codebook containing {len(all_vars)} variables\"\n",
    "        }\n",
    "\n",
    "\n",
    "class ValidationAgent(BaseAgent):\n",
    "    \"\"\"Agent for validating outputs from other agents and ensuring quality and consistency.\"\"\"\n",
    "\n",
    "    def __init__(self, config: APIConfig = None):\n",
    "        system_prompt = \"\"\"You are a ValidationAgent specialized in validating and\n",
    "        quality-checking outputs from other agents in the documentation pipeline.\n",
    "\n",
    "        Your task:\n",
    "        1. Review outputs from various agents for correctness and completeness\n",
    "        2. Check for consistency across different agent outputs\n",
    "        3. Identify potential errors, inconsistencies, or missing information\n",
    "        4. Validate data types, formats, and standards compliance\n",
    "        5. Ensure ontology mappings are accurate and appropriate\n",
    "        6. Verify that documentation is clear, accurate, and complete\n",
    "\n",
    "        Output format:\n",
    "        ```json\n",
    "        {\n",
    "          \"validation_passed\": true/false,\n",
    "          \"overall_score\": 0-100,\n",
    "          \"issues_found\": [\n",
    "            {\n",
    "              \"severity\": \"critical/warning/info\",\n",
    "              \"category\": \"category_name\",\n",
    "              \"description\": \"issue description\",\n",
    "              \"affected_field\": \"field_name\",\n",
    "              \"suggestion\": \"how to fix\"\n",
    "            }\n",
    "          ],\n",
    "          \"consistency_checks\": {\n",
    "            \"naming_consistent\": true/false,\n",
    "            \"types_valid\": true/false,\n",
    "            \"ontologies_appropriate\": true/false,\n",
    "            \"documentation_complete\": true/false\n",
    "          },\n",
    "          \"recommendations\": [\"list of improvement recommendations\"],\n",
    "          \"validated_at\": \"timestamp\"\n",
    "        }\n",
    "        ```\n",
    "        Only output valid JSON. No additional commentary.\n",
    "\n",
    "        Be thorough but fair in your validation. Focus on:\n",
    "        - Data integrity and correctness\n",
    "        - Consistency across all outputs\n",
    "        - Completeness of documentation\n",
    "        - Appropriateness of ontology mappings\n",
    "        - Clarity of plain language descriptions\"\"\"\n",
    "\n",
    "        super().__init__(\"ValidationAgent\", system_prompt, config)\n",
    "\n",
    "    def validate_parsed_data(self, parsed_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Validate the output from DataParserAgent.\"\"\"\n",
    "        validation_input = f\"Validate this parsed data output: {json.dumps(parsed_data[:20])}\"\n",
    "        result = self.process(validation_input)\n",
    "        return self._parse_validation_result(result)\n",
    "\n",
    "    def validate_technical_analysis(self, analyzed_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Validate the output from TechnicalAnalyzerAgent.\"\"\"\n",
    "        validation_input = f\"Validate this technical analysis output: {json.dumps(analyzed_data[:10])}\"\n",
    "        result = self.process(validation_input)\n",
    "        return self._parse_validation_result(result)\n",
    "\n",
    "    def validate_ontology_mappings(self, enriched_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Validate ontology mappings from DomainOntologyAgent.\"\"\"\n",
    "        validation_input = f\"Validate these ontology mappings: {json.dumps(enriched_data[:10])}\"\n",
    "        result = self.process(validation_input)\n",
    "        return self._parse_validation_result(result)\n",
    "\n",
    "    def validate_documentation(self, documentation: str) -> Dict:\n",
    "        \"\"\"Validate plain language documentation from PlainLanguageAgent.\"\"\"\n",
    "        validation_input = f\"Validate this documentation for clarity and completeness: {documentation[:2000]}\"\n",
    "        result = self.process(validation_input)\n",
    "        return self._parse_validation_result(result)\n",
    "\n",
    "    def validate_full_pipeline_output(self, pipeline_results: Dict) -> Dict:\n",
    "        \"\"\"Validate the complete output from the entire agent pipeline.\"\"\"\n",
    "        validation_input = f\"\"\"Validate this complete pipeline output for consistency and quality:\n",
    "\n",
    "        Parsed Data Summary: {len(pipeline_results.get('parsed_data', []))} variables\n",
    "        Technical Analysis: {len(pipeline_results.get('analyzed_data', []))} analyzed\n",
    "        Ontology Mappings: {len(pipeline_results.get('enriched_data', []))} mapped\n",
    "        Documentation: {len(pipeline_results.get('documentation', []))} documents\n",
    "\n",
    "        Sample Data: {json.dumps(pipeline_results, default=str)[:3000]}\n",
    "        \"\"\"\n",
    "        result = self.process(validation_input)\n",
    "        return self._parse_validation_result(result)\n",
    "\n",
    "    def cross_validate_agents(self, agent_outputs: Dict[str, Any]) -> Dict:\n",
    "        \"\"\"Cross-validate outputs from multiple agents for consistency.\"\"\"\n",
    "        validation_input = f\"\"\"Cross-validate these outputs from different agents for consistency:\n",
    "        {json.dumps(agent_outputs, default=str)[:3000]}\n",
    "\n",
    "        Check for:\n",
    "        1. Consistent variable naming across outputs\n",
    "        2. Matching data types and formats\n",
    "        3. Coherent ontology mappings\n",
    "        4. Complete information flow between agents\n",
    "        \"\"\"\n",
    "        result = self.process(validation_input)\n",
    "        return self._parse_validation_result(result)\n",
    "\n",
    "    def _parse_validation_result(self, result: str) -> Dict:\n",
    "        \"\"\"Parse the validation result from the LLM response.\"\"\"\n",
    "        if \"```json\" in result:\n",
    "            result = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        try:\n",
    "            parsed = json.loads(result)\n",
    "            # Ensure required fields exist\n",
    "            if 'validation_passed' not in parsed:\n",
    "                parsed['validation_passed'] = parsed.get('overall_score', 0) >= 70\n",
    "            if 'validated_at' not in parsed:\n",
    "                parsed['validated_at'] = datetime.now().isoformat()\n",
    "            return parsed\n",
    "        except json.JSONDecodeError:\n",
    "            return {\n",
    "                \"validation_passed\": False,\n",
    "                \"overall_score\": 0,\n",
    "                \"issues_found\": [{\n",
    "                    \"severity\": \"critical\",\n",
    "                    \"category\": \"parse_error\",\n",
    "                    \"description\": \"Could not parse validation result\",\n",
    "                    \"affected_field\": \"all\",\n",
    "                    \"suggestion\": \"Retry validation\"\n",
    "                }],\n",
    "                \"consistency_checks\": {\n",
    "                    \"naming_consistent\": False,\n",
    "                    \"types_valid\": False,\n",
    "                    \"ontologies_appropriate\": False,\n",
    "                    \"documentation_complete\": False\n",
    "                },\n",
    "                \"recommendations\": [\"Retry validation with clearer input\"],\n",
    "                \"validated_at\": datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "    def generate_validation_report(self, all_validations: List[Dict]) -> str:\n",
    "        \"\"\"Generate a comprehensive validation report.\"\"\"\n",
    "        total_checks = len(all_validations)\n",
    "        passed = sum(1 for v in all_validations if v.get('validation_passed', False))\n",
    "        avg_score = sum(v.get('overall_score', 0) for v in all_validations) / max(total_checks, 1)\n",
    "\n",
    "        all_issues = []\n",
    "        for v in all_validations:\n",
    "            all_issues.extend(v.get('issues_found', []))\n",
    "\n",
    "        critical_issues = [i for i in all_issues if i.get('severity') == 'critical']\n",
    "        warnings = [i for i in all_issues if i.get('severity') == 'warning']\n",
    "\n",
    "        report = f\"\"\"# Validation Report\n",
    "\n",
    "## Summary\n",
    "- Total Validations: {total_checks}\n",
    "- Passed: {passed}/{total_checks} ({100*passed/max(total_checks,1):.1f}%)\n",
    "- Average Score: {avg_score:.1f}/100\n",
    "\n",
    "## Issues Found\n",
    "- Critical: {len(critical_issues)}\n",
    "- Warnings: {len(warnings)}\n",
    "- Info: {len(all_issues) - len(critical_issues) - len(warnings)}\n",
    "\n",
    "## Critical Issues\n",
    "\"\"\"\n",
    "        for issue in critical_issues[:10]:\n",
    "            report += f\"- [{issue.get('category')}] {issue.get('description')}\\n\"\n",
    "            report += f\"  Suggestion: {issue.get('suggestion')}\\n\\n\"\n",
    "\n",
    "        report += \"\"\"\n",
    "## Recommendations\n",
    "\"\"\"\n",
    "        all_recs = []\n",
    "        for v in all_validations:\n",
    "            all_recs.extend(v.get('recommendations', []))\n",
    "\n",
    "        for rec in list(set(all_recs))[:10]:\n",
    "            report += f\"- {rec}\\n\"\n",
    "\n",
    "        return report\n",
    "\n",
    "\n",
    "print(\"\u2713 Extended Agent classes defined:\")\n",
    "print(\"   - DesignImprovementAgent: Enhances documentation design\")\n",
    "print(\"   - DataConventionsAgent: Enforces naming conventions\")\n",
    "print(\"   - VersionControlAgent: Tracks documentation versions\")\n",
    "print(\"   - HigherLevelDocumentationAgent: Generates instrument/codebook docs\")\n",
    "print(\"   - ValidationAgent: Validates outputs for quality and consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Orchestrator:\n",
    "    \"\"\"Manages the workflow of agents and coordinates the documentation pipeline.\"\"\"\n",
    "\n",
    "    def __init__(self, db_manager: DatabaseManager, api_config: APIConfig = None):\n",
    "        self.db = db_manager\n",
    "        self.config = api_config or API_CONFIG\n",
    "        self.snippet_manager = SnippetManager(db_manager)\n",
    "        self.review_queue = ReviewQueueManager(db_manager)\n",
    "\n",
    "        # Initialize core agents with configuration\n",
    "        self.data_parser = DataParserAgent(config=self.config)\n",
    "        self.technical_analyzer = TechnicalAnalyzerAgent(config=self.config)\n",
    "        self.domain_ontology = DomainOntologyAgent(config=self.config)\n",
    "        self.plain_language = PlainLanguageAgent(config=self.config)\n",
    "        self.assembler = DocumentationAssemblerAgent(self.review_queue, config=self.config)\n",
    "\n",
    "        # Initialize extended agents\n",
    "        self.design_improvement = DesignImprovementAgent(config=self.config)\n",
    "        self.data_conventions = DataConventionsAgent(config=self.config)\n",
    "        self.version_control = VersionControlAgent(db_manager, config=self.config)\n",
    "        self.higher_level_docs = HigherLevelDocumentationAgent(config=self.config)\n",
    "        self.validation = ValidationAgent(config=self.config)\n",
    "\n",
    "        logger.info(f\"Orchestrator initialized with {self.config.requests_per_minute} req/min limit\")\n",
    "        print(f\"\u2713 Orchestrator initialized with {self.config.requests_per_minute} req/min limit\")\n",
    "        print(f\"   Core agents: DataParser, TechnicalAnalyzer, DomainOntology, PlainLanguage, Assembler\")\n",
    "        print(f\"   Extended agents: DesignImprovement, DataConventions, VersionControl, HigherLevelDocs, Validation\")\n",
    "\n",
    "    def create_job(self, source_file: str) -> str:\n",
    "        \"\"\"Create a new documentation job.\"\"\"\n",
    "        job_id = hashlib.md5(f\"{source_file}_{datetime.now().isoformat()}\".encode()).hexdigest()[:12]\n",
    "        query = \"INSERT INTO Jobs (job_id, source_file, status) VALUES (?, ?, 'Running')\"\n",
    "        self.db.execute_update(query, (job_id, source_file))\n",
    "        logger.info(f\"Created job {job_id} for {source_file}\")\n",
    "        return job_id\n",
    "\n",
    "    def process_data_dictionary(self, source_data: str, source_file: str = \"input.csv\",\n",
    "                                auto_approve: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        Main workflow: Process a data dictionary through the agent pipeline.\n",
    "\n",
    "        Args:\n",
    "            source_data: The raw data dictionary content\n",
    "            source_file: Name of the source file\n",
    "            auto_approve: If True, automatically approve all generated content\n",
    "\n",
    "        Returns:\n",
    "            job_id: The ID of the created job\n",
    "        \"\"\"\n",
    "        job_id = self.create_job(source_file)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing Job: {job_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Step 1: Parse data\n",
    "        print(\"\\n\ud83d\udcca Step 1: Parsing Data...\")\n",
    "        parsed_data = self.data_parser.parse_csv(source_data)\n",
    "        print(f\"   \u2713 Parsed {len(parsed_data)} variables\")\n",
    "\n",
    "        # Step 2: Technical analysis\n",
    "        print(\"\\n\ud83d\udd2c Step 2: Technical Analysis...\")\n",
    "        analyzed_data = self.technical_analyzer.analyze(parsed_data)\n",
    "        print(f\"   \u2713 Analyzed {len(analyzed_data)} variables\")\n",
    "\n",
    "        # Check for clarifications needed\n",
    "        needs_clarification = [v for v in analyzed_data if v.get('needs_clarification', False)]\n",
    "        if needs_clarification:\n",
    "            print(f\"   \u26a0\ufe0f  {len(needs_clarification)} variables need clarification\")\n",
    "            for var in needs_clarification:\n",
    "                print(f\"      - {var['original_name']}: {var.get('clarification_question', 'Unknown')}\")\n",
    "\n",
    "        # Step 3: Ontology mapping and documentation\n",
    "        print(\"\\n\ud83c\udfe5 Step 3: Ontology Mapping & Documentation...\")\n",
    "        for i, var_data in enumerate(analyzed_data, 1):\n",
    "            print(f\"   Processing {i}/{len(analyzed_data)}: {var_data.get('variable_name', var_data.get('original_name'))}\")\n",
    "\n",
    "            # Map to ontologies\n",
    "            ontology_result = self.domain_ontology.map_ontologies(var_data)\n",
    "\n",
    "            # Enrich with ontology data\n",
    "            enriched_data = {**var_data, **ontology_result}\n",
    "\n",
    "            # Generate plain language documentation\n",
    "            documentation = self.plain_language.document_variable(enriched_data)\n",
    "\n",
    "            # Add to review queue\n",
    "            item_id = self.review_queue.add_item(\n",
    "                job_id=job_id,\n",
    "                source_agent=\"PlainLanguageAgent\",\n",
    "                source_data=json.dumps(enriched_data),\n",
    "                generated_content=documentation\n",
    "            )\n",
    "\n",
    "            if auto_approve:\n",
    "                self.review_queue.approve_item(item_id)\n",
    "\n",
    "        # Update job status\n",
    "        status = 'Completed' if auto_approve else 'Pending Review'\n",
    "        self.db.execute_update(\n",
    "            \"UPDATE Jobs SET status = ?, updated_at = CURRENT_TIMESTAMP WHERE job_id = ?\",\n",
    "            (status, job_id)\n",
    "        )\n",
    "\n",
    "        print(f\"\\n\u2713 Processing complete! Job status: {status}\")\n",
    "        return job_id\n",
    "\n",
    "    def process_with_extended_agents(self, source_data: str, source_file: str = \"input.csv\",\n",
    "                                     auto_approve: bool = False,\n",
    "                                     apply_design_improvement: bool = True,\n",
    "                                     enforce_conventions: bool = True,\n",
    "                                     enable_versioning: bool = True,\n",
    "                                     document_higher_levels: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Enhanced workflow with extended agent capabilities.\n",
    "\n",
    "        Args:\n",
    "            source_data: The raw data dictionary content\n",
    "            source_file: Name of the source file\n",
    "            auto_approve: If True, automatically approve all generated content\n",
    "            apply_design_improvement: Use DesignImprovementAgent to enhance output\n",
    "            enforce_conventions: Use DataConventionsAgent to ensure standards\n",
    "            enable_versioning: Use VersionControlAgent to track changes\n",
    "            document_higher_levels: Use HigherLevelDocumentationAgent for segments\n",
    "\n",
    "        Returns:\n",
    "            job_id: The ID of the created job\n",
    "        \"\"\"\n",
    "        job_id = self.create_job(source_file)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"EXTENDED PROCESSING: Job {job_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"   Design Improvement: {'ON' if apply_design_improvement else 'OFF'}\")\n",
    "        print(f\"   Convention Enforcement: {'ON' if enforce_conventions else 'OFF'}\")\n",
    "        print(f\"   Version Control: {'ON' if enable_versioning else 'OFF'}\")\n",
    "        print(f\"   Higher-Level Docs: {'ON' if document_higher_levels else 'OFF'}\")\n",
    "\n",
    "        # Step 1: Parse data\n",
    "        print(\"\\n\ud83d\udcca Step 1: Parsing Data...\")\n",
    "        parsed_data = self.data_parser.parse_csv(source_data)\n",
    "        print(f\"   \u2713 Parsed {len(parsed_data)} variables\")\n",
    "\n",
    "        # Step 2: Technical analysis with conventions\n",
    "        print(\"\\n\ud83d\udd2c Step 2: Technical Analysis...\")\n",
    "        analyzed_data = self.technical_analyzer.analyze(parsed_data)\n",
    "        print(f\"   \u2713 Analyzed {len(analyzed_data)} variables\")\n",
    "\n",
    "        # Step 2.5: Enforce data conventions\n",
    "        conventions_data = []\n",
    "        if enforce_conventions:\n",
    "            print(\"\\n\ud83d\udccf Step 2.5: Analyzing Data Conventions...\")\n",
    "            for i, var_data in enumerate(analyzed_data, 1):\n",
    "                var_name = var_data.get('variable_name', var_data.get('original_name', 'Unknown'))\n",
    "                print(f\"   Checking conventions for {i}/{len(analyzed_data)}: {var_name}\")\n",
    "\n",
    "                conventions_result = self.data_conventions.analyze_conventions(var_data)\n",
    "                conventions_data.append(conventions_result)\n",
    "\n",
    "                # Merge convention info into analyzed data\n",
    "                var_data['conventions'] = conventions_result\n",
    "\n",
    "                # Track convention violations\n",
    "                if conventions_result.get('convention_warnings'):\n",
    "                    print(f\"      \u26a0\ufe0f  Warnings: {', '.join(conventions_result['convention_warnings'][:2])}\")\n",
    "\n",
    "            # Generate conventions glossary\n",
    "            glossary = self.data_conventions.generate_conventions_glossary(analyzed_data)\n",
    "            print(f\"   \u2713 Generated conventions glossary\")\n",
    "            print(f\"      Dominant naming pattern: {glossary.get('dominant_pattern', 'mixed')}\")\n",
    "\n",
    "        # Step 3: Ontology mapping and documentation\n",
    "        print(\"\\n\ud83c\udfe5 Step 3: Ontology Mapping & Documentation...\")\n",
    "        all_documentation = []\n",
    "\n",
    "        for i, var_data in enumerate(analyzed_data, 1):\n",
    "            var_name = var_data.get('variable_name', var_data.get('original_name', 'Unknown'))\n",
    "            print(f\"   Processing {i}/{len(analyzed_data)}: {var_name}\")\n",
    "\n",
    "            # Map to ontologies\n",
    "            ontology_result = self.domain_ontology.map_ontologies(var_data)\n",
    "            enriched_data = {**var_data, **ontology_result}\n",
    "\n",
    "            # Generate plain language documentation\n",
    "            documentation = self.plain_language.document_variable(enriched_data)\n",
    "\n",
    "            # Step 3.5: Apply design improvements\n",
    "            if apply_design_improvement:\n",
    "                print(f\"      Improving design...\")\n",
    "                design_result = self.design_improvement.improve_design(documentation)\n",
    "                if design_result.get('improved_content'):\n",
    "                    documentation = design_result['improved_content']\n",
    "                    score_before = design_result.get('design_score', {}).get('before', 0)\n",
    "                    score_after = design_result.get('design_score', {}).get('after', 0)\n",
    "                    print(f\"      Design score: {score_before} \u2192 {score_after}\")\n",
    "\n",
    "            all_documentation.append(documentation)\n",
    "\n",
    "            # Step 3.6: Version control\n",
    "            if enable_versioning:\n",
    "                version_result = self.version_control.create_version(\n",
    "                    element_id=var_name,\n",
    "                    element_type=\"variable\",\n",
    "                    content=documentation,\n",
    "                    author=\"system\"\n",
    "                )\n",
    "                if version_result.get('status') == 'success':\n",
    "                    print(f\"      Version: {version_result['new_version']}\")\n",
    "\n",
    "            # Add to review queue\n",
    "            item_id = self.review_queue.add_item(\n",
    "                job_id=job_id,\n",
    "                source_agent=\"PlainLanguageAgent\",\n",
    "                source_data=json.dumps(enriched_data),\n",
    "                generated_content=documentation\n",
    "            )\n",
    "\n",
    "            if auto_approve:\n",
    "                self.review_queue.approve_item(item_id)\n",
    "\n",
    "        # Step 4: Higher-level documentation\n",
    "        if document_higher_levels:\n",
    "            print(\"\\n\ud83d\udcda Step 4: Higher-Level Documentation...\")\n",
    "\n",
    "            # Identify potential instruments\n",
    "            potential_instruments = self.higher_level_docs.identify_instruments(analyzed_data)\n",
    "            print(f\"   Found {len(potential_instruments)} potential instruments/segments\")\n",
    "\n",
    "            for inst in potential_instruments:\n",
    "                print(f\"   Documenting: {inst['suggested_name']} ({inst['variable_count']} variables)\")\n",
    "                inst_doc = self.higher_level_docs.document_instrument(inst['variables'])\n",
    "\n",
    "                # Version the instrument documentation\n",
    "                if enable_versioning:\n",
    "                    self.version_control.create_version(\n",
    "                        element_id=inst['suggested_name'],\n",
    "                        element_type=\"instrument\",\n",
    "                        content=json.dumps(inst_doc),\n",
    "                        author=\"system\"\n",
    "                    )\n",
    "\n",
    "                # Add instrument documentation to review queue\n",
    "                item_id = self.review_queue.add_item(\n",
    "                    job_id=job_id,\n",
    "                    source_agent=\"HigherLevelDocumentationAgent\",\n",
    "                    source_data=json.dumps(inst),\n",
    "                    generated_content=inst_doc.get('documentation_markdown', str(inst_doc))\n",
    "                )\n",
    "\n",
    "                if auto_approve:\n",
    "                    self.review_queue.approve_item(item_id)\n",
    "\n",
    "            # Generate codebook overview\n",
    "            print(\"   Generating codebook overview...\")\n",
    "            overview = self.higher_level_docs.generate_codebook_overview(\n",
    "                analyzed_data,\n",
    "                instruments=[inst.get('documentation', {}) for inst in potential_instruments]\n",
    "            )\n",
    "            print(f\"   \u2713 Generated overview with {len(analyzed_data)} variables\")\n",
    "\n",
    "        # Update job status\n",
    "        status = 'Completed' if auto_approve else 'Pending Review'\n",
    "        self.db.execute_update(\n",
    "            \"UPDATE Jobs SET status = ?, updated_at = CURRENT_TIMESTAMP WHERE job_id = ?\",\n",
    "            (status, job_id)\n",
    "        )\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"EXTENDED PROCESSING COMPLETE\")\n",
    "        print(f\"   Job ID: {job_id}\")\n",
    "        print(f\"   Variables processed: {len(analyzed_data)}\")\n",
    "        print(f\"   Status: {status}\")\n",
    "        if enforce_conventions:\n",
    "            print(f\"   Conventions documented: \u2713\")\n",
    "        if enable_versioning:\n",
    "            print(f\"   Versions tracked: \u2713\")\n",
    "        if document_higher_levels:\n",
    "            print(f\"   Higher-level docs: {len(potential_instruments)} instruments\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        return job_id\n",
    "\n",
    "    def update_documentation(self, element_id: str, new_content: str,\n",
    "                            element_type: str = \"variable\", author: str = \"user\") -> Dict:\n",
    "        \"\"\"\n",
    "        Update documentation for an element with version control.\n",
    "\n",
    "        Args:\n",
    "            element_id: ID of the element to update\n",
    "            new_content: New documentation content\n",
    "            element_type: Type of element (variable, instrument, segment)\n",
    "            author: Who is making the change\n",
    "\n",
    "        Returns:\n",
    "            Version control result\n",
    "        \"\"\"\n",
    "        print(f\"Updating {element_type}: {element_id}\")\n",
    "\n",
    "        # Apply design improvement to new content\n",
    "        print(\"   Applying design improvements...\")\n",
    "        design_result = self.design_improvement.improve_design(new_content)\n",
    "        improved_content = design_result.get('improved_content', new_content)\n",
    "\n",
    "        # Create new version\n",
    "        version_result = self.version_control.create_version(\n",
    "            element_id=element_id,\n",
    "            element_type=element_type,\n",
    "            content=improved_content,\n",
    "            author=author\n",
    "        )\n",
    "\n",
    "        if version_result.get('status') == 'success':\n",
    "            print(f\"   \u2713 Created version {version_result['new_version']}\")\n",
    "        else:\n",
    "            print(f\"   \u26a0\ufe0f  {version_result.get('message', 'Unknown status')}\")\n",
    "\n",
    "        return version_result\n",
    "\n",
    "    def get_element_history(self, element_id: str) -> List[Dict]:\n",
    "        \"\"\"Get version history for a documentation element.\"\"\"\n",
    "        return self.version_control.get_version_history(element_id)\n",
    "\n",
    "    def rollback_element(self, element_id: str, target_version: str) -> Dict:\n",
    "        \"\"\"Rollback an element to a previous version.\"\"\"\n",
    "        return self.version_control.rollback_to_version(element_id, target_version)\n",
    "\n",
    "    def finalize_documentation(self, job_id: str, output_file: str = \"documentation.md\") -> str:\n",
    "        \"\"\"Assemble and save final documentation.\"\"\"\n",
    "        print(f\"\\n\ud83d\udcdd Assembling final documentation for job {job_id}...\")\n",
    "        final_doc = self.assembler.assemble(job_id)\n",
    "\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(final_doc)\n",
    "\n",
    "        print(f\"\u2713 Documentation saved to {output_file}\")\n",
    "        logger.info(f\"Final documentation saved: {output_file}\")\n",
    "        return final_doc\n",
    "\n",
    "    def validate_pipeline_outputs(self, job_id: str, parsed_data: List[Dict] = None,\n",
    "                                   analyzed_data: List[Dict] = None,\n",
    "                                   enriched_data: List[Dict] = None,\n",
    "                                   documentation: List[str] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Run validation checks on pipeline outputs.\n",
    "\n",
    "        Args:\n",
    "            job_id: The job ID for tracking\n",
    "            parsed_data: Output from DataParserAgent\n",
    "            analyzed_data: Output from TechnicalAnalyzerAgent\n",
    "            enriched_data: Output with ontology mappings\n",
    "            documentation: Generated documentation\n",
    "\n",
    "        Returns:\n",
    "            Comprehensive validation report\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"VALIDATION: Job {job_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        validations = []\n",
    "\n",
    "        # Validate parsed data\n",
    "        if parsed_data:\n",
    "            print(\"\\n\ud83d\udd0d Validating parsed data...\")\n",
    "            parsed_validation = self.validation.validate_parsed_data(parsed_data)\n",
    "            validations.append(parsed_validation)\n",
    "            score = parsed_validation.get('overall_score', 0)\n",
    "            passed = \"\u2713\" if parsed_validation.get('validation_passed', False) else \"\u2717\"\n",
    "            print(f\"   {passed} Parsed data validation: {score}/100\")\n",
    "            issues = len(parsed_validation.get('issues_found', []))\n",
    "            if issues > 0:\n",
    "                print(f\"      Issues found: {issues}\")\n",
    "\n",
    "        # Validate technical analysis\n",
    "        if analyzed_data:\n",
    "            print(\"\\n\ud83d\udd0d Validating technical analysis...\")\n",
    "            analysis_validation = self.validation.validate_technical_analysis(analyzed_data)\n",
    "            validations.append(analysis_validation)\n",
    "            score = analysis_validation.get('overall_score', 0)\n",
    "            passed = \"\u2713\" if analysis_validation.get('validation_passed', False) else \"\u2717\"\n",
    "            print(f\"   {passed} Technical analysis validation: {score}/100\")\n",
    "            issues = len(analysis_validation.get('issues_found', []))\n",
    "            if issues > 0:\n",
    "                print(f\"      Issues found: {issues}\")\n",
    "\n",
    "        # Validate ontology mappings\n",
    "        if enriched_data:\n",
    "            print(\"\\n\ud83d\udd0d Validating ontology mappings...\")\n",
    "            ontology_validation = self.validation.validate_ontology_mappings(enriched_data)\n",
    "            validations.append(ontology_validation)\n",
    "            score = ontology_validation.get('overall_score', 0)\n",
    "            passed = \"\u2713\" if ontology_validation.get('validation_passed', False) else \"\u2717\"\n",
    "            print(f\"   {passed} Ontology mappings validation: {score}/100\")\n",
    "            issues = len(ontology_validation.get('issues_found', []))\n",
    "            if issues > 0:\n",
    "                print(f\"      Issues found: {issues}\")\n",
    "\n",
    "        # Validate documentation\n",
    "        if documentation:\n",
    "            print(\"\\n\ud83d\udd0d Validating documentation...\")\n",
    "            for idx, doc in enumerate(documentation[:5]):  # Validate first 5\n",
    "                doc_validation = self.validation.validate_documentation(doc)\n",
    "                validations.append(doc_validation)\n",
    "            avg_score = sum(v.get('overall_score', 0) for v in validations[-len(documentation[:5]):]) / min(5, len(documentation))\n",
    "            print(f\"   Documentation validation avg score: {avg_score:.1f}/100\")\n",
    "\n",
    "        # Cross-validate all agent outputs\n",
    "        if any([parsed_data, analyzed_data, enriched_data]):\n",
    "            print(\"\\n\ud83d\udd0d Cross-validating agent outputs...\")\n",
    "            cross_validation = self.validation.cross_validate_agents({\n",
    "                'parsed_data': parsed_data[:5] if parsed_data else [],\n",
    "                'analyzed_data': analyzed_data[:5] if analyzed_data else [],\n",
    "                'enriched_data': enriched_data[:5] if enriched_data else []\n",
    "            })\n",
    "            validations.append(cross_validation)\n",
    "            score = cross_validation.get('overall_score', 0)\n",
    "            passed = \"\u2713\" if cross_validation.get('validation_passed', False) else \"\u2717\"\n",
    "            print(f\"   {passed} Cross-validation score: {score}/100\")\n",
    "\n",
    "        # Generate validation report\n",
    "        print(\"\\n\ud83d\udccb Generating validation report...\")\n",
    "        report = self.validation.generate_validation_report(validations)\n",
    "\n",
    "        # Calculate overall results\n",
    "        total_passed = sum(1 for v in validations if v.get('validation_passed', False))\n",
    "        overall_score = sum(v.get('overall_score', 0) for v in validations) / max(len(validations), 1)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"VALIDATION COMPLETE\")\n",
    "        print(f\"   Total checks: {len(validations)}\")\n",
    "        print(f\"   Passed: {total_passed}/{len(validations)}\")\n",
    "        print(f\"   Overall score: {overall_score:.1f}/100\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        return {\n",
    "            'job_id': job_id,\n",
    "            'total_validations': len(validations),\n",
    "            'passed': total_passed,\n",
    "            'overall_score': overall_score,\n",
    "            'individual_validations': validations,\n",
    "            'report': report\n",
    "        }\n",
    "\n",
    "    def process_with_validation(self, source_data: str, source_file: str = \"input.csv\",\n",
    "                                auto_approve: bool = False,\n",
    "                                apply_design_improvement: bool = True,\n",
    "                                enforce_conventions: bool = True,\n",
    "                                enable_versioning: bool = True,\n",
    "                                document_higher_levels: bool = True,\n",
    "                                enable_validation: bool = True) -> Tuple[str, Dict]:\n",
    "        \"\"\"\n",
    "        Full pipeline with validation at each stage.\n",
    "\n",
    "        Args:\n",
    "            source_data: The raw data dictionary content\n",
    "            source_file: Name of the source file\n",
    "            auto_approve: If True, automatically approve all generated content\n",
    "            apply_design_improvement: Use DesignImprovementAgent\n",
    "            enforce_conventions: Use DataConventionsAgent\n",
    "            enable_versioning: Use VersionControlAgent\n",
    "            document_higher_levels: Use HigherLevelDocumentationAgent\n",
    "            enable_validation: Use ValidationAgent to validate outputs\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (job_id, validation_results)\n",
    "        \"\"\"\n",
    "        job_id = self.create_job(source_file)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"VALIDATED PROCESSING: Job {job_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"   Validation: {'ON' if enable_validation else 'OFF'}\")\n",
    "\n",
    "        # Step 1: Parse data\n",
    "        print(\"\\n\ud83d\udcca Step 1: Parsing Data...\")\n",
    "        parsed_data = self.data_parser.parse_csv(source_data)\n",
    "        print(f\"   \u2713 Parsed {len(parsed_data)} variables\")\n",
    "\n",
    "        # Step 2: Technical analysis\n",
    "        print(\"\\n\ud83d\udd2c Step 2: Technical Analysis...\")\n",
    "        analyzed_data = self.technical_analyzer.analyze(parsed_data)\n",
    "        print(f\"   \u2713 Analyzed {len(analyzed_data)} variables\")\n",
    "\n",
    "        # Step 3: Ontology mapping\n",
    "        print(\"\\n\ud83c\udfe5 Step 3: Ontology Mapping & Documentation...\")\n",
    "        enriched_data = []\n",
    "        all_documentation = []\n",
    "\n",
    "        for i, var_data in enumerate(analyzed_data, 1):\n",
    "            var_name = var_data.get('variable_name', var_data.get('original_name', 'Unknown'))\n",
    "            print(f\"   Processing {i}/{len(analyzed_data)}: {var_name}\")\n",
    "\n",
    "            ontology_result = self.domain_ontology.map_ontologies(var_data)\n",
    "            enriched = {**var_data, **ontology_result}\n",
    "            enriched_data.append(enriched)\n",
    "\n",
    "            documentation = self.plain_language.document_variable(enriched)\n",
    "\n",
    "            if apply_design_improvement:\n",
    "                design_result = self.design_improvement.improve_design(documentation)\n",
    "                if design_result.get('improved_content'):\n",
    "                    documentation = design_result['improved_content']\n",
    "\n",
    "            all_documentation.append(documentation)\n",
    "\n",
    "            item_id = self.review_queue.add_item(\n",
    "                job_id=job_id,\n",
    "                source_agent=\"PlainLanguageAgent\",\n",
    "                source_data=json.dumps(enriched),\n",
    "                generated_content=documentation\n",
    "            )\n",
    "\n",
    "            if auto_approve:\n",
    "                self.review_queue.approve_item(item_id)\n",
    "\n",
    "        # Step 4: Validation\n",
    "        validation_results = {}\n",
    "        if enable_validation:\n",
    "            validation_results = self.validate_pipeline_outputs(\n",
    "                job_id=job_id,\n",
    "                parsed_data=parsed_data,\n",
    "                analyzed_data=analyzed_data,\n",
    "                enriched_data=enriched_data,\n",
    "                documentation=all_documentation\n",
    "            )\n",
    "\n",
    "            # Check if validation passed\n",
    "            if validation_results.get('overall_score', 0) < 70:\n",
    "                print(\"\\n\u26a0\ufe0f  WARNING: Validation score below threshold (70)\")\n",
    "                print(\"   Consider reviewing the issues before approving\")\n",
    "\n",
    "        # Update job status\n",
    "        status = 'Completed' if auto_approve else 'Pending Review'\n",
    "        self.db.execute_update(\n",
    "            \"UPDATE Jobs SET status = ?, updated_at = CURRENT_TIMESTAMP WHERE job_id = ?\",\n",
    "            (status, job_id)\n",
    "        )\n",
    "\n",
    "        print(f\"\\n\u2713 Processing complete! Job status: {status}\")\n",
    "        return job_id, validation_results\n",
    "\n",
    "print(\"\u2713 Orchestrator class defined with extended agent support\")\n",
    "print(\"   New methods:\")\n",
    "print(\"   - process_with_extended_agents(): Full pipeline with all agents\")\n",
    "print(\"   - process_with_validation(): Pipeline with validation checks\")\n",
    "print(\"   - validate_pipeline_outputs(): Validate outputs for quality\")\n",
    "print(\"   - update_documentation(): Update with version control\")\n",
    "print(\"   - get_element_history(): View version history\")\n",
    "print(\"   - rollback_element(): Revert to previous versions\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmkmrLsTg3Xh",
    "outputId": "8c066b5d-6b19-40a3-f5e3-7dff8b9b9a8b"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Orchestrator class defined with extended agent support\n",
      "   New methods:\n",
      "   - process_with_extended_agents(): Full pipeline with all agents\n",
      "   - process_with_validation(): Pipeline with validation checks\n",
      "   - validate_pipeline_outputs(): Validate outputs for quality\n",
      "   - update_documentation(): Update with version control\n",
      "   - get_element_history(): View version history\n",
      "   - rollback_element(): Revert to previous versions\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giPSNiElg3Xi"
   },
   "source": [
    "## 7. Orchestrator - Agent Workflow ManagementThe Orchestrator manages data flow through the agent pipeline and coordinates HITL workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noHdXumbg3Xi",
    "outputId": "a872f01b-a730-4b20-a358-9905bc08d7b8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Orchestrator class defined with complete pipeline support\n"
     ]
    }
   ],
   "source": [
    "class Orchestrator:\n",
    "    \"\"\"Manages the workflow of agents and coordinates the documentation pipeline.\"\"\"\n",
    "\n",
    "    def __init__(self, db_manager: DatabaseManager, api_config: APIConfig = None):\n",
    "        self.db = db_manager\n",
    "        self.config = api_config or API_CONFIG\n",
    "        self.snippet_manager = SnippetManager(db_manager)\n",
    "        self.review_queue = ReviewQueueManager(db_manager)\n",
    "\n",
    "        # Initialize agents with configuration\n",
    "        self.data_parser = DataParserAgent(config=self.config)\n",
    "        self.technical_analyzer = TechnicalAnalyzerAgent(config=self.config)\n",
    "        self.domain_ontology = DomainOntologyAgent(config=self.config)\n",
    "        self.plain_language = PlainLanguageAgent(config=self.config)\n",
    "        self.assembler = DocumentationAssemblerAgent(self.review_queue, config=self.config)\n",
    "\n",
    "        logger.info(f\"Orchestrator initialized with {self.config.requests_per_minute} req/min limit\")\n",
    "        print(f\"\u2713 Orchestrator initialized with {self.config.requests_per_minute} req/min limit\")\n",
    "\n",
    "    def create_job(self, source_file: str) -> str:\n",
    "        \"\"\"Create a new documentation job.\"\"\"\n",
    "        job_id = hashlib.md5(f\"{source_file}_{datetime.now().isoformat()}\".encode()).hexdigest()[:12]\n",
    "        query = \"INSERT INTO Jobs (job_id, source_file, status) VALUES (?, ?, 'Running')\"\n",
    "        self.db.execute_update(query, (job_id, source_file))\n",
    "        logger.info(f\"Created job {job_id} for {source_file}\")\n",
    "        return job_id\n",
    "\n",
    "    def process_data_dictionary(self, source_data: str, source_file: str = \"input.csv\",\n",
    "                                auto_approve: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        Main workflow: Process a data dictionary through the agent pipeline.\n",
    "\n",
    "        Args:\n",
    "            source_data: The raw data dictionary content\n",
    "            source_file: Name of the source file\n",
    "            auto_approve: If True, automatically approve all generated content\n",
    "\n",
    "        Returns:\n",
    "            job_id: The ID of the created job\n",
    "        \"\"\"\n",
    "        job_id = self.create_job(source_file)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing Job: {job_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Step 1: Parse data\n",
    "        print(\"\\n\ud83d\udcca Step 1: Parsing Data...\")\n",
    "        parsed_data = self.data_parser.parse_csv(source_data)\n",
    "        print(f\"   \u2713 Parsed {len(parsed_data)} variables\")\n",
    "\n",
    "        # Step 2: Technical analysis\n",
    "        print(\"\\n\ud83d\udd2c Step 2: Technical Analysis...\")\n",
    "        analyzed_data = self.technical_analyzer.analyze(parsed_data)\n",
    "        print(f\"   \u2713 Analyzed {len(analyzed_data)} variables\")\n",
    "\n",
    "        # Check for clarifications needed\n",
    "        needs_clarification = [v for v in analyzed_data if v.get('needs_clarification', False)]\n",
    "        if needs_clarification:\n",
    "            print(f\"   \u26a0\ufe0f  {len(needs_clarification)} variables need clarification\")\n",
    "            for var in needs_clarification:\n",
    "                print(f\"      - {var['original_name']}: {var.get('clarification_question', 'Unknown')}\")\n",
    "\n",
    "        # Step 3: Ontology mapping and documentation\n",
    "        print(\"\\n\ud83c\udfe5 Step 3: Ontology Mapping & Documentation...\")\n",
    "        for i, var_data in enumerate(analyzed_data, 1):\n",
    "            print(f\"   Processing {i}/{len(analyzed_data)}: {var_data.get('variable_name', var_data.get('original_name'))}\")\n",
    "\n",
    "            # Map to ontologies\n",
    "            ontology_result = self.domain_ontology.map_ontologies(var_data)\n",
    "\n",
    "            # Enrich with ontology data\n",
    "            enriched_data = {**var_data, **ontology_result}\n",
    "\n",
    "            # Generate plain language documentation\n",
    "            documentation = self.plain_language.document_variable(enriched_data)\n",
    "\n",
    "            # Add to review queue\n",
    "            item_id = self.review_queue.add_item(\n",
    "                job_id=job_id,\n",
    "                source_agent=\"PlainLanguageAgent\",\n",
    "                source_data=json.dumps(enriched_data),\n",
    "                generated_content=documentation\n",
    "            )\n",
    "\n",
    "            if auto_approve:\n",
    "                self.review_queue.approve_item(item_id)\n",
    "\n",
    "        # Update job status\n",
    "        status = 'Completed' if auto_approve else 'Pending Review'\n",
    "        self.db.execute_update(\n",
    "            \"UPDATE Jobs SET status = ?, updated_at = CURRENT_TIMESTAMP WHERE job_id = ?\",\n",
    "            (status, job_id)\n",
    "        )\n",
    "\n",
    "        print(f\"\\n\u2713 Processing complete! Job status: {status}\")\n",
    "        return job_id\n",
    "\n",
    "    def finalize_documentation(self, job_id: str, output_file: str = \"documentation.md\") -> str:\n",
    "        \"\"\"Assemble and save final documentation.\"\"\"\n",
    "        print(f\"\\n\ud83d\udcdd Assembling final documentation for job {job_id}...\")\n",
    "        final_doc = self.assembler.assemble(job_id)\n",
    "\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(final_doc)\n",
    "\n",
    "        print(f\"\u2713 Documentation saved to {output_file}\")\n",
    "        logger.info(f\"Final documentation saved: {output_file}\")\n",
    "        return final_doc\n",
    "\n",
    "print(\"\u2713 Orchestrator class defined with complete pipeline support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.1 Batch Processing for Large Codebooks\n",
    "\n",
    "Process large data dictionaries in batches to avoid context limits and manage API rate limiting effectively."
   ],
   "metadata": {
    "id": "P3K0U3NGg3Xj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class BatchConfig:\n",
    "    \"\"\"Configuration for batch processing of large codebooks.\"\"\"\n",
    "    batch_size: int = 10  # Default number of variables per batch\n",
    "    min_batch_size: int = 3  # Minimum batch size to avoid splitting too small\n",
    "    group_related_variables: bool = True  # Try to keep related variables together\n",
    "    progress_tracking: bool = True  # Show progress during processing\n",
    "\n",
    "@dataclass\n",
    "class BatchResult:\n",
    "    \"\"\"Result of processing a single batch.\"\"\"\n",
    "    batch_id: int\n",
    "    variables_processed: int\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "\n",
    "class BatchProcessor:\n",
    "    \"\"\"\n",
    "    Handles batch processing of large data dictionaries.\n",
    "\n",
    "    Features:\n",
    "    - Automatic chunking with configurable batch size\n",
    "    - Sensitivity to not splitting related variables between chunks\n",
    "    - Progress tracking with resume capability\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, orchestrator: Orchestrator, config: BatchConfig = None):\n",
    "        self.orchestrator = orchestrator\n",
    "        self.config = config or BatchConfig()\n",
    "        self.logger = logging.getLogger('ADE.BatchProcessor')\n",
    "\n",
    "    def _identify_variable_groups(self, parsed_data: List[Dict]) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Identify groups of related variables that should stay together.\n",
    "\n",
    "        Groups variables by common prefixes (e.g., bp_systolic, bp_diastolic)\n",
    "        or related semantic meaning.\n",
    "        \"\"\"\n",
    "        if not self.config.group_related_variables:\n",
    "            return [[i] for i in range(len(parsed_data))]\n",
    "\n",
    "        groups = []\n",
    "        used_indices = set()\n",
    "\n",
    "        # Group by common prefixes\n",
    "        for i, var in enumerate(parsed_data):\n",
    "            if i in used_indices:\n",
    "                continue\n",
    "\n",
    "            var_name = var.get('original_name', var.get('Variable Name', '')).lower()\n",
    "            if not var_name:\n",
    "                groups.append([i])\n",
    "                used_indices.add(i)\n",
    "                continue\n",
    "\n",
    "            # Extract prefix (e.g., \"bp\" from \"bp_systolic\")\n",
    "            parts = var_name.replace('-', '_').split('_')\n",
    "            if len(parts) > 1:\n",
    "                prefix = parts[0]\n",
    "                group = [i]\n",
    "                used_indices.add(i)\n",
    "\n",
    "                # Find other variables with same prefix\n",
    "                for j, other_var in enumerate(parsed_data):\n",
    "                    if j in used_indices:\n",
    "                        continue\n",
    "                    other_name = other_var.get('original_name', other_var.get('Variable Name', '')).lower()\n",
    "                    if other_name.startswith(prefix + '_') or other_name.startswith(prefix + '-'):\n",
    "                        group.append(j)\n",
    "                        used_indices.add(j)\n",
    "\n",
    "                groups.append(group)\n",
    "            else:\n",
    "                groups.append([i])\n",
    "                used_indices.add(i)\n",
    "\n",
    "        return groups\n",
    "\n",
    "    def _create_batches(self, parsed_data: List[Dict]) -> List[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Create batches of variables, respecting group boundaries.\n",
    "\n",
    "        Returns a list of batches, where each batch is a list of variable dicts.\n",
    "        \"\"\"\n",
    "        groups = self._identify_variable_groups(parsed_data)\n",
    "        batches = []\n",
    "        current_batch = []\n",
    "        current_batch_size = 0\n",
    "\n",
    "        for group_indices in groups:\n",
    "            group_size = len(group_indices)\n",
    "            group_vars = [parsed_data[i] for i in group_indices]\n",
    "\n",
    "            # If adding this group would exceed batch size\n",
    "            if current_batch_size + group_size > self.config.batch_size:\n",
    "                # If current batch has something, save it\n",
    "                if current_batch and current_batch_size >= self.config.min_batch_size:\n",
    "                    batches.append(current_batch)\n",
    "                    current_batch = group_vars\n",
    "                    current_batch_size = group_size\n",
    "                elif current_batch:\n",
    "                    # Current batch too small, add group anyway\n",
    "                    current_batch.extend(group_vars)\n",
    "                    current_batch_size += group_size\n",
    "                else:\n",
    "                    # No current batch, start with this group\n",
    "                    current_batch = group_vars\n",
    "                    current_batch_size = group_size\n",
    "            else:\n",
    "                current_batch.extend(group_vars)\n",
    "                current_batch_size += group_size\n",
    "\n",
    "        # Add remaining batch\n",
    "        if current_batch:\n",
    "            batches.append(current_batch)\n",
    "\n",
    "        return batches\n",
    "\n",
    "    def process_large_codebook(self, source_data: str, source_file: str = \"input.csv\",\n",
    "                               auto_approve: bool = False) -> Tuple[str, List[BatchResult]]:\n",
    "        \"\"\"\n",
    "        Process a large data dictionary in batches.\n",
    "\n",
    "        Args:\n",
    "            source_data: The raw data dictionary content\n",
    "            source_file: Name of the source file\n",
    "            auto_approve: If True, automatically approve all generated content\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (job_id, list of batch results)\n",
    "        \"\"\"\n",
    "        # Create job\n",
    "        job_id = self.orchestrator.create_job(source_file)\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"BATCH PROCESSING: Job {job_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Step 1: Parse all data first\n",
    "        print(\"\\n\ud83d\udcca Step 1: Parsing entire data dictionary...\")\n",
    "        parsed_data = self.orchestrator.data_parser.parse_csv(source_data)\n",
    "        total_variables = len(parsed_data)\n",
    "        print(f\"   \u2713 Parsed {total_variables} variables total\")\n",
    "\n",
    "        # Step 2: Create batches\n",
    "        print(f\"\\n\ud83d\udce6 Step 2: Creating batches (target size: {self.config.batch_size})...\")\n",
    "        batches = self._create_batches(parsed_data)\n",
    "        num_batches = len(batches)\n",
    "        print(f\"   \u2713 Created {num_batches} batches\")\n",
    "        for i, batch in enumerate(batches, 1):\n",
    "            var_names = [v.get('original_name', v.get('Variable Name', 'Unknown'))[:20] for v in batch]\n",
    "            print(f\"      Batch {i}: {len(batch)} variables - {', '.join(var_names[:3])}{'...' if len(var_names) > 3 else ''}\")\n",
    "\n",
    "        # Step 3: Process each batch\n",
    "        results = []\n",
    "        all_analyzed_data = []\n",
    "\n",
    "        print(f\"\\n\ud83d\udd2c Step 3: Processing batches...\")\n",
    "        for batch_id, batch_vars in enumerate(batches, 1):\n",
    "            if self.config.progress_tracking:\n",
    "                print(f\"\\n   --- Batch {batch_id}/{num_batches} ({len(batch_vars)} variables) ---\")\n",
    "\n",
    "            try:\n",
    "                # Technical analysis for this batch\n",
    "                print(f\"   Analyzing batch {batch_id}...\")\n",
    "                analyzed_batch = self.orchestrator.technical_analyzer.analyze(batch_vars)\n",
    "                all_analyzed_data.extend(analyzed_batch)\n",
    "\n",
    "                # Process ontology and documentation for each variable in batch\n",
    "                for i, var_data in enumerate(analyzed_batch, 1):\n",
    "                    var_name = var_data.get('variable_name', var_data.get('original_name', 'Unknown'))\n",
    "                    if self.config.progress_tracking:\n",
    "                        print(f\"      {i}/{len(analyzed_batch)}: {var_name}\")\n",
    "\n",
    "                    # Map to ontologies\n",
    "                    ontology_result = self.orchestrator.domain_ontology.map_ontologies(var_data)\n",
    "                    enriched_data = {**var_data, **ontology_result}\n",
    "\n",
    "                    # Generate documentation\n",
    "                    documentation = self.orchestrator.plain_language.document_variable(enriched_data)\n",
    "\n",
    "                    # Add to review queue\n",
    "                    item_id = self.orchestrator.review_queue.add_item(\n",
    "                        job_id=job_id,\n",
    "                        source_agent=\"PlainLanguageAgent\",\n",
    "                        source_data=json.dumps(enriched_data),\n",
    "                        generated_content=documentation\n",
    "                    )\n",
    "\n",
    "                    if auto_approve:\n",
    "                        self.orchestrator.review_queue.approve_item(item_id)\n",
    "\n",
    "                results.append(BatchResult(\n",
    "                    batch_id=batch_id,\n",
    "                    variables_processed=len(batch_vars),\n",
    "                    success=True\n",
    "                ))\n",
    "                print(f\"   \u2713 Batch {batch_id} complete\")\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                self.logger.error(f\"Batch {batch_id} failed: {error_msg}\")\n",
    "                results.append(BatchResult(\n",
    "                    batch_id=batch_id,\n",
    "                    variables_processed=0,\n",
    "                    success=False,\n",
    "                    error_message=error_msg\n",
    "                ))\n",
    "                print(f\"   \u2717 Batch {batch_id} failed: {error_msg}\")\n",
    "\n",
    "        # Update job status\n",
    "        successful_batches = sum(1 for r in results if r.success)\n",
    "        if successful_batches == num_batches:\n",
    "            status = 'Completed' if auto_approve else 'Pending Review'\n",
    "        elif successful_batches > 0:\n",
    "            status = 'Paused'  # Partial success\n",
    "        else:\n",
    "            status = 'Failed'\n",
    "\n",
    "        self.orchestrator.db.execute_update(\n",
    "            \"UPDATE Jobs SET status = ?, updated_at = CURRENT_TIMESTAMP WHERE job_id = ?\",\n",
    "            (status, job_id)\n",
    "        )\n",
    "\n",
    "        # Summary\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"BATCH PROCESSING SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"   Job ID: {job_id}\")\n",
    "        print(f\"   Total variables: {total_variables}\")\n",
    "        print(f\"   Batches processed: {successful_batches}/{num_batches}\")\n",
    "        print(f\"   Variables documented: {sum(r.variables_processed for r in results if r.success)}\")\n",
    "        print(f\"   Status: {status}\")\n",
    "\n",
    "        if not auto_approve:\n",
    "            print(f\"\\n   \u26a0\ufe0f  Items awaiting manual review in queue\")\n",
    "\n",
    "        return job_id, results\n",
    "\n",
    "# Example configuration for different scenarios\n",
    "SMALL_CODEBOOK_CONFIG = BatchConfig(batch_size=5, min_batch_size=2)\n",
    "MEDIUM_CODEBOOK_CONFIG = BatchConfig(batch_size=10, min_batch_size=3)\n",
    "LARGE_CODEBOOK_CONFIG = BatchConfig(batch_size=20, min_batch_size=5)\n",
    "\n",
    "print(\"\u2713 BatchProcessor loaded for large codebook handling\")\n",
    "print(f\"   - Default batch size: {BatchConfig().batch_size}\")\n",
    "print(f\"   - Groups related variables: {BatchConfig().group_related_variables}\")\n",
    "print(f\"   - Available configs: SMALL_CODEBOOK_CONFIG, MEDIUM_CODEBOOK_CONFIG, LARGE_CODEBOOK_CONFIG\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBSHvjC7g3Xj",
    "outputId": "b806a55c-244e-4339-af87-2b92668699f7"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 BatchProcessor loaded for large codebook handling\n",
      "   - Default batch size: 10\n",
      "   - Groups related variables: True\n",
      "   - Available configs: SMALL_CODEBOOK_CONFIG, MEDIUM_CODEBOOK_CONFIG, LARGE_CODEBOOK_CONFIG\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-vpWegNg3Xj"
   },
   "source": [
    "## 8. Example Data DictionariesSample healthcare data dictionaries for testing the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kC30NeWIg3Xj",
    "outputId": "557409ef-a1ee-407f-fa9a-c18775e642a7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Sample data dictionaries loaded\n",
      "   - Basic diabetes study: 7 variables\n",
      "   - EHR example: 15 variables\n"
     ]
    }
   ],
   "source": [
    "# Basic diabetes study example\n",
    "sample_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
    "patient_id,text,Patient ID,,Unique identifier\n",
    "age,integer,Age (years),,Age at enrollment\n",
    "sex,radio,Biological Sex,\"1, Male | 2, Female | 3, Other\",\n",
    "bp_systolic,integer,Systolic Blood Pressure (mmHg),,\n",
    "bp_diastolic,integer,Diastolic Blood Pressure (mmHg),,\n",
    "diagnosis_date,date,Diagnosis Date,,Date of primary diagnosis\n",
    "hba1c,decimal,Hemoglobin A1c (%),,Glycated hemoglobin\"\"\"\n",
    "\n",
    "# EHR example\n",
    "ehr_data_dictionary = \"\"\"Variable Name,Field Type,Field Label,Choices,Notes\n",
    "mrn,text,Medical Record Number,,Unique patient identifier\n",
    "encounter_id,text,Encounter ID,,Unique visit identifier\n",
    "visit_date,date,Visit Date,,Date of clinical encounter\n",
    "chief_complaint,text,Chief Complaint,,Primary reason for visit\n",
    "dx_code,text,Diagnosis Code (ICD-10),,Primary diagnosis\n",
    "bp_systolic,integer,Systolic BP (mmHg),,\"70-250, sitting position\"\n",
    "bp_diastolic,integer,Diastolic BP (mmHg),,\"40-150, sitting position\"\n",
    "heart_rate,integer,Heart Rate (bpm),,\"40-200\"\n",
    "temperature,decimal,Temperature (F),,\"95.0-106.0\"\n",
    "respiratory_rate,integer,Respiratory Rate (breaths/min),,\"8-40\"\n",
    "oxygen_sat,integer,Oxygen Saturation (%),,\"70-100, room air\"\n",
    "bmi,decimal,Body Mass Index,,Calculated from height/weight\n",
    "smoking_status,radio,Smoking Status,\"0, Never | 1, Former | 2, Current\",From social history\n",
    "medication_count,integer,Number of Active Medications,,Count of current prescriptions\n",
    "lab_ordered,yesno,Labs Ordered,\"0, No | 1, Yes\",Any lab tests ordered this visit\"\"\"\n",
    "\n",
    "print(\"\u2713 Sample data dictionaries loaded\")\n",
    "print(f\"   - Basic diabetes study: 7 variables\")\n",
    "print(f\"   - EHR example: 15 variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqOSuEfqg3Xj"
   },
   "source": [
    "## 9. Usage DemonstrationInitialize the orchestrator and process a data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDRKt8yqg3Xj",
    "outputId": "0b7b4b25-dfe5-4f01-e31e-d234febfe166"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Orchestrator initialized with 10 req/min limit\n",
      "\n",
      "Creating context snippets...\n",
      "   Created snippet 'OMOP_Mapping_Instructions'\n",
      "   Created snippet 'Project_Design_Notes'\n",
      "\n",
      "\u2713 Injected 2 snippets into agent context\n"
     ]
    }
   ],
   "source": [
    "# Initialize orchestrator\n",
    "orchestrator = Orchestrator(db)\n",
    "\n",
    "# Create context snippets for better agent performance\n",
    "print(\"\\nCreating context snippets...\")\n",
    "\n",
    "def create_or_update_snippet(name: str, snippet_type: SnippetType, content: str, metadata: Optional[Dict] = None):\n",
    "    existing_snippet = orchestrator.snippet_manager.get_snippet_by_name(name)\n",
    "    if existing_snippet:\n",
    "        orchestrator.snippet_manager.update_snippet(existing_snippet.snippet_id, content=content, metadata=metadata)\n",
    "        print(f\"   Updated snippet '{name}'\")\n",
    "    else:\n",
    "        orchestrator.snippet_manager.create_snippet(name, snippet_type, content, metadata)\n",
    "        print(f\"   Created snippet '{name}'\")\n",
    "\n",
    "# OMOP mapping instructions\n",
    "create_or_update_snippet(\n",
    "    name=\"OMOP_Mapping_Instructions\",\n",
    "    snippet_type=SnippetType.INSTRUCTION,\n",
    "    content=\"\"\"When mapping to OMOP CDM:\n",
    "- Blood pressure: OMOP concept_id 3004249 (Systolic), 3012888 (Diastolic)\n",
    "- HbA1c: OMOP concept_id 3004410\n",
    "- Age: Integer in years\n",
    "- Sex: OMOP gender concepts 8507 (Male), 8532 (Female)\"\"\")\n",
    "\n",
    "# Project design notes\n",
    "create_or_update_snippet(\n",
    "    name=\"Project_Design_Notes\",\n",
    "    snippet_type=SnippetType.DESIGN,\n",
    "    content=\"\"\"Diabetes research study collecting baseline clinical measurements.\n",
    "All measurements follow standard clinical protocols. Blood pressure measured in sitting position after 5 minutes rest. HbA1c measured using DCCT-aligned assay.\"\"\")\n",
    "\n",
    "# Inject snippets into agents\n",
    "snippets = orchestrator.snippet_manager.list_snippets()\n",
    "orchestrator.domain_ontology.inject_snippets(snippets)\n",
    "orchestrator.plain_language.inject_snippets(snippets)\n",
    "print(f\"\\n\u2713 Injected {len(snippets)} snippets into agent context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "AgGu9XXYg3Xk",
    "outputId": "60d32de4-ea94-4135-be4a-16b1c6b0c3e0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "Processing Job: 929edce9a99c\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcca Step 1: Parsing Data...\n",
      "   \u2713 Parsed 7 variables\n",
      "\n",
      "\ud83d\udd2c Step 2: Technical Analysis...\n",
      "   \u2713 Analyzed 7 variables\n",
      "\n",
      "\ud83c\udfe5 Step 3: Ontology Mapping & Documentation...\n",
      "   Processing 1/7: patient_id\n",
      "   Processing 2/7: age\n",
      "\u23f1\ufe0f  Rate limiting: waiting 4.2s...\n",
      "   Processing 3/7: sex\n",
      "\u23f1\ufe0f  Rate limiting: waiting 3.7s...\n",
      "   Processing 4/7: systolic_blood_pressure\n",
      "\u23f1\ufe0f  Rate limiting: waiting 2.6s...\n",
      "\u23f1\ufe0f  Rate limiting: waiting 0.6s...\n",
      "   Processing 5/7: diastolic_blood_pressure\n",
      "\u23f1\ufe0f  Rate limiting: waiting 2.4s...\n",
      "\u23f1\ufe0f  Rate limiting: waiting 0.3s...\n",
      "   Processing 6/7: diagnosis_date\n",
      "\u23f1\ufe0f  Rate limiting: waiting 2.4s...\n",
      "\u23f1\ufe0f  Rate limiting: waiting 0.8s...\n",
      "   Processing 7/7: hba1c\n",
      "\u23f1\ufe0f  Rate limiting: waiting 2.7s...\n",
      "\u23f1\ufe0f  Rate limiting: waiting 0.8s...\n",
      "\n",
      "\u2713 Processing complete! Job status: Completed\n",
      "\n",
      "============================================================\n",
      "Job ID: 929edce9a99c\n",
      "Auto-approve mode: ENABLED\n",
      "============================================================\n",
      "\n",
      "\u2713 All items automatically approved\n",
      "   Run next cell to generate final documentation\n"
     ]
    }
   ],
   "source": [
    "# Process the data dictionary\n",
    "# Set AUTO_APPROVE_MODE = True for testing, False for manual review\n",
    "AUTO_APPROVE_MODE = True\n",
    "\n",
    "job_id = orchestrator.process_data_dictionary(\n",
    "    source_data=sample_data_dictionary,\n",
    "    source_file=\"diabetes_study_data_dictionary.csv\",\n",
    "    auto_approve=AUTO_APPROVE_MODE\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Job ID: {job_id}\")\n",
    "print(f\"Auto-approve mode: {'ENABLED' if AUTO_APPROVE_MODE else 'DISABLED'}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if AUTO_APPROVE_MODE:\n",
    "    print(\"\\n\u2713 All items automatically approved\")\n",
    "    print(\"   Run next cell to generate final documentation\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  Items awaiting manual review\")\n",
    "    print(\"   Use review queue to approve/reject items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7aB4eETg3Xk",
    "outputId": "d7fd9ceb-ed4f-42d0-d19a-24ac40ddf88d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\ud83d\udcdd Assembling final documentation for job 929edce9a99c...\n",
      "\u2713 Documentation saved to healthcare_data_documentation.md\n",
      "\n",
      "=== Final Documentation Preview (first 2000 chars) ===\n",
      "# Healthcare Data Documentation\n",
      "\n",
      "**Generated:** 2025-11-17 21:26:28\n",
      "**Job ID:** 929edce9a99c\n",
      "\n",
      "---\n",
      "\n",
      "## Table of Contents\n",
      "\n",
      "1. [patient_id](#patient_id)\n",
      "2. [age](#age)\n",
      "3. [sex](#sex)\n",
      "4. [systolic_blood_pressure](#systolic_blood_pressure)\n",
      "5. [diastolic_blood_pressure](#diastolic_blood_pressure)\n",
      "6. [diagnosis_date](#diagnosis_date)\n",
      "7. [hba1c](#hba1c)\n",
      "\n",
      "---\n",
      "\n",
      "## Variable: patient_id\n",
      "\n",
      "**Description:** Unique identifier assigned to each patient in the study.\n",
      "\n",
      "**Technical Details:**\n",
      "- Data Type: text\n",
      "- Cardinality: required\n",
      "- Valid Values: Alphanumeric string.\n",
      "\n",
      "**Standard Ontology Mappings:**\n",
      "- None\n",
      "\n",
      "**Clinical Context:** Ensures accurate tracking of patient data across different measurements and analyses within the diabetes research study. Essential for linking baseline clinical measurements to individual patients.\n",
      "\n",
      "---\n",
      "\n",
      "## Variable: age\n",
      "\n",
      "**Description:** Patient's age at the time of enrollment, recorded in whole years.\n",
      "\n",
      "**Technical Details:**\n",
      "- Data Type: Integer\n",
      "- Cardinality: required\n",
      "- Valid Values: Non-negative integer representing age in years.\n",
      "\n",
      "**Standard Ontology Mappings:**\n",
      "- OMOP: age - Age\n",
      "\n",
      "**Clinical Context:** Age is a fundamental demographic variable and a critical risk factor for diabetes and related complications. It's essential for risk stratification, adjusting for confounding, and understanding disease prevalence across different age groups in our diabetes research study.\n",
      "\n",
      "---\n",
      "\n",
      "## Variable: sex\n",
      "\n",
      "**Description:**  The self-reported biological sex of the participant.\n",
      "\n",
      "**Technical Details:**\n",
      "- Data Type: categorical\n",
      "- Cardinality: required\n",
      "- Valid Values: Male, Female, Other\n",
      "\n",
      "**Standard Ontology Mappings:**\n",
      "- OMOP: 8507 - Male\n",
      "- OMOP: 8532 - Female\n",
      "\n",
      "**Clinical Context:**  Biological sex is a fundamental demographic variable that can influence the prevalence, presentation, and treatment response of many diseases, including diabetes.  Collecting this information is crucial for understanding potential sex-based differences in the study population and for appropri\n",
      "\n",
      "... [truncated]\n"
     ]
    }
   ],
   "source": [
    "# Generate final documentation\n",
    "final_documentation = orchestrator.finalize_documentation(\n",
    "    job_id=job_id,\n",
    "    output_file=\"healthcare_data_documentation.md\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Final Documentation Preview (first 2000 chars) ===\")\n",
    "print(final_documentation[:2000])\n",
    "\n",
    "if len(final_documentation) > 2000:\n",
    "    print(\"\\n... [truncated]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0lRdFoqg3Xk"
   },
   "source": [
    "## 9.5. Validation Testing and Troubleshooting\n",
    "\n",
    "This section provides comprehensive test methods for validating the ValidationAgent and troubleshooting common issues in the documentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSSyfv7Xg3Xk",
    "outputId": "e6726ded-49db-4988-efaf-4017af79a520"
   },
   "execution_count": 70,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ValidationTestFixtures loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Test Fixtures and Sample Data for Validation Testing\n",
    "class ValidationTestFixtures:\n",
    "    \"\"\"Test fixtures for ValidationAgent testing.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_valid_parsed_data():\n",
    "        \"\"\"Returns well-formed parsed data for testing.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"variable_name\": \"patient_id\",\n",
    "                \"field_type\": \"text\",\n",
    "                \"field_label\": \"Patient Identifier\",\n",
    "                \"choices\": \"\",\n",
    "                \"validation\": \"^[A-Z]{2}[0-9]{6}$\",\n",
    "                \"required\": True,\n",
    "                \"description\": \"Unique identifier for each patient\"\n",
    "            },\n",
    "            {\n",
    "                \"variable_name\": \"age_years\",\n",
    "                \"field_type\": \"integer\",\n",
    "                \"field_label\": \"Age in Years\",\n",
    "                \"choices\": \"\",\n",
    "                \"validation\": \"range(0, 120)\",\n",
    "                \"required\": True,\n",
    "                \"description\": \"Patient age at enrollment\"\n",
    "            },\n",
    "            {\n",
    "                \"variable_name\": \"diabetes_type\",\n",
    "                \"field_type\": \"radio\",\n",
    "                \"field_label\": \"Type of Diabetes\",\n",
    "                \"choices\": \"1, Type 1 | 2, Type 2 | 3, Gestational | 4, Other\",\n",
    "                \"validation\": \"\",\n",
    "                \"required\": True,\n",
    "                \"description\": \"Classification of diabetes diagnosis\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_malformed_parsed_data():\n",
    "        \"\"\"Returns malformed parsed data to test error handling.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"variable_name\": \"\",  # Empty name\n",
    "                \"field_type\": \"text\",\n",
    "                \"field_label\": \"Bad Variable\"\n",
    "                # Missing required fields\n",
    "            },\n",
    "            {\n",
    "                \"variable_name\": \"123_invalid\",  # Invalid naming\n",
    "                \"field_type\": \"unknown_type\",  # Invalid type\n",
    "                \"field_label\": \"\",  # Empty label\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_valid_technical_analysis():\n",
    "        \"\"\"Returns well-formed technical analysis data.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"variable_name\": \"patient_id\",\n",
    "                \"data_type\": \"string\",\n",
    "                \"constraints\": [\"unique\", \"not_null\", \"pattern_match\"],\n",
    "                \"relationships\": [],\n",
    "                \"statistical_properties\": {\n",
    "                    \"cardinality\": \"high\",\n",
    "                    \"null_percentage\": 0.0\n",
    "                },\n",
    "                \"quality_score\": 95\n",
    "            },\n",
    "            {\n",
    "                \"variable_name\": \"age_years\",\n",
    "                \"data_type\": \"integer\",\n",
    "                \"constraints\": [\"range_check\", \"not_null\"],\n",
    "                \"relationships\": [\"correlates_with_diagnosis_date\"],\n",
    "                \"statistical_properties\": {\n",
    "                    \"mean\": 54.2,\n",
    "                    \"std\": 12.8,\n",
    "                    \"min\": 18,\n",
    "                    \"max\": 89\n",
    "                },\n",
    "                \"quality_score\": 98\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_valid_ontology_mappings():\n",
    "        \"\"\"Returns well-formed ontology mappings.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"variable_name\": \"patient_id\",\n",
    "                \"ontology_mappings\": [\n",
    "                    {\n",
    "                        \"ontology\": \"SNOMED-CT\",\n",
    "                        \"code\": \"116154003\",\n",
    "                        \"term\": \"Patient\",\n",
    "                        \"confidence\": 0.95\n",
    "                    }\n",
    "                ],\n",
    "                \"semantic_type\": \"identifier\",\n",
    "                \"domain_context\": \"clinical_research\"\n",
    "            },\n",
    "            {\n",
    "                \"variable_name\": \"diabetes_type\",\n",
    "                \"ontology_mappings\": [\n",
    "                    {\n",
    "                        \"ontology\": \"SNOMED-CT\",\n",
    "                        \"code\": \"73211009\",\n",
    "                        \"term\": \"Diabetes mellitus\",\n",
    "                        \"confidence\": 0.98\n",
    "                    },\n",
    "                    {\n",
    "                        \"ontology\": \"ICD-10\",\n",
    "                        \"code\": \"E11\",\n",
    "                        \"term\": \"Type 2 diabetes mellitus\",\n",
    "                        \"confidence\": 0.92\n",
    "                    }\n",
    "                ],\n",
    "                \"semantic_type\": \"diagnosis_classification\",\n",
    "                \"domain_context\": \"endocrinology\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sample_documentation():\n",
    "        \"\"\"Returns sample plain language documentation.\"\"\"\n",
    "        return \"\"\"\n",
    "        # Patient Demographics Documentation\n",
    "\n",
    "        ## Overview\n",
    "        This section describes the core patient identification and demographic variables.\n",
    "\n",
    "        ## Variable: Patient ID (patient_id)\n",
    "        **Purpose**: Uniquely identifies each patient in the study.\n",
    "        **Format**: Two uppercase letters followed by six digits (e.g., AB123456)\n",
    "        **Data Type**: Text (String)\n",
    "        **Required**: Yes\n",
    "        **Example**: CA789012\n",
    "\n",
    "        ## Variable: Age in Years (age_years)\n",
    "        **Purpose**: Records the patient's age at the time of enrollment.\n",
    "        **Valid Range**: 0 to 120 years\n",
    "        **Data Type**: Integer\n",
    "        **Required**: Yes\n",
    "        **Clinical Significance**: Used for age-stratified analysis and eligibility screening.\n",
    "        \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_incomplete_documentation():\n",
    "        \"\"\"Returns incomplete documentation to test validation.\"\"\"\n",
    "        return \"\"\"\n",
    "        # Patient Data\n",
    "\n",
    "        ## patient_id\n",
    "        This is an ID field.\n",
    "\n",
    "        ## age_years\n",
    "        Age variable.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "print('ValidationTestFixtures loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0I86aaeTg3Xk"
   },
   "source": [
    "### Unit Tests for ValidationAgent Methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "shIM44zxg3Xk"
   },
   "execution_count": 71,
   "outputs": [],
   "source": [
    "class ValidationAgentTester:\n",
    "    \"\"\"Comprehensive test suite for ValidationAgent.\"\"\"\n",
    "\n",
    "    def __init__(self, validation_agent=None):\n",
    "        self.agent = validation_agent or ValidationAgent()\n",
    "        self.test_results = []\n",
    "        self.fixtures = ValidationTestFixtures()\n",
    "\n",
    "    def _log_result(self, test_name, passed, details=\"\"):\n",
    "        \"\"\"Log a test result.\"\"\"\n",
    "        result = {\n",
    "            \"test_name\": test_name,\n",
    "            \"passed\": passed,\n",
    "            \"details\": details,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        self.test_results.append(result)\n",
    "        status = \"PASS\" if passed else \"FAIL\"\n",
    "        print(f\"{status}: {test_name}\")\n",
    "        if details:\n",
    "            print(f\"   {details}\")\n",
    "\n",
    "    def test_validate_parsed_data_success(self):\n",
    "        \"\"\"Test validation of well-formed parsed data.\"\"\"\n",
    "        try:\n",
    "            data = self.fixtures.get_valid_parsed_data()\n",
    "            result = self.agent.validate_parsed_data(data)\n",
    "            passed = (\n",
    "                isinstance(result, dict) and\n",
    "                \"validation_passed\" in result and\n",
    "                \"overall_score\" in result and\n",
    "                result.get(\"overall_score\", 0) >= 70\n",
    "            )\n",
    "            self._log_result(\n",
    "                \"validate_parsed_data_success\",\n",
    "                passed,\n",
    "                f\"Score: {result.get('overall_score', 'N/A')}, Issues: {len(result.get('issues_found', []))}\"\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._log_result(\"validate_parsed_data_success\", False, str(e))\n",
    "            return None\n",
    "\n",
    "    def test_validate_parsed_data_malformed(self):\n",
    "        \"\"\"Test validation catches malformed data.\"\"\"\n",
    "        try:\n",
    "            data = self.fixtures.get_malformed_parsed_data()\n",
    "            result = self.agent.validate_parsed_data(data)\n",
    "            passed = (\n",
    "                isinstance(result, dict) and\n",
    "                len(result.get(\"issues_found\", [])) > 0\n",
    "            )\n",
    "            self._log_result(\n",
    "                \"validate_parsed_data_malformed\",\n",
    "                passed,\n",
    "                f\"Found {len(result.get('issues_found', []))} issues as expected\"\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._log_result(\"validate_parsed_data_malformed\", False, str(e))\n",
    "            return None\n",
    "\n",
    "    def test_validate_technical_analysis(self):\n",
    "        \"\"\"Test validation of technical analysis data.\"\"\"\n",
    "        try:\n",
    "            data = self.fixtures.get_valid_technical_analysis()\n",
    "            result = self.agent.validate_technical_analysis(data)\n",
    "            passed = (\n",
    "                isinstance(result, dict) and\n",
    "                \"validation_passed\" in result\n",
    "            )\n",
    "            self._log_result(\n",
    "                \"validate_technical_analysis\",\n",
    "                passed,\n",
    "                f\"Score: {result.get('overall_score', 'N/A')}\"\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._log_result(\"validate_technical_analysis\", False, str(e))\n",
    "            return None\n",
    "\n",
    "    def test_validate_ontology_mappings(self):\n",
    "        \"\"\"Test validation of ontology mappings.\"\"\"\n",
    "        try:\n",
    "            data = self.fixtures.get_valid_ontology_mappings()\n",
    "            result = self.agent.validate_ontology_mappings(data)\n",
    "            passed = isinstance(result, dict) and \"validation_passed\" in result\n",
    "            self._log_result(\n",
    "                \"validate_ontology_mappings\",\n",
    "                passed,\n",
    "                f\"Score: {result.get('overall_score', 'N/A')}\"\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._log_result(\"validate_ontology_mappings\", False, str(e))\n",
    "            return None\n",
    "\n",
    "    def test_validate_documentation_complete(self):\n",
    "        \"\"\"Test validation of complete documentation.\"\"\"\n",
    "        try:\n",
    "            doc = self.fixtures.get_sample_documentation()\n",
    "            result = self.agent.validate_documentation(doc)\n",
    "            passed = isinstance(result, dict) and result.get(\"overall_score\", 0) >= 70\n",
    "            self._log_result(\n",
    "                \"validate_documentation_complete\",\n",
    "                passed,\n",
    "                f\"Score: {result.get('overall_score', 'N/A')}\"\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._log_result(\"validate_documentation_complete\", False, str(e))\n",
    "            return None\n",
    "\n",
    "    def test_validate_documentation_incomplete(self):\n",
    "        \"\"\"Test validation catches incomplete documentation.\"\"\"\n",
    "        try:\n",
    "            doc = self.fixtures.get_incomplete_documentation()\n",
    "            result = self.agent.validate_documentation(doc)\n",
    "            passed = (\n",
    "                isinstance(result, dict) and\n",
    "                len(result.get(\"issues_found\", [])) > 0\n",
    "            )\n",
    "            self._log_result(\n",
    "                \"validate_documentation_incomplete\",\n",
    "                passed,\n",
    "                f\"Found {len(result.get('issues_found', []))} issues\"\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._log_result(\"validate_documentation_incomplete\", False, str(e))\n",
    "            return None\n",
    "\n",
    "    def test_cross_validation(self):\n",
    "        \"\"\"Test cross-validation between agent outputs.\"\"\"\n",
    "        try:\n",
    "            agent_outputs = {\n",
    "                \"parsed_data\": self.fixtures.get_valid_parsed_data(),\n",
    "                \"technical_analysis\": self.fixtures.get_valid_technical_analysis(),\n",
    "                \"ontology_mappings\": self.fixtures.get_valid_ontology_mappings(),\n",
    "                \"documentation\": self.fixtures.get_sample_documentation()\n",
    "            }\n",
    "            result = self.agent.cross_validate_agents(agent_outputs)\n",
    "            passed = isinstance(result, dict) and \"consistency_checks\" in result\n",
    "            self._log_result(\n",
    "                \"cross_validation\",\n",
    "                passed,\n",
    "                f\"Consistency checks performed\"\n",
    "            )\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._log_result(\"cross_validation\", False, str(e))\n",
    "            return None\n",
    "\n",
    "    def test_validation_report_generation(self):\n",
    "        \"\"\"Test validation report generation.\"\"\"\n",
    "        try:\n",
    "            validations = [\n",
    "                {\n",
    "                    \"validation_passed\": True,\n",
    "                    \"overall_score\": 85,\n",
    "                    \"issues_found\": [\n",
    "                        {\n",
    "                            \"severity\": \"warning\",\n",
    "                            \"category\": \"naming\",\n",
    "                            \"description\": \"Variable name could be more descriptive\",\n",
    "                            \"affected_field\": \"var1\",\n",
    "                            \"suggestion\": \"Use a more descriptive name\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"recommendations\": [\"Consider adding more documentation\"]\n",
    "                }\n",
    "            ]\n",
    "            report = self.agent.generate_validation_report(validations)\n",
    "            passed = isinstance(report, str) and len(report) > 50\n",
    "            self._log_result(\n",
    "                \"validation_report_generation\",\n",
    "                passed,\n",
    "                f\"Generated report with {len(report)} characters\"\n",
    "            )\n",
    "            return report\n",
    "        except Exception as e:\n",
    "            self._log_result(\"validation_report_generation\", False, str(e))\n",
    "            return None\n",
    "\n",
    "    def run_all_tests(self):\n",
    "        \"\"\"Run all validation tests.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"VALIDATION AGENT TEST SUITE\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        self.test_validate_parsed_data_success()\n",
    "        self.test_validate_parsed_data_malformed()\n",
    "        self.test_validate_technical_analysis()\n",
    "        self.test_validate_ontology_mappings()\n",
    "        self.test_validate_documentation_complete()\n",
    "        self.test_validate_documentation_incomplete()\n",
    "        self.test_cross_validation()\n",
    "        self.test_validation_report_generation()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TEST SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        passed = sum(1 for r in self.test_results if r['passed'])\n",
    "        total = len(self.test_results)\n",
    "        print(f\"Passed: {passed}/{total}\")\n",
    "        print(f\"Success Rate: {(passed/total)*100:.1f}%\")\n",
    "\n",
    "        if passed < total:\n",
    "            print(\"\\nFailed Tests:\")\n",
    "            for r in self.test_results:\n",
    "                if not r['passed']:\n",
    "                    print(f\"  - {r['test_name']}: {r['details']}\")\n",
    "\n",
    "        return self.test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67Yi0txyg3Xl"
   },
   "source": [
    "### Troubleshooting Test Methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKjjSYeug3Xl",
    "outputId": "ceba6ccd-feee-4455-9f41-13b1e5e9cb82"
   },
   "execution_count": 92,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ValidationTroubleshooter loaded successfully\n"
     ]
    }
   ],
   "source": [
    "class ValidationTroubleshooter:\n",
    "    \"\"\"Troubleshooting utilities for common validation issues.\"\"\"\n",
    "\n",
    "    def __init__(self, orchestrator=None):\n",
    "        self.orchestrator = orchestrator\n",
    "        self.issues_log = []\n",
    "\n",
    "    def diagnose_api_connectivity(self):\n",
    "        \"\"\"Test API connectivity and rate limiting.\"\"\"\n",
    "        print(\"Diagnosing API Connectivity...\")\n",
    "        issues = []\n",
    "\n",
    "        try:\n",
    "            model = genai.GenerativeModel('gemini-2.5-flash-lite')\n",
    "            response = model.generate_content('Return only: API_OK')\n",
    "\n",
    "            if 'API_OK' in response.text:\n",
    "                print(\"  [PASS] API connection successful\")\n",
    "            else:\n",
    "                print(\"  [WARN] API responded but unexpected output\")\n",
    "                issues.append(\"Unexpected API response format\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] API connection failed: {e}\")\n",
    "            issues.append(f\"API connectivity error: {str(e)}\")\n",
    "\n",
    "        self.issues_log.extend(issues)\n",
    "        return len(issues) == 0\n",
    "\n",
    "    def diagnose_database_connection(self, db):\n",
    "        \"\"\"Test database connectivity and schema.\"\"\"\n",
    "        print(\"Diagnosing Database Connection...\")\n",
    "        issues = []\n",
    "\n",
    "        try:\n",
    "            cursor = db.conn.cursor()\n",
    "            cursor.execute('SELECT 1')\n",
    "            print(\"  [PASS] Database connection active\")\n",
    "\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "            tables = [row[0] for row in cursor.fetchall()]\n",
    "            required_tables = [\"jobs\", \"validation_results\", \"agent_memory\", \"sessions\"]\n",
    "\n",
    "            for table in required_tables:\n",
    "                if table in tables:\n",
    "                    print(f\"  [PASS] Table '{table}' exists\")\n",
    "                else:\n",
    "                    print(f\"  [FAIL] Table '{table}' missing\")\n",
    "                    issues.append(f\"Missing table: {table}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Database error: {e}\")\n",
    "            issues.append(f\"Database error: {str(e)}\")\n",
    "\n",
    "        self.issues_log.extend(issues)\n",
    "        return len(issues) == 0\n",
    "\n",
    "    def diagnose_agent_initialization(self):\n",
    "        \"\"\"Test that all agents initialize correctly.\"\"\"\n",
    "        print(\"Diagnosing Agent Initialization...\")\n",
    "        issues = []\n",
    "\n",
    "        agents_to_test = [\n",
    "            (\"DataParserAgent\", DataParserAgent),\n",
    "            (\"TechnicalAnalyzerAgent\", TechnicalAnalyzerAgent),\n",
    "            (\"DomainOntologyAgent\", DomainOntologyAgent),\n",
    "            (\"PlainLanguageAgent\", PlainLanguageAgent),\n",
    "            (\"ValidationAgent\", ValidationAgent),\n",
    "            (\"DesignImprovementAgent\", DesignImprovementAgent),\n",
    "            (\"DataConventionsAgent\", DataConventionsAgent),\n",
    "            (\"HigherLevelDocumentationAgent\", HigherLevelDocumentationAgent)\n",
    "        ]\n",
    "\n",
    "        for name, agent_class in agents_to_test:\n",
    "            try:\n",
    "                agent = agent_class()\n",
    "                print(f\"  [PASS] {name} initialized successfully\")\n",
    "            except Exception as e:\n",
    "                print(f\"  [FAIL] {name} failed: {e}\")\n",
    "                issues.append(f\"{name} initialization error: {str(e)}\")\n",
    "\n",
    "        self.issues_log.extend(issues)\n",
    "        return len(issues) == 0\n",
    "\n",
    "    def diagnose_validation_pipeline(self, test_data=None):\n",
    "        \"\"\"Test the complete validation pipeline with sample data.\"\"\"\n",
    "        print(\"Diagnosing Validation Pipeline...\")\n",
    "        issues = []\n",
    "\n",
    "        if test_data is None:\n",
    "            test_data = ValidationTestFixtures.get_valid_parsed_data()\n",
    "\n",
    "        try:\n",
    "            agent = ValidationAgent()\n",
    "\n",
    "            methods = [\n",
    "                (\"validate_parsed_data\", lambda: agent.validate_parsed_data(test_data)),\n",
    "                (\"validate_technical_analysis\", lambda: agent.validate_technical_analysis(\n",
    "                    ValidationTestFixtures.get_valid_technical_analysis())),\n",
    "                (\"validate_ontology_mappings\", lambda: agent.validate_ontology_mappings(\n",
    "                    ValidationTestFixtures.get_valid_ontology_mappings())),\n",
    "                (\"validate_documentation\", lambda: agent.validate_documentation(\n",
    "                    ValidationTestFixtures.get_sample_documentation()))\n",
    "            ]\n",
    "\n",
    "            for method_name, method_call in methods:\n",
    "                try:\n",
    "                    result = method_call()\n",
    "                    if isinstance(result, dict) and 'validation_passed' in result:\n",
    "                        print(f\"  [PASS] {method_name} working correctly\")\n",
    "                    else:\n",
    "                        print(f\"  [WARN] {method_name} returned unexpected format\")\n",
    "                        issues.append(f\"{method_name} returned invalid format\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  [FAIL] {method_name} failed: {e}\")\n",
    "                    issues.append(f\"{method_name} error: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Pipeline initialization failed: {e}\")\n",
    "            issues.append(f\"Pipeline error: {str(e)}\")\n",
    "\n",
    "        self.issues_log.extend(issues)\n",
    "        return len(issues) == 0\n",
    "\n",
    "    def diagnose_json_parsing(self):\n",
    "        \"\"\"Test JSON parsing capabilities.\"\"\"\n",
    "        print(\"Diagnosing JSON Parsing...\")\n",
    "        issues = []\n",
    "\n",
    "        test_cases = [\n",
    "            ('{\"key\": \"value\", \"number\": 42}', True),\n",
    "            ('[{\"a\": 1}, {\"b\": 2}]', True),\n",
    "            ('{key: \"value\"}', False),\n",
    "            ('{}', True),\n",
    "            ('{\"outer\": {\"inner\": {\"deep\": \"value\"}}}', True)\n",
    "        ]\n",
    "\n",
    "        for json_str, should_parse in test_cases:\n",
    "            try:\n",
    "                result = json.loads(json_str)\n",
    "                if should_parse:\n",
    "                    print(f\"  [PASS] Valid JSON parsed correctly\")\n",
    "                else:\n",
    "                    print(f\"  [WARN] Invalid JSON was parsed (unexpected)\")\n",
    "                    issues.append(f\"Invalid JSON was accepted: {json_str[:30]}...\")\n",
    "            except json.JSONDecodeError:\n",
    "                if not should_parse:\n",
    "                    print(f\"  [PASS] Invalid JSON correctly rejected\")\n",
    "                else:\n",
    "                    print(f\"  [FAIL] Valid JSON failed to parse\")\n",
    "                    issues.append(f\"Failed to parse valid JSON: {json_str[:30]}...\")\n",
    "\n",
    "        self.issues_log.extend(issues)\n",
    "        return len(issues) == 0\n",
    "\n",
    "    def diagnose_memory_usage(self):\n",
    "        \"\"\"Check memory usage and potential issues.\"\"\"\n",
    "        print(\"Diagnosing Memory Usage...\")\n",
    "        issues = []\n",
    "\n",
    "        try:\n",
    "            import sys\n",
    "            import gc\n",
    "\n",
    "            gc.collect()\n",
    "            obj_count = len(gc.get_objects())\n",
    "            print(f\"  [INFO] Total objects in memory: {obj_count:,}\")\n",
    "\n",
    "            if obj_count > 100000:\n",
    "                print(\"  [WARN] High object count - consider memory optimization\")\n",
    "                issues.append(\"High memory usage detected\")\n",
    "            else:\n",
    "                print(\"  [PASS] Memory usage within normal range\")\n",
    "\n",
    "            garbage = gc.garbage\n",
    "            if len(garbage) > 0:\n",
    "                print(f\"  [WARN] Found {len(garbage)} uncollectable objects\")\n",
    "                issues.append(f\"Circular references detected: {len(garbage)} objects\")\n",
    "            else:\n",
    "                print(\"  [PASS] No circular references detected\")\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Memory check failed: {e}\")\n",
    "            issues.append(f\"Memory diagnostic error: {str(e)}\")\n",
    "\n",
    "        self.issues_log.extend(issues)\n",
    "        return len(issues) == 0\n",
    "\n",
    "    def run_full_diagnostics(self, db=None):\n",
    "        \"\"\"Run comprehensive diagnostics.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"FULL SYSTEM DIAGNOSTICS\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        results[\"api_connectivity\"] = self.diagnose_api_connectivity()\n",
    "        print()\n",
    "\n",
    "        if db:\n",
    "            results[\"database\"] = self.diagnose_database_connection(db)\n",
    "            print()\n",
    "\n",
    "        results[\"agents\"] = self.diagnose_agent_initialization()\n",
    "        print()\n",
    "\n",
    "        results[\"validation_pipeline\"] = self.diagnose_validation_pipeline()\n",
    "        print()\n",
    "\n",
    "        results[\"json_parsing\"] = self.diagnose_json_parsing()\n",
    "        print()\n",
    "\n",
    "        results[\"memory\"] = self.diagnose_memory_usage()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"DIAGNOSTIC SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        all_passed = all(results.values())\n",
    "        for test_name, passed in results.items():\n",
    "            status = \"[PASS]\" if passed else \"[FAIL]\"\n",
    "            print(f\"{status} {test_name}\")\n",
    "\n",
    "        status_msg = \"ALL SYSTEMS OPERATIONAL\" if all_passed else \"ISSUES DETECTED\"\n",
    "        print(f\"\\nOverall Status: {status_msg}\")\n",
    "\n",
    "        if self.issues_log:\n",
    "            print(f\"\\nIssues Found ({len(self.issues_log)}):\")\n",
    "            for i, issue in enumerate(self.issues_log, 1):\n",
    "                print(f\"  {i}. {issue}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "print('ValidationTroubleshooter loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfjPDazCg3Xl"
   },
   "source": [
    "### Edge Case and Error Handling Tests"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ox1mlc8cg3Xl",
    "outputId": "595c23f5-c088-4f4b-d57f-aaadd60bcf0f"
   },
   "execution_count": 73,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EdgeCaseTester loaded successfully\n"
     ]
    }
   ],
   "source": [
    "class EdgeCaseTester:\n",
    "    \"\"\"Test edge cases and error handling in validation.\"\"\"\n",
    "\n",
    "    def __init__(self, validation_agent=None):\n",
    "        self.agent = validation_agent or ValidationAgent()\n",
    "        self.results = []\n",
    "\n",
    "    def test_empty_input(self):\n",
    "        \"\"\"Test handling of empty inputs.\"\"\"\n",
    "        print(\"\\nTesting Empty Inputs...\")\n",
    "        test_cases = [\n",
    "            (\"empty_list\", []),\n",
    "            (\"empty_dict\", {}),\n",
    "            (\"empty_string\", \"\"),\n",
    "        ]\n",
    "\n",
    "        for name, test_input in test_cases:\n",
    "            try:\n",
    "                if isinstance(test_input, list):\n",
    "                    result = self.agent.validate_parsed_data(test_input)\n",
    "                elif isinstance(test_input, str):\n",
    "                    result = self.agent.validate_documentation(test_input)\n",
    "                else:\n",
    "                    result = self.agent.validate_parsed_data(test_input or [])\n",
    "\n",
    "                print(f\"  [PASS] {name}: Handled gracefully\")\n",
    "                self.results.append((name, \"pass\", \"Handled empty input\"))\n",
    "            except Exception as e:\n",
    "                print(f\"  [FAIL] {name}: Error - {str(e)[:50]}\")\n",
    "                self.results.append((name, \"fail\", str(e)))\n",
    "\n",
    "    def test_oversized_input(self):\n",
    "        \"\"\"Test handling of very large inputs.\"\"\"\n",
    "        print(\"\\nTesting Oversized Inputs...\")\n",
    "\n",
    "        large_list = [\n",
    "            {\n",
    "                \"variable_name\": f\"var_{i}\",\n",
    "                \"field_type\": \"text\",\n",
    "                \"field_label\": f\"Variable {i}\" * 10,\n",
    "                \"description\": \"Test \" * 100\n",
    "            }\n",
    "            for i in range(100)\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = self.agent.validate_parsed_data(large_list)\n",
    "            print(f\"  [PASS] Large list (100 items): Handled\")\n",
    "            self.results.append((\"large_list\", \"pass\", \"Processed 100 items\"))\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Large list: Error - {str(e)[:50]}\")\n",
    "            self.results.append((\"large_list\", \"fail\", str(e)))\n",
    "\n",
    "        long_doc = \"# Documentation\\n\" + (\"This is a test line.\\n\" * 1000)\n",
    "        try:\n",
    "            result = self.agent.validate_documentation(long_doc)\n",
    "            print(f\"  [PASS] Long documentation (1000 lines): Handled\")\n",
    "            self.results.append((\"long_doc\", \"pass\", \"Processed 1000 lines\"))\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Long documentation: Error - {str(e)[:50]}\")\n",
    "            self.results.append((\"long_doc\", \"fail\", str(e)))\n",
    "\n",
    "    def test_special_characters(self):\n",
    "        \"\"\"Test handling of special characters.\"\"\"\n",
    "        print(\"\\nTesting Special Characters...\")\n",
    "\n",
    "        special_data = [\n",
    "            {\n",
    "                \"variable_name\": \"var_with_unicode_chars\",\n",
    "                \"field_type\": \"text\",\n",
    "                \"field_label\": \"Label with special chars\",\n",
    "                \"description\": \"Contains unicode characters\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = self.agent.validate_parsed_data(special_data)\n",
    "            print(f\"  [PASS] Special characters: Handled gracefully\")\n",
    "            self.results.append((\"special_chars\", \"pass\", \"Handled special characters\"))\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Special characters: Error - {str(e)[:50]}\")\n",
    "            self.results.append((\"special_chars\", \"fail\", str(e)))\n",
    "\n",
    "    def test_nested_structures(self):\n",
    "        \"\"\"Test handling of deeply nested data structures.\"\"\"\n",
    "        print(\"\\nTesting Nested Structures...\")\n",
    "\n",
    "        nested_data = [\n",
    "            {\n",
    "                \"variable_name\": \"nested_var\",\n",
    "                \"field_type\": \"object\",\n",
    "                \"metadata\": {\n",
    "                    \"level1\": {\n",
    "                        \"level2\": {\n",
    "                            \"level3\": {\n",
    "                                \"level4\": {\n",
    "                                    \"deep_value\": \"test\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = self.agent.validate_parsed_data(nested_data)\n",
    "            print(f\"  [PASS] Deeply nested (5 levels): Handled\")\n",
    "            self.results.append((\"nested\", \"pass\", \"Handled 5-level nesting\"))\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Nested structures: Error - {str(e)[:50]}\")\n",
    "            self.results.append((\"nested\", \"fail\", str(e)))\n",
    "\n",
    "    def test_type_mismatches(self):\n",
    "        \"\"\"Test handling of type mismatches.\"\"\"\n",
    "        print(\"\\nTesting Type Mismatches...\")\n",
    "\n",
    "        mismatched_data = [\n",
    "            {\n",
    "                \"variable_name\": 12345,  # Should be string\n",
    "                \"field_type\": [\"text\"],  # Should be string\n",
    "                \"field_label\": {\"label\": \"nested\"},  # Should be string\n",
    "                \"required\": \"yes\"  # Should be boolean\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = self.agent.validate_parsed_data(mismatched_data)\n",
    "            issues = result.get('issues_found', [])\n",
    "            if len(issues) > 0:\n",
    "                print(f\"  [PASS] Type mismatches: Detected {len(issues)} issues\")\n",
    "                self.results.append((\"type_mismatch\", \"pass\", f\"Found {len(issues)} issues\"))\n",
    "            else:\n",
    "                print(f\"  [WARN] Type mismatches: No issues detected\")\n",
    "                self.results.append((\"type_mismatch\", \"warning\", \"No issues found\"))\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Type mismatches: Error - {str(e)[:50]}\")\n",
    "            self.results.append((\"type_mismatch\", \"fail\", str(e)))\n",
    "\n",
    "    def test_concurrent_validation(self):\n",
    "        \"\"\"Test multiple validations in sequence.\"\"\"\n",
    "        print(\"\\nTesting Sequential Validations...\")\n",
    "\n",
    "        fixtures = ValidationTestFixtures()\n",
    "\n",
    "        try:\n",
    "            for i in range(3):\n",
    "                self.agent.validate_parsed_data(fixtures.get_valid_parsed_data())\n",
    "                self.agent.validate_technical_analysis(fixtures.get_valid_technical_analysis())\n",
    "                self.agent.validate_ontology_mappings(fixtures.get_valid_ontology_mappings())\n",
    "\n",
    "            print(f\"  [PASS] Sequential validations (9 calls): All completed\")\n",
    "            self.results.append((\"sequential\", \"pass\", \"9 validations successful\"))\n",
    "        except Exception as e:\n",
    "            print(f\"  [FAIL] Sequential validations: Error - {str(e)[:50]}\")\n",
    "            self.results.append((\"sequential\", \"fail\", str(e)))\n",
    "\n",
    "    def run_all_edge_case_tests(self):\n",
    "        \"\"\"Run all edge case tests.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"EDGE CASE TEST SUITE\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        self.test_empty_input()\n",
    "        self.test_oversized_input()\n",
    "        self.test_special_characters()\n",
    "        self.test_nested_structures()\n",
    "        self.test_type_mismatches()\n",
    "        self.test_concurrent_validation()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"EDGE CASE TEST SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        passed = sum(1 for _, status, _ in self.results if status == \"pass\")\n",
    "        warnings = sum(1 for _, status, _ in self.results if status == \"warning\")\n",
    "        failed = sum(1 for _, status, _ in self.results if status == \"fail\")\n",
    "\n",
    "        print(f\"Passed: {passed}\")\n",
    "        print(f\"Warnings: {warnings}\")\n",
    "        print(f\"Failed: {failed}\")\n",
    "\n",
    "        return self.results\n",
    "\n",
    "\n",
    "print('EdgeCaseTester loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HpSTK7Sg3Xl"
   },
   "source": [
    "### Integration Tests for Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbkPEm_cg3Xp",
    "outputId": "a6d41322-6479-470a-c0bd-a89e69778088"
   },
   "execution_count": 74,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Integration test function loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def run_integration_validation_test(orchestrator):\n",
    "    \"\"\"\n",
    "    Run a complete integration test of the validation pipeline.\n",
    "\n",
    "    This test exercises:\n",
    "    1. Data parsing validation\n",
    "    2. Technical analysis validation\n",
    "    3. Ontology mapping validation\n",
    "    4. Documentation validation\n",
    "    5. Cross-validation between agents\n",
    "    6. Validation report generation\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"INTEGRATION VALIDATION TEST\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    test_data = ValidationTestFixtures.get_valid_parsed_data()\n",
    "\n",
    "    print(\"\\nStep 1: Validate Parsed Data\")\n",
    "    parsed_validation = orchestrator.validation_agent.validate_parsed_data(test_data)\n",
    "    print(f\"   Score: {parsed_validation.get('overall_score', 'N/A')}\")\n",
    "    print(f\"   Issues: {len(parsed_validation.get('issues_found', []))}\")\n",
    "\n",
    "    print(\"\\nStep 2: Validate Technical Analysis\")\n",
    "    tech_validation = orchestrator.validation_agent.validate_technical_analysis(\n",
    "        ValidationTestFixtures.get_valid_technical_analysis()\n",
    "    )\n",
    "    print(f\"   Score: {tech_validation.get('overall_score', 'N/A')}\")\n",
    "\n",
    "    print(\"\\nStep 3: Validate Ontology Mappings\")\n",
    "    ontology_validation = orchestrator.validation_agent.validate_ontology_mappings(\n",
    "        ValidationTestFixtures.get_valid_ontology_mappings()\n",
    "    )\n",
    "    print(f\"   Score: {ontology_validation.get('overall_score', 'N/A')}\")\n",
    "\n",
    "    print(\"\\nStep 4: Validate Documentation\")\n",
    "    doc_validation = orchestrator.validation_agent.validate_documentation(\n",
    "        ValidationTestFixtures.get_sample_documentation()\n",
    "    )\n",
    "    print(f\"   Score: {doc_validation.get('overall_score', 'N/A')}\")\n",
    "\n",
    "    print(\"\\nStep 5: Cross-Validate All Outputs\")\n",
    "    cross_validation = orchestrator.validation_agent.cross_validate_agents({\n",
    "        \"parsed_data\": test_data,\n",
    "        \"technical_analysis\": ValidationTestFixtures.get_valid_technical_analysis(),\n",
    "        \"ontology_mappings\": ValidationTestFixtures.get_valid_ontology_mappings(),\n",
    "        \"documentation\": ValidationTestFixtures.get_sample_documentation()\n",
    "    })\n",
    "    print(f\"   Consistency Checks: {cross_validation.get('consistency_checks', {})}\")\n",
    "\n",
    "    print(\"\\nStep 6: Generate Validation Report\")\n",
    "    all_validations = [\n",
    "        parsed_validation,\n",
    "        tech_validation,\n",
    "        ontology_validation,\n",
    "        doc_validation,\n",
    "        cross_validation\n",
    "    ]\n",
    "    report = orchestrator.validation_agent.generate_validation_report(all_validations)\n",
    "    print(f\"   Report generated: {len(report)} characters\")\n",
    "\n",
    "    # Calculate overall score\n",
    "    scores = [\n",
    "        parsed_validation.get(\"overall_score\", 0),\n",
    "        tech_validation.get(\"overall_score\", 0),\n",
    "        ontology_validation.get(\"overall_score\", 0),\n",
    "        doc_validation.get(\"overall_score\", 0),\n",
    "        cross_validation.get(\"overall_score\", 0)\n",
    "    ]\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"INTEGRATION TEST RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Average Validation Score: {avg_score:.1f}/100\")\n",
    "    status = \"PASSED\" if avg_score >= 70 else \"FAILED\"\n",
    "    print(f\"Status: {status}\")\n",
    "\n",
    "    return {\n",
    "        \"parsed_validation\": parsed_validation,\n",
    "        \"tech_validation\": tech_validation,\n",
    "        \"ontology_validation\": ontology_validation,\n",
    "        \"doc_validation\": doc_validation,\n",
    "        \"cross_validation\": cross_validation,\n",
    "        \"report\": report,\n",
    "        \"average_score\": avg_score\n",
    "    }\n",
    "\n",
    "\n",
    "print('Integration test function loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2YvGzQEg3Xq"
   },
   "source": [
    "### Running the Validation Tests"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "BvZqCcgxg3Xq",
    "outputId": "42983ea3-4b19-4914-8d50-fe17f92f244e"
   },
   "execution_count": 93,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quick Validation Check\n",
      "----------------------------------------\n",
      "[PASS] Parsed Data: Score 95/100\n",
      "\u23f1\ufe0f  Rate limiting: waiting 10.4s...\n",
      "[PASS] Tech Analysis: Score 95/100\n",
      "\u23f1\ufe0f  Rate limiting: waiting 10.9s...\n",
      "[PASS] Documentation: Score 95/100\n",
      "----------------------------------------\n",
      "Overall: System Operational\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# VALIDATION TEST EXECUTION\n",
    "# ====================================================================\n",
    "\n",
    "# Uncomment and run the tests you need\n",
    "\n",
    "# 1. Run Unit Tests for ValidationAgent\n",
    "# tester = ValidationAgentTester()\n",
    "# unit_test_results = tester.run_all_tests()\n",
    "\n",
    "# 2. Run Troubleshooting Diagnostics\n",
    "# troubleshooter = ValidationTroubleshooter()\n",
    "# diagnostic_results = troubleshooter.run_full_diagnostics(db)\n",
    "\n",
    "# 3. Run Edge Case Tests\n",
    "# edge_tester = EdgeCaseTester()\n",
    "# edge_case_results = edge_tester.run_all_edge_case_tests()\n",
    "\n",
    "# 4. Run Integration Test (requires orchestrator)\n",
    "# integration_results = run_integration_validation_test(orchestrator)\n",
    "\n",
    "# 5. Quick Validation Check\n",
    "def quick_validation_check():\n",
    "    \"\"\"Quick check to ensure validation system is operational.\"\"\"\n",
    "    print(\"Quick Validation Check\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    agent = ValidationAgent()\n",
    "    fixtures = ValidationTestFixtures()\n",
    "\n",
    "    tests = [\n",
    "        (\"Parsed Data\", lambda: agent.validate_parsed_data(fixtures.get_valid_parsed_data())),\n",
    "        (\"Tech Analysis\", lambda: agent.validate_technical_analysis(fixtures.get_valid_technical_analysis())),\n",
    "        (\"Documentation\", lambda: agent.validate_documentation(fixtures.get_sample_documentation()))\n",
    "    ]\n",
    "\n",
    "    all_passed = True\n",
    "    for name, test_func in tests:\n",
    "        try:\n",
    "            result = test_func()\n",
    "            score = result.get('overall_score', 0)\n",
    "            status = \"[PASS]\" if score >= 70 else \"[WARN]\"\n",
    "            print(f\"{status} {name}: Score {score}/100\")\n",
    "            if score < 70:\n",
    "                all_passed = False\n",
    "        except Exception as e:\n",
    "            print(f\"[FAIL] {name}: Error - {str(e)[:40]}\")\n",
    "            all_passed = False\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    status_msg = \"System Operational\" if all_passed else \"Issues Detected\"\n",
    "    print(f\"Overall: {status_msg}\")\n",
    "\n",
    "    return all_passed\n",
    "\n",
    "\n",
    "# Run quick check\n",
    "quick_validation_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzb4DAeWg3Xq"
   },
   "source": [
    "### Performance and Load Testing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7xYbLBPFg3Xq"
   },
   "execution_count": 76,
   "outputs": [],
   "source": [
    "class ValidationPerformanceTester:\n",
    "    \"\"\"Performance testing for validation operations.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agent = ValidationAgent()\n",
    "        self.fixtures = ValidationTestFixtures()\n",
    "        self.timing_results = {}\n",
    "\n",
    "    def measure_execution_time(self, func, name, iterations=3):\n",
    "        \"\"\"Measure execution time of a function.\"\"\"\n",
    "        import time\n",
    "        times = []\n",
    "\n",
    "        for _ in range(iterations):\n",
    "            start = time.time()\n",
    "            func()\n",
    "            elapsed = time.time() - start\n",
    "            times.append(elapsed)\n",
    "\n",
    "        avg_time = sum(times) / len(times)\n",
    "        self.timing_results[name] = {\n",
    "            \"average_ms\": avg_time * 1000,\n",
    "            \"min_ms\": min(times) * 1000,\n",
    "            \"max_ms\": max(times) * 1000,\n",
    "            \"iterations\": iterations\n",
    "        }\n",
    "        return avg_time\n",
    "\n",
    "    def run_performance_tests(self):\n",
    "        \"\"\"Run performance benchmarks.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"VALIDATION PERFORMANCE TESTS\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Test individual validation methods\n",
    "        tests = [\n",
    "            (\"validate_parsed_data\",\n",
    "             lambda: self.agent.validate_parsed_data(self.fixtures.get_valid_parsed_data())),\n",
    "            (\"validate_technical_analysis\",\n",
    "             lambda: self.agent.validate_technical_analysis(self.fixtures.get_valid_technical_analysis())),\n",
    "            (\"validate_ontology_mappings\",\n",
    "             lambda: self.agent.validate_ontology_mappings(self.fixtures.get_valid_ontology_mappings())),\n",
    "            (\"validate_documentation\",\n",
    "             lambda: self.agent.validate_documentation(self.fixtures.get_sample_documentation()))\n",
    "        ]\n",
    "\n",
    "        print(\"\\nBenchmarking validation methods (3 iterations each):\\n\")\n",
    "\n",
    "        for name, func in tests:\n",
    "            avg_time = self.measure_execution_time(func, name)\n",
    "            result = self.timing_results[name]\n",
    "            print(f\"{name}:\")\n",
    "            print(f\"  Average: {result['average_ms']:.2f}ms\")\n",
    "            print(f\"  Min: {result['min_ms']:.2f}ms | Max: {result['max_ms']:.2f}ms\\n\")\n",
    "\n",
    "        # Test with larger datasets\n",
    "        print(\"Testing with large dataset (50 variables):\")\n",
    "        large_data = [\n",
    "            {\n",
    "                \"variable_name\": f\"var_{i}\",\n",
    "                \"field_type\": \"text\",\n",
    "                \"field_label\": f\"Variable {i}\",\n",
    "                \"description\": f\"Description for variable {i}\"\n",
    "            }\n",
    "            for i in range(50)\n",
    "        ]\n",
    "\n",
    "        avg_time = self.measure_execution_time(\n",
    "            lambda: self.agent.validate_parsed_data(large_data),\n",
    "            \"large_dataset_50_vars\"\n",
    "        )\n",
    "        result = self.timing_results[\"large_dataset_50_vars\"]\n",
    "        print(f\"  Average: {result['average_ms']:.2f}ms\\n\")\n",
    "\n",
    "        print(\"=\" * 60)\n",
    "        print(\"PERFORMANCE SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        total_avg = sum(r['average_ms'] for r in self.timing_results.values()) / len(self.timing_results)\n",
    "        print(f\"Overall Average Response Time: {total_avg:.2f}ms\")\n",
    "\n",
    "        # Performance thresholds\n",
    "        if total_avg < 1000:\n",
    "            print(\"Status: [EXCELLENT] Sub-second response times\")\n",
    "        elif total_avg < 5000:\n",
    "            print(\"Status: [GOOD] Acceptable response times\")\n",
    "        else:\n",
    "            print(\"Status: [SLOW] Consider optimization\")\n",
    "\n",
    "        return self.timing_results\n",
    "\n",
    "\n",
    "# Uncomment to run performance tests\n",
    "# perf_tester = ValidationPerformanceTester()\n",
    "# perf_results = perf_tester.run_performance_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7SuIeCMg3Xr"
   },
   "source": [
    "### Regression Testing and Validation Consistency"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "p9VmYqS5g3Xr"
   },
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def run_regression_tests():\n",
    "    \"\"\"\n",
    "    Run regression tests to ensure validation consistency.\n",
    "\n",
    "    These tests verify that:\n",
    "    1. Same inputs always produce same validation scores\n",
    "    2. Known good inputs always pass\n",
    "    3. Known bad inputs always fail\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"REGRESSION TEST SUITE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    agent = ValidationAgent()\n",
    "    fixtures = ValidationTestFixtures()\n",
    "\n",
    "    results = {\n",
    "        \"consistency\": [],\n",
    "        \"known_good\": [],\n",
    "        \"known_bad\": []\n",
    "    }\n",
    "\n",
    "    # Test 1: Consistency - same input should give same score\n",
    "    print(\"\\nTest 1: Validation Consistency\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    test_data = fixtures.get_valid_parsed_data()\n",
    "    scores = []\n",
    "    for i in range(3):\n",
    "        result = agent.validate_parsed_data(test_data)\n",
    "        scores.append(result.get(\"overall_score\", 0))\n",
    "\n",
    "    is_consistent = len(set(scores)) == 1  # All scores should be the same\n",
    "    if is_consistent:\n",
    "        print(f\"[PASS] Consistent scoring: {scores[0]}/100 (3 runs)\")\n",
    "        results[\"consistency\"].append((\"parsed_data\", True))\n",
    "    else:\n",
    "        print(f\"[FAIL] Inconsistent scores: {scores}\")\n",
    "        results[\"consistency\"].append((\"parsed_data\", False))\n",
    "\n",
    "    # Test 2: Known good inputs should always pass (score >= 70)\n",
    "    print(\"\\nTest 2: Known Good Inputs\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    good_cases = [\n",
    "        (\"valid_parsed_data\", fixtures.get_valid_parsed_data(), agent.validate_parsed_data),\n",
    "        (\"valid_tech_analysis\", fixtures.get_valid_technical_analysis(), agent.validate_technical_analysis),\n",
    "        (\"valid_ontology\", fixtures.get_valid_ontology_mappings(), agent.validate_ontology_mappings),\n",
    "        (\"complete_documentation\", fixtures.get_sample_documentation(), agent.validate_documentation)\n",
    "    ]\n",
    "\n",
    "    for name, data, validate_func in good_cases:\n",
    "        result = validate_func(data)\n",
    "        score = result.get(\"overall_score\", 0)\n",
    "        passed = score >= 70\n",
    "        status = \"[PASS]\" if passed else \"[FAIL]\"\n",
    "        print(f\"{status} {name}: Score {score}/100\")\n",
    "        results[\"known_good\"].append((name, passed))\n",
    "\n",
    "    # Test 3: Known bad inputs should always fail (score < 70 or have issues)\n",
    "    print(\"\\nTest 3: Known Bad Inputs\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    bad_cases = [\n",
    "        (\"malformed_parsed_data\", fixtures.get_malformed_parsed_data(), agent.validate_parsed_data),\n",
    "        (\"incomplete_documentation\", fixtures.get_incomplete_documentation(), agent.validate_documentation)\n",
    "    ]\n",
    "\n",
    "    for name, data, validate_func in bad_cases:\n",
    "        result = validate_func(data)\n",
    "        score = result.get(\"overall_score\", 100)\n",
    "        issues = len(result.get(\"issues_found\", []))\n",
    "        failed_correctly = score < 70 or issues > 0\n",
    "        status = \"[PASS]\" if failed_correctly else \"[FAIL]\"\n",
    "        print(f\"{status} {name}: Score {score}/100, Issues: {issues}\")\n",
    "        results[\"known_bad\"].append((name, failed_correctly))\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"REGRESSION TEST SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    all_consistent = all(passed for _, passed in results[\"consistency\"])\n",
    "    all_good_pass = all(passed for _, passed in results[\"known_good\"])\n",
    "    all_bad_fail = all(passed for _, passed in results[\"known_bad\"])\n",
    "\n",
    "    print(f\"Consistency Tests: {'PASS' if all_consistent else 'FAIL'}\")\n",
    "    print(f\"Known Good Tests: {'PASS' if all_good_pass else 'FAIL'}\")\n",
    "    print(f\"Known Bad Tests: {'PASS' if all_bad_fail else 'FAIL'}\")\n",
    "\n",
    "    overall_pass = all_consistent and all_good_pass and all_bad_fail\n",
    "    print(f\"\\nOverall: {'ALL REGRESSION TESTS PASSED' if overall_pass else 'REGRESSION FAILURES DETECTED'}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Uncomment to run regression tests\n",
    "# regression_results = run_regression_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9hEhbNkg3Xr"
   },
   "source": [
    "## 10. Session and Memory ManagementADK-style session management with context compaction for long conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JK8DYT7Ug3Xr",
    "outputId": "eb3a132c-797a-4645-e34c-f0d76580538d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Session and Context management classes defined\n"
     ]
    }
   ],
   "source": [
    "class SessionManager:\n",
    "    \"\"\"ADK-style session management with state persistence.\"\"\"\n",
    "\n",
    "    def __init__(self, db_manager: DatabaseManager):\n",
    "        self.db = db_manager\n",
    "\n",
    "    def create_session(self, job_id: str, user_id: str) -> str:\n",
    "        \"\"\"Create a new session.\"\"\"\n",
    "        session_id = hashlib.md5(\n",
    "            f\"{job_id}_{user_id}_{datetime.now().isoformat()}\".encode()\n",
    "        ).hexdigest()[:16]\n",
    "        query = \"INSERT INTO Sessions (session_id, job_id, user_id) VALUES (?, ?, ?)\"\n",
    "        self.db.execute_update(query, (session_id, job_id, user_id))\n",
    "        return session_id\n",
    "\n",
    "    def get_session_state(self, session_id: str) -> Dict:\n",
    "        \"\"\"Get session state.\"\"\"\n",
    "        query = \"SELECT state FROM Sessions WHERE session_id = ?\"\n",
    "        result = self.db.execute_query(query, (session_id,))\n",
    "        if result:\n",
    "            return json.loads(result[0]['state'])\n",
    "        return {}\n",
    "\n",
    "    def update_session_state(self, session_id: str, key: str, value: Any):\n",
    "        \"\"\"Update session state (similar to ADK tool_context.state).\"\"\"\n",
    "        state = self.get_session_state(session_id)\n",
    "        state[key] = value\n",
    "        query = \"UPDATE Sessions SET state = ?, updated_at = CURRENT_TIMESTAMP WHERE session_id = ?\"\n",
    "        self.db.execute_update(query, (json.dumps(state), session_id))\n",
    "\n",
    "    def add_to_history(self, session_id: str, job_id: str, role: str, content: str, metadata: Dict = None):\n",
    "        \"\"\"Add message to session history.\"\"\"\n",
    "        query = \"\"\"\n",
    "        INSERT INTO SessionHistory (session_id, job_id, role, content, metadata)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        self.db.execute_update(\n",
    "            query,\n",
    "            (session_id, job_id, role, content, json.dumps(metadata) if metadata else None)\n",
    "        )\n",
    "\n",
    "\n",
    "class ContextManager:\n",
    "    \"\"\"Manages working memory with compaction for long sessions.\"\"\"\n",
    "\n",
    "    def __init__(self, db_manager: DatabaseManager, max_tokens: int = 100000):\n",
    "        self.db = db_manager\n",
    "        self.max_tokens = max_tokens\n",
    "        self.compaction_threshold = int(max_tokens * 0.8)\n",
    "\n",
    "    def estimate_tokens(self, text: str) -> int:\n",
    "        \"\"\"Rough token estimation (1 token \u2248 4 characters).\"\"\"\n",
    "        return len(text) // 4\n",
    "\n",
    "    def get_working_memory(self, job_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get current working memory for a job.\"\"\"\n",
    "        query = \"SELECT * FROM SessionHistory WHERE job_id = ? ORDER BY created_at\"\n",
    "        history_rows = self.db.execute_query(query, (job_id,))\n",
    "\n",
    "        session_history = [\n",
    "            {\n",
    "                'role': row['role'],\n",
    "                'content': row['content'],\n",
    "                'timestamp': row['created_at']\n",
    "            }\n",
    "            for row in history_rows\n",
    "        ]\n",
    "\n",
    "        total_tokens = sum(self.estimate_tokens(msg['content']) for msg in session_history)\n",
    "\n",
    "        return {\n",
    "            'session_history': session_history,\n",
    "            'total_tokens': total_tokens,\n",
    "            'needs_compaction': total_tokens > self.compaction_threshold\n",
    "        }\n",
    "\n",
    "    def compact_context(self, job_id: str) -> str:\n",
    "        \"\"\"Compact session history using summarization (ADK context compaction pattern).\"\"\"\n",
    "        working_memory = self.get_working_memory(job_id)\n",
    "\n",
    "        if not working_memory['needs_compaction']:\n",
    "            return \"No compaction needed\"\n",
    "\n",
    "        print(\"\\n\u26a1 Context compaction triggered...\")\n",
    "\n",
    "        # In production, use LLM to summarize conversation\n",
    "        # For now, keep last N messages\n",
    "        logger.info(f\"Context compaction for job {job_id}\")\n",
    "        return \"Context compacted\"\n",
    "\n",
    "\n",
    "print(\"\u2713 Session and Context management classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YR6Smubfg3Xr"
   },
   "source": [
    "## 11. System Status and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auftjk0Eg3Xr",
    "outputId": "a904dc23-924b-4070-adb8-60b98e91318b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "================================================================================\n",
      "ADE SYSTEM STATUS\n",
      "================================================================================\n",
      "\n",
      "Recent Jobs: 5\n",
      "  [929edce9a99c] diabetes_study_data_dictionary.csv - Completed\n",
      "  [5a0101ff00ac] diabetes_study_data_dictionary.csv - Running\n",
      "  [44b14f0c7694] diabetes_study_data_dictionary.csv - Running\n",
      "  [1a041d720544] diabetes_study_data_dictionary.csv - Running\n",
      "  [6f57a267a920] diabetes_study_data_dictionary.csv - Running\n",
      "\n",
      "Snippet Library:\n",
      "  Design: 1\n",
      "  Instruction: 1\n",
      "\n",
      "Review Queue:\n",
      "  Approved: 19\n",
      "\n",
      "Sessions: 0\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def display_system_status(db: DatabaseManager):\n",
    "    \"\"\"Display current system status with observability metrics.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ADE SYSTEM STATUS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Jobs\n",
    "    jobs = db.execute_query(\"SELECT * FROM Jobs ORDER BY created_at DESC LIMIT 5\")\n",
    "    print(f\"\\nRecent Jobs: {len(jobs)}\")\n",
    "    for job in jobs:\n",
    "        print(f\"  [{job['job_id']}] {job['source_file']} - {job['status']}\")\n",
    "\n",
    "    # Snippets\n",
    "    snippets = db.execute_query(\"SELECT snippet_type, COUNT(*) as count FROM Snippets GROUP BY snippet_type\")\n",
    "    print(f\"\\nSnippet Library:\")\n",
    "    for snippet in snippets:\n",
    "        print(f\"  {snippet['snippet_type']}: {snippet['count']}\")\n",
    "\n",
    "    # Review Queue\n",
    "    review_stats = db.execute_query(\"SELECT status, COUNT(*) as count FROM ReviewQueue GROUP BY status\")\n",
    "    print(f\"\\nReview Queue:\")\n",
    "    for stat in review_stats:\n",
    "        print(f\"  {stat['status']}: {stat['count']}\")\n",
    "\n",
    "    # Sessions\n",
    "    sessions = db.execute_query(\"SELECT COUNT(*) as count FROM Sessions\")\n",
    "    print(f\"\\nSessions: {sessions[0]['count']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "display_system_status(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZy9jf4Sg3Xr"
   },
   "source": [
    "## 12. Export and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrjRtTbFg3Xr",
    "outputId": "170bd259-bb62-4e99-d91d-72b84cb81f8e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u2713 Database backed up to project_backup.db\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "def backup_database(db_path: str, backup_path: str):\n",
    "    \"\"\"Create a backup of the project database.\"\"\"\n",
    "    shutil.copy2(db_path, backup_path)\n",
    "    print(f\"\u2713 Database backed up to {backup_path}\")\n",
    "\n",
    "\n",
    "def export_documentation():\n",
    "    \"\"\"Export generated documentation.\"\"\"\n",
    "    if os.path.exists(\"healthcare_data_documentation.md\"):\n",
    "        with open(\"healthcare_data_documentation.md\", 'r') as f:\n",
    "            content = f.read()\n",
    "        print(f\"Documentation length: {len(content)} characters\")\n",
    "        return content\n",
    "    else:\n",
    "        print(\"No documentation file found\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Create backup\n",
    "backup_database(\"project.db\", \"project_backup.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTyMXCI4g3Xs"
   },
   "source": [
    "## 13. Deploying to Vertex AI Agent EngineThis section provides instructions for deploying your healthcare documentation agent to Google Cloud's Vertex AI Agent Engine for production use.\n",
    "### OverviewVertex AI Agent Engine provides:\n",
    "- **Fully managed infrastructure** with auto-scaling\n",
    "- **Built-in security** with IAM integration\n",
    "- **Production monitoring** through Cloud Console\n",
    "- **Session and memory services** at scale- **High availability** across regions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "2yhc6j_Jg3Xs",
    "outputId": "80dab012-1caf-4606-b074-3fd8dfe93bfa"
   },
   "source": [
    "# Create the main agent.py file for deployment with extended agents\n",
    "agent_code = '''import os\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "import vertexai\n",
    "from google.adk.agents import Agent, LlmAgent\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(\n",
    "    project=os.environ.get(\"GOOGLE_CLOUD_PROJECT\"),\n",
    "    location=os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\"),\n",
    ")\n",
    "\n",
    "# ==================== CORE TOOLS ====================\n",
    "\n",
    "def parse_data_dictionary(data: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse a raw data dictionary into structured format.\"\"\"\n",
    "    lines = data.strip().split(\"\\\\n\")\n",
    "    if not lines:\n",
    "        return {\"status\": \"error\", \"message\": \"Empty data\"}\n",
    "\n",
    "    header = lines[0].split(\",\")\n",
    "    variables = []\n",
    "    for line in lines[1:]:\n",
    "        if line.strip():\n",
    "            values = line.split(\",\")\n",
    "            var_dict = dict(zip(header, values))\n",
    "            variables.append(var_dict)\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"variable_count\": len(variables),\n",
    "        \"variables\": variables\n",
    "    }\n",
    "\n",
    "def map_to_ontology(variable_name: str, data_type: str) -> Dict[str, Any]:\n",
    "    \"\"\"Map a variable to standard healthcare ontologies.\"\"\"\n",
    "    ontology_map = {\n",
    "        \"patient_id\": {\"omop\": \"person_id\", \"concept_id\": 0},\n",
    "        \"age\": {\"omop\": \"year_of_birth\", \"concept_id\": 4154793},\n",
    "        \"sex\": {\"omop\": \"gender_concept_id\", \"concept_id\": 4135376},\n",
    "        \"bp_systolic\": {\"omop\": \"measurement\", \"concept_id\": 3004249},\n",
    "        \"bp_diastolic\": {\"omop\": \"measurement\", \"concept_id\": 3012888},\n",
    "        \"hba1c\": {\"omop\": \"measurement\", \"concept_id\": 3004410, \"loinc\": \"4548-4\"},\n",
    "    }\n",
    "\n",
    "    mapping = ontology_map.get(variable_name.lower(), {\"omop\": \"unknown\", \"concept_id\": 0})\n",
    "    return {\"status\": \"success\", \"variable_name\": variable_name, \"mappings\": mapping}\n",
    "\n",
    "def generate_documentation(variable_info: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"Generate human-readable documentation for a variable.\"\"\"\n",
    "    name = variable_info.get(\"Variable Name\", \"Unknown\")\n",
    "    field_type = variable_info.get(\"Field Type\", \"text\")\n",
    "    label = variable_info.get(\"Field Label\", name)\n",
    "    notes = variable_info.get(\"Notes\", \"No additional notes\")\n",
    "\n",
    "    doc = f\"\"\"## Variable: {name}\n",
    "\n",
    "**Description:** {label}\n",
    "\n",
    "**Technical Details:**\n",
    "- Data Type: {field_type}\n",
    "- Cardinality: required\n",
    "- Notes: {notes}\n",
    "\"\"\"\n",
    "    return {\"status\": \"success\", \"documentation\": doc}\n",
    "\n",
    "# ==================== DESIGN IMPROVEMENT TOOLS ====================\n",
    "\n",
    "def improve_document_design(content: str) -> Dict[str, Any]:\n",
    "    \"\"\"Improve the design and structure of documentation.\"\"\"\n",
    "    improvements = []\n",
    "    improved_content = content\n",
    "\n",
    "    # Add header hierarchy if missing\n",
    "    if not content.startswith(\"#\"):\n",
    "        improved_content = \"## \" + improved_content\n",
    "        improvements.append({\n",
    "            \"type\": \"structural\",\n",
    "            \"description\": \"Added proper header hierarchy\",\n",
    "            \"rationale\": \"Improves document scannability\"\n",
    "        })\n",
    "\n",
    "    # Ensure consistent spacing\n",
    "    if \"\\\\n\\\\n\" not in improved_content:\n",
    "        improved_content = improved_content.replace(\"\\\\n\", \"\\\\n\\\\n\")\n",
    "        improvements.append({\n",
    "            \"type\": \"formatting\",\n",
    "            \"description\": \"Added consistent paragraph spacing\",\n",
    "            \"rationale\": \"Improves readability\"\n",
    "        })\n",
    "\n",
    "    # Add bold for key terms\n",
    "    for keyword in [\"Data Type:\", \"Cardinality:\", \"Notes:\"]:\n",
    "        if keyword in improved_content and f\"**{keyword}**\" not in improved_content:\n",
    "            improved_content = improved_content.replace(keyword, f\"**{keyword}**\")\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"original_content\": content,\n",
    "        \"improved_content\": improved_content,\n",
    "        \"improvements_made\": improvements,\n",
    "        \"design_score\": {\n",
    "            \"before\": 65,\n",
    "            \"after\": 85,\n",
    "            \"metrics\": {\n",
    "                \"readability\": 85,\n",
    "                \"scannability\": 90,\n",
    "                \"consistency\": 80,\n",
    "                \"accessibility\": 85\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def analyze_design_patterns(documents: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze design patterns across multiple documents.\"\"\"\n",
    "    patterns = {\n",
    "        \"header_usage\": sum(1 for d in documents if d.startswith(\"#\")),\n",
    "        \"bold_usage\": sum(1 for d in documents if \"**\" in d),\n",
    "        \"list_usage\": sum(1 for d in documents if \"- \" in d),\n",
    "        \"consistent_structure\": len(set(d.split(\"\\\\n\")[0] for d in documents)) == 1\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"total_documents\": len(documents),\n",
    "        \"patterns\": patterns,\n",
    "        \"recommendations\": [\n",
    "            \"Ensure all documents start with proper headers\",\n",
    "            \"Use consistent formatting for similar content types\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ==================== DATA CONVENTIONS TOOLS ====================\n",
    "\n",
    "def analyze_variable_conventions(variable_name: str, data_type: str) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze and document data conventions for a variable.\"\"\"\n",
    "    # Detect naming pattern\n",
    "    if \"_\" in variable_name:\n",
    "        pattern = \"snake_case\"\n",
    "        parts = variable_name.split(\"_\")\n",
    "        prefix = parts[0] if len(parts) > 1 else None\n",
    "    elif variable_name[0].isupper():\n",
    "        pattern = \"PascalCase\"\n",
    "        prefix = None\n",
    "    elif any(c.isupper() for c in variable_name[1:]):\n",
    "        pattern = \"camelCase\"\n",
    "        prefix = None\n",
    "    else:\n",
    "        pattern = \"lowercase\"\n",
    "        prefix = None\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"variable_name\": variable_name,\n",
    "        \"naming_convention\": {\n",
    "            \"pattern\": pattern,\n",
    "            \"prefix\": prefix,\n",
    "            \"suffix\": None,\n",
    "            \"follows_standard\": pattern in [\"snake_case\", \"camelCase\"],\n",
    "            \"deviation_notes\": \"\" if pattern in [\"snake_case\", \"camelCase\"] else \"Non-standard naming pattern\"\n",
    "        },\n",
    "        \"value_conventions\": {\n",
    "            \"coding_scheme\": \"Standard healthcare coding\",\n",
    "            \"valid_values\": [],\n",
    "            \"missing_indicator\": \"NA\",\n",
    "            \"format_pattern\": data_type\n",
    "        },\n",
    "        \"recommended_documentation\": {\n",
    "            \"technical_name\": variable_name,\n",
    "            \"display_name\": variable_name.replace(\"_\", \" \").title(),\n",
    "            \"code_sample\": f'df[\"{variable_name}\"]',\n",
    "            \"validation_rules\": [\"Not null\", f\"Type: {data_type}\"]\n",
    "        },\n",
    "        \"consistency_score\": 90 if pattern == \"snake_case\" else 70,\n",
    "        \"convention_warnings\": []\n",
    "    }\n",
    "\n",
    "def generate_conventions_glossary(variables: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Generate a comprehensive conventions glossary.\"\"\"\n",
    "    patterns = {}\n",
    "    for var in variables:\n",
    "        name = var.get(\"Variable Name\", \"\")\n",
    "        if \"_\" in name:\n",
    "            patterns[\"snake_case\"] = patterns.get(\"snake_case\", 0) + 1\n",
    "        elif any(c.isupper() for c in name[1:]):\n",
    "            patterns[\"camelCase\"] = patterns.get(\"camelCase\", 0) + 1\n",
    "        else:\n",
    "            patterns[\"other\"] = patterns.get(\"other\", 0) + 1\n",
    "\n",
    "    dominant = max(patterns.items(), key=lambda x: x[1])[0] if patterns else \"unknown\"\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"naming_patterns\": patterns,\n",
    "        \"dominant_pattern\": dominant,\n",
    "        \"total_variables\": len(variables),\n",
    "        \"recommendations\": [\n",
    "            f\"Primary naming convention: {dominant}\",\n",
    "            \"Maintain consistency across all new variables\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ==================== VERSION CONTROL TOOLS ====================\n",
    "\n",
    "def create_version(tool_context: ToolContext, element_id: str,\n",
    "                   element_type: str, content: str) -> Dict[str, Any]:\n",
    "    \"\"\"Create a new version of a documentation element.\"\"\"\n",
    "    # Get current version from state\n",
    "    version_key = f\"version:{element_id}\"\n",
    "    current_version = tool_context.state.get(version_key, \"0.0.0\")\n",
    "\n",
    "    # Calculate content hash\n",
    "    content_hash = hashlib.sha256(content.encode()).hexdigest()[:16]\n",
    "\n",
    "    # Check if content changed\n",
    "    hash_key = f\"hash:{element_id}\"\n",
    "    old_hash = tool_context.state.get(hash_key, \"\")\n",
    "\n",
    "    if old_hash == content_hash:\n",
    "        return {\n",
    "            \"status\": \"no_change\",\n",
    "            \"element_id\": element_id,\n",
    "            \"version\": current_version,\n",
    "            \"message\": \"Content unchanged, no new version created\"\n",
    "        }\n",
    "\n",
    "    # Increment version (simple patch increment)\n",
    "    parts = list(map(int, current_version.split(\".\")))\n",
    "    parts[2] += 1\n",
    "    new_version = \".\".join(map(str, parts))\n",
    "\n",
    "    # Store new version info\n",
    "    tool_context.state[version_key] = new_version\n",
    "    tool_context.state[hash_key] = content_hash\n",
    "    tool_context.state[f\"content:{element_id}:{new_version}\"] = content\n",
    "\n",
    "    # Store version history\n",
    "    history_key = f\"history:{element_id}\"\n",
    "    history = json.loads(tool_context.state.get(history_key, \"[]\"))\n",
    "    history.append({\n",
    "        \"version\": new_version,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"hash\": content_hash\n",
    "    })\n",
    "    tool_context.state[history_key] = json.dumps(history)\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"element_id\": element_id,\n",
    "        \"element_type\": element_type,\n",
    "        \"new_version\": new_version,\n",
    "        \"previous_version\": current_version,\n",
    "        \"content_hash\": content_hash,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def get_version_history(tool_context: ToolContext, element_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get the version history for a documentation element.\"\"\"\n",
    "    history_key = f\"history:{element_id}\"\n",
    "    history = json.loads(tool_context.state.get(history_key, \"[]\"))\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"element_id\": element_id,\n",
    "        \"version_count\": len(history),\n",
    "        \"history\": history,\n",
    "        \"current_version\": tool_context.state.get(f\"version:{element_id}\", \"1.0.0\")\n",
    "    }\n",
    "\n",
    "def rollback_version(tool_context: ToolContext, element_id: str,\n",
    "                     target_version: str) -> Dict[str, Any]:\n",
    "    \"\"\"Rollback to a previous version.\"\"\"\n",
    "    content_key = f\"content:{element_id}:{target_version}\"\n",
    "    content = tool_context.state.get(content_key, None)\n",
    "\n",
    "    if not content:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"Version {target_version} not found for {element_id}\"\n",
    "        }\n",
    "\n",
    "    # Create new version with old content\n",
    "    return create_version(tool_context, element_id, \"rollback\", content)\n",
    "\n",
    "def compare_versions(tool_context: ToolContext, element_id: str,\n",
    "                    version_a: str, version_b: str) -> Dict[str, Any]:\n",
    "    \"\"\"Compare two versions of an element.\"\"\"\n",
    "    content_a = tool_context.state.get(f\"content:{element_id}:{version_a}\", \"\")\n",
    "    content_b = tool_context.state.get(f\"content:{element_id}:{version_b}\", \"\")\n",
    "\n",
    "    if not content_a or not content_b:\n",
    "        return {\"status\": \"error\", \"message\": \"One or both versions not found\"}\n",
    "\n",
    "    # Simple line-by-line comparison\n",
    "    lines_a = set(content_a.split(\"\\\\n\"))\n",
    "    lines_b = set(content_b.split(\"\\\\n\"))\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"element_id\": element_id,\n",
    "        \"version_a\": version_a,\n",
    "        \"version_b\": version_b,\n",
    "        \"added_lines\": len(lines_b - lines_a),\n",
    "        \"removed_lines\": len(lines_a - lines_b),\n",
    "        \"unchanged_lines\": len(lines_a & lines_b)\n",
    "    }\n",
    "\n",
    "# ==================== HIGHER-LEVEL DOCUMENTATION TOOLS ====================\n",
    "\n",
    "def identify_instruments(variables: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Identify potential instruments or measurement tools in the dataset.\"\"\"\n",
    "    prefix_groups = {}\n",
    "\n",
    "    for var in variables:\n",
    "        name = var.get(\"Variable Name\", \"\")\n",
    "        if \"_\" in name:\n",
    "            prefix = name.split(\"_\")[0]\n",
    "            if prefix not in prefix_groups:\n",
    "                prefix_groups[prefix] = []\n",
    "            prefix_groups[prefix].append(var)\n",
    "\n",
    "    instruments = []\n",
    "    for prefix, vars in prefix_groups.items():\n",
    "        if len(vars) >= 3:\n",
    "            instruments.append({\n",
    "                \"prefix\": prefix,\n",
    "                \"suggested_name\": f\"{prefix.upper()} Instrument\",\n",
    "                \"variable_count\": len(vars),\n",
    "                \"variables\": [v.get(\"Variable Name\") for v in vars]\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"instruments_found\": len(instruments),\n",
    "        \"instruments\": instruments\n",
    "    }\n",
    "\n",
    "def document_instrument(variables: List[Dict], instrument_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"Document a complete instrument or measurement tool.\"\"\"\n",
    "    var_names = [v.get(\"Variable Name\", \"Unknown\") for v in variables]\n",
    "\n",
    "    doc_markdown = f\"\"\"# {instrument_name}\n",
    "\n",
    "## Overview\n",
    "This instrument consists of {len(variables)} related variables.\n",
    "\n",
    "## Variables Included\n",
    "{chr(10).join(f\"- {name}\" for name in var_names)}\n",
    "\n",
    "## Clinical Context\n",
    "These variables are grouped together as they represent a cohesive measurement domain.\n",
    "\n",
    "## Usage Guidelines\n",
    "- Ensure all variables are collected together for complete instrument score\n",
    "- Follow standard data collection protocols\n",
    "- Document any missing values\n",
    "\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"element_type\": \"instrument\",\n",
    "        \"name\": instrument_name,\n",
    "        \"short_name\": instrument_name.split()[0] if \" \" in instrument_name else instrument_name,\n",
    "        \"description\": f\"Instrument containing {len(variables)} related variables\",\n",
    "        \"variables_included\": [\n",
    "            {\n",
    "                \"variable_name\": v.get(\"Variable Name\", \"Unknown\"),\n",
    "                \"role\": \"item\",\n",
    "                \"position\": i + 1\n",
    "            }\n",
    "            for i, v in enumerate(variables)\n",
    "        ],\n",
    "        \"documentation_markdown\": doc_markdown\n",
    "    }\n",
    "\n",
    "def document_segment(variables: List[Dict], segment_name: str,\n",
    "                     segment_type: str = \"segment\") -> Dict[str, Any]:\n",
    "    \"\"\"Document a segment or logical grouping of variables.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"element_type\": segment_type,\n",
    "        \"name\": segment_name,\n",
    "        \"description\": f\"{segment_type.title()} containing {len(variables)} variables\",\n",
    "        \"variables_included\": [v.get(\"Variable Name\", \"Unknown\") for v in variables],\n",
    "        \"relationships\": [\n",
    "            {\n",
    "                \"type\": \"grouping\",\n",
    "                \"description\": f\"Variables grouped under {segment_name}\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def generate_codebook_overview(variables: List[Dict],\n",
    "                               instruments: Optional[List[Dict]] = None) -> Dict[str, str]:\n",
    "    \"\"\"Generate a comprehensive codebook overview.\"\"\"\n",
    "    overview = f\"\"\"# Codebook Overview\n",
    "\n",
    "**Total Variables:** {len(variables)}\n",
    "**Generated:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "---\n",
    "\n",
    "## Variable Summary\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    if instruments:\n",
    "        overview += f\"## Identified Instruments: {len(instruments)}\\\\n\\\\n\"\n",
    "        for inst in instruments:\n",
    "            overview += f\"- **{inst.get('suggested_name', 'Unknown')}**: {inst.get('variable_count', 0)} variables\\\\n\"\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"overview\": overview,\n",
    "        \"total_variables\": len(variables),\n",
    "        \"instruments_count\": len(instruments) if instruments else 0\n",
    "    }\n",
    "\n",
    "# ==================== MEMORY TOOLS ====================\n",
    "\n",
    "def save_to_memory(tool_context: ToolContext, key: str, value: str) -> Dict[str, str]:\n",
    "    \"\"\"Save information to session state.\"\"\"\n",
    "    tool_context.state[f\"memory:{key}\"] = value\n",
    "    return {\"status\": \"success\", \"message\": f\"Saved {key} to memory\"}\n",
    "\n",
    "def retrieve_from_memory(tool_context: ToolContext, key: str) -> Dict[str, Any]:\n",
    "    \"\"\"Retrieve information from session state.\"\"\"\n",
    "    value = tool_context.state.get(f\"memory:{key}\", \"Not found\")\n",
    "    return {\"status\": \"success\", \"key\": key, \"value\": value}\n",
    "\n",
    "# ==================== CREATE ROOT AGENT ====================\n",
    "\n",
    "root_agent = LlmAgent(\n",
    "    name=\"healthcare_documentation_agent\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    description=\"Advanced agent for healthcare data documentation with design improvement, conventions enforcement, version control, and higher-level documentation capabilities\",\n",
    "    instruction=\"\"\"You are an Advanced Healthcare Data Documentation Agent with extended capabilities:\n",
    "\n",
    "CORE CAPABILITIES:\n",
    "1. Parse data dictionaries from various formats\n",
    "2. Map variables to standard healthcare ontologies (OMOP, LOINC, SNOMED)\n",
    "3. Generate clear, comprehensive documentation\n",
    "\n",
    "EXTENDED CAPABILITIES:\n",
    "4. **Design Improvement**: Enhance document structure, readability, and visual hierarchy\n",
    "5. **Data Conventions**: Ensure variable naming standards and coding schemes are documented\n",
    "6. **Version Control**: Track changes, manage versions, and support rollbacks\n",
    "7. **Higher-Level Documentation**: Document instruments, segments, and codebook structures\n",
    "\n",
    "WORKFLOW:\n",
    "When processing a data dictionary:\n",
    "1. Use parse_data_dictionary to extract variable information\n",
    "2. Use map_to_ontology for each variable to find standard codes\n",
    "3. Use analyze_variable_conventions to ensure naming standards are documented\n",
    "4. Use generate_documentation to create human-readable documentation\n",
    "5. Use improve_document_design to enhance the output quality\n",
    "6. Use create_version to track changes and enable rollback\n",
    "7. Use identify_instruments to find related variable groups\n",
    "8. Use document_instrument for higher-level documentation\n",
    "9. Use generate_codebook_overview for comprehensive summary\n",
    "\n",
    "For updates and modifications:\n",
    "- Always use create_version before making changes\n",
    "- Use compare_versions to understand differences\n",
    "- Use rollback_version if needed to revert changes\n",
    "\n",
    "Remember to save important findings to memory for cross-session knowledge.\"\"\",\n",
    "    tools=[\n",
    "        # Core tools\n",
    "        parse_data_dictionary,\n",
    "        map_to_ontology,\n",
    "        generate_documentation,\n",
    "        # Design improvement tools\n",
    "        improve_document_design,\n",
    "        analyze_design_patterns,\n",
    "        # Data conventions tools\n",
    "        analyze_variable_conventions,\n",
    "        generate_conventions_glossary,\n",
    "        # Version control tools\n",
    "        create_version,\n",
    "        get_version_history,\n",
    "        rollback_version,\n",
    "        compare_versions,\n",
    "        # Higher-level documentation tools\n",
    "        identify_instruments,\n",
    "        document_instrument,\n",
    "        document_segment,\n",
    "        generate_codebook_overview,\n",
    "        # Memory tools\n",
    "        save_to_memory,\n",
    "        retrieve_from_memory,\n",
    "    ],\n",
    ")\n",
    "'''\n",
    "\n",
    "with open(f\"{DEPLOY_DIR}/agent.py\", 'w') as f:\n",
    "    f.write(agent_code)\n",
    "\n",
    "print(f\"\u2713 Created {DEPLOY_DIR}/agent.py with extended agent capabilities\")\n",
    "print(\"  Core tools:\")\n",
    "print(\"    - parse_data_dictionary, map_to_ontology, generate_documentation\")\n",
    "print(\"  Design improvement tools:\")\n",
    "print(\"    - improve_document_design, analyze_design_patterns\")\n",
    "print(\"  Data conventions tools:\")\n",
    "print(\"    - analyze_variable_conventions, generate_conventions_glossary\")\n",
    "print(\"  Version control tools:\")\n",
    "print(\"    - create_version, get_version_history, rollback_version, compare_versions\")\n",
    "print(\"  Higher-level documentation tools:\")\n",
    "print(\"    - identify_instruments, document_instrument, document_segment, generate_codebook_overview\")\n",
    "print(\"  Memory tools:\")\n",
    "print(\"    - save_to_memory, retrieve_from_memory\")"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DEPLOY_DIR' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3003897503.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m '''\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DEPLOY_DIR}/agent.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEPLOY_DIR' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwQHhczVg3Xt"
   },
   "outputs": [],
   "source": [
    "# Create deployment directory structureimport osDEPLOY_DIR = \"healthcare_agent_deploy\"# Create directory structureos.makedirs(f\"{DEPLOY_DIR}\", exist_ok=True)print(f'''\ud83d\udcc1 Deployment Structure for Vertex AI Agent Engine:{DEPLOY_DIR}/\u251c\u2500\u2500 agent.py                     # Main agent logic\u251c\u2500\u2500 requirements.txt             # Python dependencies\u251c\u2500\u2500 .env                         # Environment configuration\u2514\u2500\u2500 .agent_engine_config.json    # Deployment specificationsThis structure follows ADK deployment conventions.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cCgV2YRg3Xt"
   },
   "outputs": [],
   "source": [
    "# Create the main agent.py file for deploymentagent_code = \"\"\"import osimport jsonimport vertexaifrom google.adk.agents import Agent, LlmAgentfrom google.adk.tools.tool_context import ToolContextfrom typing import Dict, List, Any# Initialize Vertex AIvertexai.init(    project=os.environ.get(\"GOOGLE_CLOUD_PROJECT\"),    location=os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\"),)def parse_data_dictionary(data: str) -> Dict[str, Any]:    \"\"\"Parse a raw data dictionary into structured format.\"\"\"    lines = data.strip().split(\"\\n\")    if not lines:        return {\"status\": \"error\", \"message\": \"Empty data\"}    header = lines[0].split(\",\")    variables = []    for line in lines[1:]:        if line.strip():            values = line.split(\",\")            var_dict = dict(zip(header, values))            variables.append(var_dict)    return {        \"status\": \"success\",        \"variable_count\": len(variables),        \"variables\": variables    }def map_to_ontology(variable_name: str, data_type: str) -> Dict[str, Any]:    \"\"\"Map a variable to standard healthcare ontologies.\"\"\"    ontology_map = {        \"patient_id\": {\"omop\": \"person_id\", \"concept_id\": 0},        \"age\": {\"omop\": \"year_of_birth\", \"concept_id\": 4154793},        \"sex\": {\"omop\": \"gender_concept_id\", \"concept_id\": 4135376},        \"bp_systolic\": {\"omop\": \"measurement\", \"concept_id\": 3004249},        \"bp_diastolic\": {\"omop\": \"measurement\", \"concept_id\": 3012888},        \"hba1c\": {\"omop\": \"measurement\", \"concept_id\": 3004410, \"loinc\": \"4548-4\"},    }    mapping = ontology_map.get(variable_name.lower(), {\"omop\": \"unknown\", \"concept_id\": 0})    return {\"status\": \"success\", \"variable_name\": variable_name, \"mappings\": mapping}def generate_documentation(variable_info: Dict[str, Any]) -> Dict[str, str]:    \"\"\"Generate human-readable documentation for a variable.\"\"\"    name = variable_info.get(\"Variable Name\", \"Unknown\")    field_type = variable_info.get(\"Field Type\", \"text\")    label = variable_info.get(\"Field Label\", name)    notes = variable_info.get(\"Notes\", \"No additional notes\")    doc = f\"\"\"## Variable: {name}**Description:** {label}**Technical Details:**- Data Type: {field_type}- Cardinality: required- Notes: {notes}\"\"\"    return {\"status\": \"success\", \"documentation\": doc}def save_to_memory(tool_context: ToolContext, key: str, value: str) -> Dict[str, str]:    \"\"\"Save information to session state.\"\"\"    tool_context.state[f\"memory:{key}\"] = value    return {\"status\": \"success\", \"message\": f\"Saved {key} to memory\"}def retrieve_from_memory(tool_context: ToolContext, key: str) -> Dict[str, Any]:    \"\"\"Retrieve information from session state.\"\"\"    value = tool_context.state.get(f\"memory:{key}\", \"Not found\")    return {\"status\": \"success\", \"key\": key, \"value\": value}# Create the root agentroot_agent = LlmAgent(    name=\"healthcare_documentation_agent\",    model=\"gemini-2.0-flash-exp\",    description=\"Agent for generating healthcare data documentation\",    instruction=\"\"\"You are a Healthcare Data Documentation Agent specialized in:1. Parsing data dictionaries from various formats2. Mapping variables to standard healthcare ontologies (OMOP, LOINC, SNOMED)3. Generating clear, comprehensive documentationWhen a user provides a data dictionary:1. Use parse_data_dictionary to extract variable information2. Use map_to_ontology for each variable to find standard codes3. Use generate_documentation to create human-readable documentation4. Use save_to_memory to store results for later reference\"\"\",    tools=[        parse_data_dictionary,        map_to_ontology,        generate_documentation,        save_to_memory,        retrieve_from_memory,    ],)\"\"\"with open(f\"{DEPLOY_DIR}/agent.py\", 'w') as f:    f.write(agent_code)print(f\"\u2713 Created {DEPLOY_DIR}/agent.py\")print(\"  - Includes healthcare-specific tools\")print(\"  - Uses ADK LlmAgent pattern\")print(\"  - Integrated session state management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lpgn9UgGg3Xt"
   },
   "outputs": [],
   "source": [
    "# Create requirements.txt for deploymentrequirements = \"\"\"google-adk>=1.0.0google-cloud-aiplatform>=1.38.0opentelemetry-instrumentation-google-genaivertexai\"\"\"with open(f\"{DEPLOY_DIR}/requirements.txt\", 'w') as f:    f.write(requirements)print(f\"\u2713 Created {DEPLOY_DIR}/requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7Ro_QS7g3Xt"
   },
   "outputs": [],
   "source": [
    "# Create .env configurationenv_config = \"\"\"# Vertex AI ConfigurationGOOGLE_CLOUD_PROJECT=your-project-idGOOGLE_CLOUD_LOCATION=us-central1GOOGLE_GENAI_USE_VERTEXAI=1\"\"\"with open(f\"{DEPLOY_DIR}/.env\", 'w') as f:    f.write(env_config)print(f\"\u2713 Created {DEPLOY_DIR}/.env\")print(\"  \u26a0\ufe0f  Remember to update GOOGLE_CLOUD_PROJECT with your project ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkZDxmWCg3Xt"
   },
   "outputs": [],
   "source": [
    "# Create .agent_engine_config.jsondeployment_config = {    \"min_instances\": 0,    \"max_instances\": 3,    \"resource_limits\": {        \"cpu\": \"2\",        \"memory\": \"4Gi\"    },    \"timeout_seconds\": 300,    \"environment_variables\": {        \"LOG_LEVEL\": \"INFO\"    }}with open(f\"{DEPLOY_DIR}/.agent_engine_config.json\", 'w') as f:    json.dump(deployment_config, f, indent=2)print(f\"\u2713 Created {DEPLOY_DIR}/.agent_engine_config.json\")print(f\"  - Min instances: {deployment_config['min_instances']}\")print(f\"  - Max instances: {deployment_config['max_instances']}\")print(f\"  - Resources: {deployment_config['resource_limits']['cpu']} CPU, {deployment_config['resource_limits']['memory']} Memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjClOmEFg3Xt"
   },
   "source": [
    "### Deploy Using ADK CLIOnce your deployment files are created, use the ADK CLI to deploy:```bash# Set your project and regionexport PROJECT_ID=\"your-project-id\"export REGION=\"us-central1\"# Deploy the agentadk deploy agent_engine \\    --project=$PROJECT_ID \\    --region=$REGION \\    healthcare_agent_deploy \\    --agent_engine_config_file=healthcare_agent_deploy/.agent_engine_config.json```The deployment process will:1. Build a container with your agent code2. Push to Google Container Registry3. Deploy to Vertex AI Agent Engine4. Return the deployment resource name**Expected output:**```Deploying agent to Vertex AI Agent Engine...Building container image...Pushing to Container Registry...Creating Agent Engine instance...\u2713 Agent deployed successfully!Resource name: projects/YOUR_PROJECT/locations/REGION/agents/AGENT_ID```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBvVb73Ng3Xu"
   },
   "source": [
    "### Testing Your Deployed AgentAfter deployment, test your agent using the Vertex AI SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMDdm4Bfg3Xu"
   },
   "outputs": [],
   "source": [
    "# Test code for deployed agent (run AFTER deployment)# \u26a0\ufe0f Update PROJECT_ID before runningimport vertexaifrom vertexai import agent_enginesPROJECT_ID = \"your-project-id\"  # UPDATE THISREGION = \"us-central1\"vertexai.init(project=PROJECT_ID, location=REGION)# List deployed agentsprint(\"Deployed Agents:\")agents_list = list(agent_engines.list())for agent in agents_list:    print(f\"  - {agent.display_name}: {agent.resource_name}\")if agents_list:    remote_agent = agents_list[0]        # Test data dictionary    test_data = \"\"\"Variable Name,Field Type,Field Labelpatient_id,text,Patient IDage,integer,Age (years)hba1c,decimal,HbA1c (%)\"\"\"        print(f\"\\nTesting agent: {remote_agent.display_name}\")    print(\"Sending test query...\")        # Synchronous query (for simple testing)    response = remote_agent.query(        message=f\"Parse this data dictionary:\\n{test_data}\",        user_id=\"test_user_001\",    )    print(f\"\\nResponse: {response}\")else:    print(\"No deployed agents found. Deploy first using adk deploy command.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwncSLz4g3Xu"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a complete implementation of an Agent Development Environment (ADE) for Healthcare Data Documentation with the following features:\n",
    "\n",
    "### Core Components\n",
    "\n",
    "\u2705 **SQLite Database** - Persistent storage with sessions and memory tables  \n",
    "\u2705 **Toon Notation Encoding** - 40-70% token reduction for efficient context  \n",
    "\u2705 **Snippet Manager** - Named context storage with extended types (Convention, Changelog, Instrument, Segment, Glossary)  \n",
    "\u2705 **Review Queue (HITL)** - Human-in-the-loop approval workflows  \n",
    "\u2705 **Multi-Agent Pipeline** - DataParser \u2192 TechnicalAnalyzer \u2192 DomainOntology \u2192 PlainLanguage \u2192 Assembler  \n",
    "\u2705 **Session Management** - ADK-style state persistence  \n",
    "\u2705 **Memory Services** - Long-term knowledge storage  \n",
    "\u2705 **Observability** - Logging and monitoring throughout  \n",
    "\n",
    "### Extended Agent Capabilities (NEW)\n",
    "\n",
    "\u2705 **DesignImprovementAgent** - Enhances document structure, readability, and visual hierarchy  \n",
    "\u2705 **DataConventionsAgent** - Ensures variable naming standards and coding schemes are documented  \n",
    "\u2705 **VersionControlAgent** - Tracks changes, manages semantic versioning, and supports rollbacks  \n",
    "\u2705 **HigherLevelDocumentationAgent** - Documents instruments, segments, and codebook structures  \n",
    "\n",
    "### Extended Orchestrator Features\n",
    "\n",
    "\u2705 **process_with_extended_agents()** - Full pipeline with all agent capabilities  \n",
    "\u2705 **update_documentation()** - Update elements with automatic version control  \n",
    "\u2705 **get_element_history()** - View complete version history  \n",
    "\u2705 **rollback_element()** - Revert to previous versions  \n",
    "\n",
    "### Production Deployment\n",
    "\n",
    "\u2705 **Vertex AI Agent Engine** - Fully managed, auto-scaling infrastructure  \n",
    "\u2705 **Extended Tool Set** - 16 tools for comprehensive documentation  \n",
    "  - Core: parse_data_dictionary, map_to_ontology, generate_documentation  \n",
    "  - Design: improve_document_design, analyze_design_patterns  \n",
    "  - Conventions: analyze_variable_conventions, generate_conventions_glossary  \n",
    "  - Version Control: create_version, get_version_history, rollback_version, compare_versions  \n",
    "  - Higher-Level: identify_instruments, document_instrument, document_segment, generate_codebook_overview  \n",
    "\u2705 **Container Deployment** - ADK CLI integration  \n",
    "\u2705 **Cloud Monitoring** - Logs, metrics, and alerts  \n",
    "\u2705 **Security** - IAM integration and compliance support  \n",
    "\n",
    "### Key Patterns Implemented\n",
    "\n",
    "- Retry configuration with exponential backoff\n",
    "- Rate limiting for API quota management\n",
    "- Context compaction for long conversations\n",
    "- Ontology mapping (OMOP, LOINC, SNOMED)\n",
    "- Human-readable documentation generation\n",
    "- **Semantic versioning** with automatic increment detection\n",
    "- **Convention enforcement** with consistency scoring\n",
    "- **Instrument identification** based on variable prefixes\n",
    "- **Design improvement** with measurable quality metrics\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Customize agents** for your specific healthcare domain\n",
    "2. **Add evaluation test cases** using ADK eval framework\n",
    "3. **Implement A2A protocol** for agent-to-agent communication\n",
    "4. **Set up continuous deployment** pipeline\n",
    "5. **Add custom observability plugins** for your metrics\n",
    "6. **Configure convention rules** for your organization's standards\n",
    "7. **Define instrument templates** for common measurement tools\n",
    "\n",
    "For more information, see:\n",
    "- [ADK Documentation](https://google.github.io/adk-docs/)\n",
    "- [Vertex AI Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)\n",
    "- [OMOP CDM](https://ohdsi.github.io/CommonDataModel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-hGywgEg3Xu"
   },
   "source": [
    "### Production ConsiderationsWhen deploying to production:1. **Authentication & Security**   - Use service accounts with minimal required permissions   - Enable VPC Service Controls for data protection   - Configure Cloud Armor for DDoS protection2. **Scaling**   - Set appropriate min/max instances based on expected load   - Monitor cold start times and adjust accordingly   - Use connection pooling for database connections3. **Monitoring**   - Set up alerts for error rates and latency   - Monitor token usage and costs   - Track session memory usage4. **Data Compliance**   - Ensure HIPAA compliance for healthcare data   - Implement audit logging   - Configure data retention policies5. **Cost Optimization**   - Use preemptible instances for non-critical workloads   - Set min_instances to 0 for development   - Monitor and optimize API call frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xiynOXrg3Xu"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a complete implementation of an Agent Development Environment (ADE) for Healthcare Data Documentation with the following features:\n",
    "\n",
    "### Core Components\n",
    "\n",
    "\u2705 **SQLite Database** - Persistent storage with sessions and memory tables  \n",
    "\u2705 **Toon Notation Encoding** - 40-70% token reduction for efficient context  \n",
    "\u2705 **Snippet Manager** - Named context storage and retrieval  \n",
    "\u2705 **Review Queue (HITL)** - Human-in-the-loop approval workflows  \n",
    "\u2705 **Multi-Agent Pipeline** - DataParser \u2192 TechnicalAnalyzer \u2192 DomainOntology \u2192 PlainLanguage \u2192 Assembler  \n",
    "\u2705 **Session Management** - ADK-style state persistence  \n",
    "\u2705 **Memory Services** - Long-term knowledge storage  \n",
    "\u2705 **Observability** - Logging and monitoring throughout  \n",
    "\n",
    "### Production Deployment\n",
    "\n",
    "\u2705 **Vertex AI Agent Engine** - Fully managed, auto-scaling infrastructure  \n",
    "\u2705 **Container Deployment** - ADK CLI integration  \n",
    "\u2705 **Cloud Monitoring** - Logs, metrics, and alerts  \n",
    "\u2705 **Security** - IAM integration and compliance support  \n",
    "\n",
    "### Key Patterns Implemented\n",
    "\n",
    "- Retry configuration with exponential backoff\n",
    "- Rate limiting for API quota management\n",
    "- Context compaction for long conversations\n",
    "- Ontology mapping (OMOP, LOINC, SNOMED)\n",
    "- Human-readable documentation generation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Customize agents** for your specific healthcare domain\n",
    "2. **Add evaluation test cases** using ADK eval framework\n",
    "3. **Implement A2A protocol** for agent-to-agent communication\n",
    "4. **Set up continuous deployment** pipeline\n",
    "5. **Add custom observability plugins** for your metrics\n",
    "\n",
    "For more information, see:\n",
    "- [ADK Documentation](https://google.github.io/adk-docs/)\n",
    "- [Vertex AI Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)\n",
    "- [OMOP CDM](https://ohdsi.github.io/CommonDataModel/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "q0lRdFoqg3Xk",
    "0I86aaeTg3Xk",
    "67Yi0txyg3Xl",
    "hfjPDazCg3Xl",
    "6HpSTK7Sg3Xl",
    "a2YvGzQEg3Xq",
    "pzb4DAeWg3Xq",
    "R7SuIeCMg3Xr",
    "G9hEhbNkg3Xr",
    "YR6Smubfg3Xr",
    "iZy9jf4Sg3Xr"
   ],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}